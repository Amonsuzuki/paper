60QAの進め方	1
１．はじめに・序論 / Introduction（10/10完了）	2
２．関連研究 / Related Work（5/5完了）	3
３．問題設定 / Problem Statement（8/8完了）	4
４．手法 / Method（11/11完了）	5
５．実験設定 / Experimental Setup（11/11完了）	6
６．実験結果 / Experimental Results（14/14完了）	7
７．結論 / Conclusions（3/3完了）	8

60QAの進め方
標準的な国際会議論文は、およそ60段落からなる。各段落を質問への回答だと考えれば、約60個の質問に答えることで論文を完成できる。
論文全体を考えるから途方に暮れるのであって、各質問に分割すれば楽。
質問者は、査読者（他大学や他分野の教員）と想定する。
具体的な質問者（XX先生、等）を思い浮かべ、その人からメールが届いたと想定して回答する。
「はじめに」からスタートすると詰まるので、以下の順で書くべし。
do {３問題設定} while (完了率<66%); 
do {５実験設定} while (完了率<66%); 
do {４手法} while (完了率<50%);
do {６実験結果} while (完了率<66%);
do {３問題設定, ４手法, ５実験設定, ６実験結果} while (完了率<100%); // 順不同
do {７結論} while (完了率<66%);
do {１はじめに} while (完了率<66%); // ここで「はじめに」に着手
do {２関連研究} while (完了率<66%);
do {１はじめに, ２関連研究, ７結論} while (完了率<100%); // 順不同
完了したら、TeX流し込み→論理構造の調整→短縮→赤入れ、と進む。
順番を気にせず進むのはなぜ良くないか？
例えば、用語定義等が誤ったまま次に進むと、大量のQAで同じ指摘が発生し、結局手戻りが発生する。
テンプレ質問は最大公約数的な質問なので、自分の論文にそぐわないものもある。
よって、通常１０個程度は質問をカスタマイズか削除する。
記号の意味
▲：未完了
○：教員チェック済　
回答の第1文はトピックセンテンスから始めよ。
論文執筆はプログラミングのようなものだと思えば良い。
適切なブロック（関数/QA）に分割して、始めから終わりまでのロジックを設計するという意味では同じ。
60QAは、文章を書くのが苦手な人でも書ける仕組みとして作った。ただし、京大・ATR・NICTでの所属研究室のノウハウ・査読者からのコメント・先人の知恵に立脚している。
べからず集
単語のみや体言止めや「...であるため。」で回答を終わらせてはならない
常に文で回答せよ。
メールだったら、質問者に単語で回答することなどしないはず。

１．はじめに・序論 / Introduction（2/10完了）
○本研究の社会的背景は何か？ / What is the social background?
分散深層学習において、中央集権型学習（Federated Learning）は単一障害点や拡張性の問題を抱えている。これに対して、分散学習（Decentralized Learning）はP2Pネットワークベースの手法として、これらの欠点を克服し、データプライバシーを保ちながら正確なモデルを構築できることが示されている。特に、帯域幅が限られた環境や高遅延ネットワーク環境では、分散学習がFederated Learningより高速に動作することが先行研究で実証されている。

○本研究のtarget task/problemは何か？ / What is the target problem of this work?
分散学習環境において、故障ノードや悪意のある攻撃者（Byzantine nodes）が存在する場合、これらのノードが異常なモデルを送信することでモデルの収束が妨げられる問題に取り組む。特に、既存の防御手法が高度な攻撃や Byzantine ノードの割合増加に対して失敗することが指摘されている。

○本研究のtarget problemの具体例（ユースケース）は何か？ / Explain a typical use case.
医療機関や金融機関などがプライバシーを保護しながら協調学習を行う場合、各ノードがローカルデータを保持したまま分散学習を実施する。しかし、ネットワーク内の一部のノードが故障したり、悪意のある攻撃者によって制御されたりすると、これらのByzantineノードが誤ったモデルパラメータを送信し、全体のモデル精度を大幅に低下させる。このような環境下でも、正常なノードが高精度なモデルを学習できることが求められる。

○そのtarget problemが難しいと言う根拠は何か？既存手法が誤る例はどんなケースか？ / Why is this task challenging?
Byzantine攻撃の検出と防御は、攻撃者が正常なノードと同じ形式でモデルを送信するため本質的に困難である。特に、学習の初期段階では、正常なノードのモデルも高い損失値を示すため、Byzantineモデルと区別することが難しい。また、攻撃者が協調して高度な攻撃（A little is enough攻撃など）を仕掛けると、既存の距離ベース手法や性能ベース手法では検出できず、モデルの収束が阻害される。さらに、Byzantineノードの割合が増加すると、既存手法の精度が急激に低下する問題がある。

○既存手法はなぜ不十分なのか？ / Why are conventional studies insufficient?
既存の距離ベース手法（Krumなど）は、高度な攻撃やByzantineノードの割合が増加すると効果がなくなる。性能ベース手法（Zenoなど）は、学習初期段階でByzantineノードとBenignノードを区別できず、Byzantineモデルが集約に含まれるリスクがある。ハイブリッド手法（UBARなど）は、第一段階で高度な攻撃をフィルタリングできず、第二段階でも攻撃モデルが選択される可能性が高い。これらの手法は、いずれもByzantineノード比率が高い環境下で性能が大幅に低下し、実用的な分散学習環境において十分な防御能力を提供できない。

○本研究では何を提案し、何を解決するのか？ / What is proposed and solved in this study?
本研究では、損失関数値に基づく新しいフィルタリング手法と、過学習検出による動的しきい値調整機構を提案する。これにより、学習初期段階でのByzantineノードとBenignノードの区別問題を解決し、高度な攻撃やByzantineノード比率が高い環境下でも安定したモデル収束を実現する。提案手法は、既存手法と比較して高速に収束し、Byzantineノード比率が0.5の場合でも0.5以上の精度を維持することで、実用的な分散学習環境におけるByzantine耐性を大幅に向上させる。

○提案手法は既存手法と何が違うのか？主要な違いに絞って述べよ。 / What is the difference between the proposed and conventional methods?
提案手法の主要な違いは、損失関数値の差分を用いた新しいフィルタリング基準と、動的しきい値調整機構の導入である。既存手法が単純な距離計算や固定的な性能評価を用いるのに対し、提案手法は自ノードのモデルとの損失値の差（F_i(x;ξ_i) - F_j(x;ξ_i) ≧ θ）を基準とし、学習初期段階では高いしきい値θを設定することで、自ノードより汎化性能が高いモデルのみを選択的に集約する。また、過学習検出時にθを動的に減少させることで、学習の進行に応じた柔軟なフィルタリングを実現する点が既存手法と大きく異なる。

○既存手法との違う部分は、なぜ導入するべきなのか？なぜ導入するとうまくいくと予想されるのか？ / Explain why the difference should be introduced.
損失関数値に基づくフィルタリングは、モデルの汎化性能を直接評価できるため導入すべきである。学習初期段階では、正常なノードのモデルも一様に高い損失値を示すが、高いしきい値θを設定することで、自ノードより明確に優れたモデルのみを受け入れることができる。これにより、Byzantineモデルが高い損失値を持つ場合でも、正常なノードより性能が低ければフィルタリングされる。また、動的しきい値調整により、過学習後はより多様なモデルを受け入れつつ、θの下限（-0.1）を設定することでByzantineモデルの浸入を防ぐ。この仕組みにより、学習の各段階で適切なフィルタリングが実現され、既存手法が失敗する高度な攻撃や高いByzantineノード比率の環境下でも効果を発揮すると予想される。

○提案手法の新規性は何か？箇条書きせよ。 / What is the novelty of the proposed method?
1. 損失関数値の差分に基づく新しいフィルタリング基準の提案
2. 学習段階に応じた動的しきい値調整機構の導入
3. 過学習検出による適応的なモデル選択手法
4. しきい値下限の設定によるByzantine攻撃への継続的な耐性確保
5. 学習初期段階における高しきい値設定による効果的なBenign/Byzantine区別手法

○提案手法全体の構成をeye-catch figureを用いて示せ（通常6回修正ののち確定）。 / Show the eye-catch figure.
提案手法の全体構成図は、分散ネットワーク内の各ノードが(1)ローカル更新、(2)モデル交換、(3)損失ベースフィルタリング、(4)過学習検出としきい値調整、(5)モデル集約の5つのステップを循環的に実行する様子を示す。図中では、Benignノード（緑色）とByzantineノード（赤色）を区別し、損失値比較によるフィルタリングプロセスと、θの動的調整メカニズムをフローチャート形式で表現する。また、学習初期段階と過学習後の2つの状態におけるしきい値θの変化を視覚的に示す。


２．関連研究 / Related Work（2/5完了）
○XXX分野のサーベイ論文を複数挙げよ。 / Explain about multiple survey papers in the related area.
Byzantine耐性を持つ分散機械学習に関するサーベイとして、Kairouz et al. [13]によるFederated Learningの包括的なサーベイがある。また、Blanchard et al.による分散最適化におけるByzantine耐性に関する研究レビューや、Li et al.による分散学習のロバスト性に関する調査論文がある。これらのサーベイは、中央集権型および分散型の両方のアプローチにおけるByzantine攻撃と防御手法を体系的に整理している。

○論文を複数挙げて、１個目の関連分野を説明せよ。 / Explain the first related subfield and several related papers.
Distance-based（距離ベース）のフィルタリング手法として、Krum [10]がある。これは、隣接ノードのモデルパラメータ間のユークリッド距離を測定し、他のノードへの距離が最小となるモデルを選択して集約に使用する手法である。しかし、この手法は高度な攻撃やByzantineノードの割合が増加すると効果がなくなる。

○論文を複数挙げて、N個目の関連分野を説明せよ。（この項目を個数分コピーしてください） / Explain the N-th related subfield and several related papers.
Performance-based（性能ベース）の手法として、Zeno [11]などがある。これらは隣接ノードのモデルを評価する際に、損失値や精度などのメトリクスをノードのローカルデータを用いて測定し、汎化性能が悪いモデルを除外する。しかし、この手法は学習の初期段階において、ほとんどのモデルが一様に高い損失値を示すため、ByzantineノードとBenignノードを区別することが困難であり、Byzantineモデルが集約に含まれる可能性がある。また、ハイブリッド手法として、UBAR [12]が提案されており、距離ベースと性能ベースの二段階フィルタリングを採用しているが、第一段階で高度な攻撃をフィルタリングできず、第二段階でも攻撃モデルが選択されるリスクが高い。

○標準データセットについて説明せよ。 / Explain standard datasets in the related fields.
Byzantine耐性を持つ分散学習の研究では、CIFAR-10、CIFAR-100、MNISTなどの画像分類データセットが標準的に使用される。これらのデータセットは、各ノードに対してIID（独立同分布）またはnon-IID（非独立同分布）の形式で分散される。CIFAR-10は10クラスの32x32カラー画像60,000枚からなり、Byzantine攻撃の評価に十分な複雑性を持つため、多くの先行研究で採用されている。また、より大規模な評価にはImageNetやFashion-MNISTも使用される。

○提案手法と類似手法A（＋類似手法B、類似手法C）との違いは何か？ / What is the difference(s) between the proposed and related methods?
提案手法とKrum（類似手法A）との違いは、Krumが距離ベースの選択を行うのに対し、提案手法は損失関数値に基づく性能評価を行う点である。UBARとの違いは、UBARが距離と性能の二段階フィルタリングを行うのに対し、提案手法は損失値差分という単一の基準で一貫したフィルタリングを行い、動的しきい値調整により学習段階に応じた適応的な選択を実現する点である。D_Zenoとの違いは、D_Zenoが固定的な性能評価を行うのに対し、提案手法は自ノードとの相対的な性能差を評価し、学習初期段階での区別困難性を高しきい値設定により克服する点である。


３．問題設定 / Problem Statement（4/8完了）
○対象とするタスクの名称および内容は何か？ / What is the target problem?
Byzantine耐性を持つ分散学習（Byzantine-resilient Decentralized Learning）である。ネットワーク内の一部のノードが任意のメッセージを送信する状況下で、正常なノード（benign nodes）が協調して最適化問題を解く。

○対象タスクの望ましい解・出力について説明せよ（何をもって良い解だとするのか）。 / What is the expected behavior of the system?
正常なノードがネットワーク全体で以下の最適化問題を解くことが望ましい：min_{x∈R^d} f(x) := 1/|H| Σ_{i∈H} {f_i(x) := E_{ξ_i~D_i} F_i(x;ξ_i)}。ここで、xはモデルパラメータ、f_iはbenignノードiのローカル目的関数、F_i(x;ξ_i)は損失関数である。

○対象タスクの代表例を示せ（図を付けること）。 / Explain a typical sample with a figure.
代表的な例として、10ノードからなる分散ネットワークにおいて、接続率Cr=0.4で各ノードが隣接ノードと接続されている状況を示す。図では、円形配置された10個のノード（うち3個がByzantineノード、7個がBenignノード）が、エッジで接続されている。各ノードはCIFAR-10データの一部を保持し、学習エポックごとにモデルパラメータを隣接ノードと交換する。Byzantineノードは、Max AttackやA little is enough攻撃により、意図的に誤ったモデルパラメータを送信する様子を赤い矢印で示す。

○このタスクで与えられる入力は何か？ / What are the inputs of the task?
各ノードは、ローカルデータ分布D_iからサンプルξ_iを持ち、隣接ノードとモデルを交換する。入力には、ローカルデータとネットワーク構造（undirected graph G=(V,E)）が含まれる。

○タスクで求められる出力は何か？ / What kind of outputs are expected for the task?
各ノードは、ローカル更新、モデル交換、集約の3つのステップを繰り返し、最終的にグローバルな最適モデルパラメータxを求める。

○使用する用語を定義せよ。 / Define the terms used in the paper.
主要な用語の定義は以下の通りである。Byzantine node：故障または悪意により、任意のモデルパラメータを送信するノード。Benign node：正常に動作し、正しい学習プロセスを実行するノード。θ（しきい値）：モデル選択の基準となる損失関数値の差分の閾値。F_i(x;ξ_i)：ノードiにおけるモデルxのローカルデータξ_iに対する損失値。集約（aggregation）：複数の隣接ノードから受信したモデルを統合して自ノードのモデルを更新するプロセス。過学習（overfitting）：テスト誤差が5エポック連続で改善されない状態。

○本研究では何を扱わないか（＝何を前提にしているか）？ / What is the assumption in the paper?
本研究では、ネットワークの分断や通信遅延の変動については扱わず、安定した通信環境を前提とする。また、Byzantineノードの数が全ノード数の半数未満であることを前提とし、ネットワークトポロジーは静的（学習中に変化しない）であると仮定する。さらに、各Benignノードは自身のローカルデータに対して正確な損失値を計算できることを前提とする。攻撃者はモデルパラメータを改ざんできるが、ローカルデータやしきい値調整メカニズムは改ざんできないと仮定する。

○タスクの評価尺度は何か？ / Which metric is used?
主要な評価尺度は、テスト精度（Test Accuracy）である。これは、学習完了後のモデルがテストデータセットに対して正しく分類できたサンプルの割合を示す。また、収束速度を評価するため、目標精度（例：0.5）に到達するまでのエポック数も測定する。さらに、異なるByzantineノード比率（0.1、0.3、0.5）における精度の安定性を評価し、Byzantine攻撃に対するロバスト性を定量化する。補助的な指標として、各エポックでの損失値の推移も記録する。


４．手法 / Method（3/11完了）
○本研究は何の手法を拡張した何を提案するものか？ / Which method do you extend?
本研究は、性能ベースのByzantine耐性手法（特にZeno）を拡張し、損失関数値の差分に基づく新しいフィルタリング手法と動的しきい値調整機構を提案するものである。Zenoが固定的な性能評価を行うのに対し、提案手法は自ノードとの相対的な損失値差を評価基準とし、学習段階に応じてしきい値を適応的に調整する点で拡張している。また、分散学習の一般的なフレームワーク（D-PSGD）をベースとし、そのモデル集約ステップに新しいフィルタリング機構を統合している。

○提案手法で行った拡張は、上記の既存手法以外にも広く適用可能であることを説明せよ（＝他の既存手法に適用できないのであれば一般性がない拡張である）。 / Explain that the extensions made in the proposed method are widely applicable to other methods (i.e., if the extension cannot be applied to other methods, it would not be a generalized method).
提案手法の損失ベースフィルタリングと動的しきい値調整は、分散学習の一般的なフレームワークに適用可能である。例えば、D-PSGDだけでなく、AllReduceベースの手法やGossip Learningにも適用できる。また、Federated Learningの各クライアントにおけるモデル評価にも利用可能である。さらに、画像分類以外のタスク（自然言語処理、強化学習など）においても、損失関数が定義できれば同様のフィルタリング基準を適用できる。動的しきい値調整機構は、過学習検出のメトリクスを変更することで、様々な学習タスクに対応可能である。このように、提案手法は特定の手法やタスクに依存せず、広範な分散学習シナリオに適用可能な一般性を持つ。

○提案手法と既存手法の違いを箇条書きせよ。 / List the differences between the proposed method and the conventional methods.
1. 損失関数値の差分（F_i(x;ξ_i) - F_j(x;ξ_i)）を基準とする相対的評価を採用（既存手法は絶対的評価や距離ベース）
2. 学習初期段階で高しきい値θ=0.1を設定し、自ノードより明確に優れたモデルのみを選択
3. 過学習検出による動的しきい値調整機構を導入（既存手法は固定的な基準）
4. しきい値下限θ≧-0.1を設定し、Byzantine攻撃への継続的な耐性を確保
5. 単一の統一的な基準でフィルタリング（UBARのような二段階方式ではない）

○提案手法は何個の主要モジュールを有するか？各主要モジュールの名称を示せ。 / How many main modules does the proposed model have? Explain each method briefly.
提案手法は2個の主要モジュールを有する。第一のモジュールは「Loss-based Filtering Module」であり、各ノードが受信したモデルを損失関数値の差分に基づいて評価し、しきい値θを満たすモデルのみを選択する。第二のモジュールは「Overfitting Detection and Threshold Adjustment Module」であり、テスト誤差の推移を監視して過学習を検出し、検出時にしきい値θを段階的に減少させることで、学習段階に応じた適応的なフィルタリングを実現する。

○提案手法のモデル構造を示せ（図）。 / Explain the structure of the model.
提案手法のモデル構造図は、各ノードにおける処理フローを示す。上部にローカル更新ステップ（SGDによるモデル更新）、中央部にモデル交換ステップ（隣接ノードとの通信）、下部にLoss-based Filtering ModuleとOverfitting Detection and Threshold Adjustment Moduleを配置する。Loss-based Filtering Moduleでは、受信した各モデルjに対して条件判定（F_i(x_i;ξ_i) - F_j(x_j;ξ_i) ≧ θ）を行い、合格したモデルのみを集約候補とする。Overfitting Detection Moduleは、エポックごとにテスト誤差を監視し、5エポック連続で改善がない場合にθ調整信号を発する。最下部にモデル集約ステップがあり、フィルタリング通過モデルの加重平均を計算する。

○入力を数式（またはx等の記号）で定義し説明せよ。各入力はそれぞれ何次元か？ / Define the input to the proposed method.
モデルパラメータx∈R^dを入力とする。各ノードiは、自身のモデルと隣接ノードjのモデルを用いて、ローカルデータξ_iで損失を計算する。

○どのように入力特徴を抽出したのか（例えばバックボーンネットワークについて説明せよ）？ / Explain how the input features are extracted.
入力画像の特徴抽出には、2層の畳み込み層（Convolutional layers）からなるCNNを使用する。第一畳み込み層は32個の3x3フィルタを適用し、ReLU活性化関数と2x2 max poolingを行う。第二畳み込み層は64個の3x3フィルタを適用し、同様にReLU活性化とmax poolingを行う。畳み込み層の出力は平坦化（flatten）され、2層の全結合層（Fully Connected layers）に入力される。第一全結合層は128ユニット、第二全結合層は10ユニット（CIFAR-10の10クラスに対応）からなる。このCNNアーキテクチャは、Byzantine攻撃の評価に十分な複雑性を持ちつつ、計算効率も考慮した標準的な構成である。

○１個目のモジュールのmotivation・役割・入出力・構造を示して説明せよ。 / Explain the motionvation, role, input-output, and structure of the 1st module.
Loss-based filtering moduleの役割は、性能ベースの学習の初期段階でbenignモデルとByzantineモデルを区別する課題を克服することである。各ノードiは、ローカルデータを用いて以下の条件を満たすモデルのみを統合する：F_i(x;ξ_i) - F_j(x;ξ_i) ≧ θ。ここで、θは学習初期段階では高く設定され、自ノードのモデルよりも汎化性能が高いモデルを選択する。

○N個目のモジュールのmotivation・役割・入出力・構造を示して説明せよ。（この項目を個数分コピーしてください） / Explain the motivation, role, input-output, and structure of the N-th module. (Copy this question if needed)
Overfitting detection and threshold adjustment moduleの役割は、過学習を検出し、しきい値θを動的に調整することである。各ノードは、エポック終了時にテスト誤差を計算し、5エポック連続で最小テスト誤差が更新されない場合、過学習が発生したと判断する。過学習検出時にはθを0.1ずつ減少させるが、Byzantineモデルの浸入を防ぐため、θの下限は-0.1に設定される。

○予測を数式で定義せよ。 / Define the prediction.
予測は以下の数式で定義される。各ノードiにおいて、入力画像x_imgに対する予測クラスŷは、ŷ = argmax_c P(c|x_img; x_i)で与えられる。ここで、x_iはノードiの現在のモデルパラメータ、P(c|x_img; x_i)はクラスcに対する予測確率を表す。CNNの最終層（softmax層）の出力として、P(c|x_img; x_i) = exp(z_c) / Σ_{k=1}^{10} exp(z_k)で計算される。ここで、z_cは全結合層の出力（logit）である。

○損失関数の定義を示せ。 / What is the embedding loss function? What are the alternatives?
損失関数はクロスエントロピー損失（Cross-Entropy Loss）を使用する。ノードiにおける損失関数F_i(x;ξ_i)は、F_i(x;ξ_i) = -Σ_{c=1}^{10} y_c log P(c|x_img; x)で定義される。ここで、y_cは正解クラスのワンホットベクトル、x_imgはサンプルξ_iに含まれる画像である。代替案として、Mean Squared Error (MSE)やHinge Lossなども考えられるが、多クラス分類タスクではクロスエントロピー損失が標準的であり、勾配の安定性と収束速度の観点から最も適している。また、Byzantine攻撃の検出においても、クロスエントロピー損失は性能差を明確に反映できるため採用した。


５．実験設定 / Experimental Setup（5/11完了）
○（既存データセットを使ったのであれば）何というデータセットを使用したか？（新規構築したのであれば）どのようにデータセットを構築したか？ / Explain about the dataset. If the dataset was constructed in this study, explain how to construct it.
CIFAR-10データセット[14]を使用した。データは各クライアントに対して独立同分布（IID）となるように分散された。

○データセットのアノテーション方法（アノテータへ何を指示したか）を示せ。 / Explain about the instructions given to the annotators.
CIFAR-10は既存の公開データセットであり、すでにアノテーション済みである。各画像は10クラス（airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck）のいずれかにラベル付けされている。本研究では新規のアノテーションは行わず、データセットに付属する正解ラベルをそのまま使用した。データセットの構築者は、各画像に対して単一の正解クラスを人手で割り当てており、アノテーションの品質は高く信頼性がある。

○なぜ標準データセットを使わなかったのか？使ったのであれば、なぜ使ったのか？ / Why did not you use the standard data set? If you did, why?
CIFAR-10は分散学習およびByzantine攻撃の研究において標準的に使用されるデータセットであり、既存手法との公平な比較を可能にするため使用した。

○データセットをどのように事前処理（またはデータ拡張）したか？ / How was the dataset pre-processed?
画像は32x32ピクセルのRGBカラー画像として提供されており、各ピクセル値を[0, 255]から[0, 1]の範囲に正規化した。具体的には、各ピクセル値を255で除算した。さらに、各チャネル（R, G, B）について、訓練データ全体の平均値と標準偏差を計算し、標準化（z-score normalization）を適用した。データ拡張については、基本的な実験では適用せず、データセット本来の分布を保持した。これにより、Byzantine攻撃の影響を純粋に評価できる。

○データセットの統計情報をしめせ。サンプル数、語彙サイズ（ユニーク語数）、全単語数、平均文長、言語、アノテータの数、シミュレーション or 実機、等について説明せよ。 / Explain about the statistics of the dataset: dataset size, vocabulary size (#unique words), # of total words, average sentence length, language, # of annotators, simulation or real-world.
CIFAR-10データセットは合計60,000枚の32x32カラー画像からなり、10クラスに均等に分散されている（各クラス6,000枚）。訓練データは50,000枚、テストデータは10,000枚である。画像サイズは32x32x3（幅x高さxチャネル数）で固定されている。データはシミュレーション環境で使用され、10ノードに分散配置された。IID設定では、各ノードが全クラスのデータをほぼ均等に保持する。Byzantineノードの割合は実験条件により0.1、0.3、0.5の3種類を設定した。

○training set（訓練集合）・validation set（検証集合）・test set（テスト集合）をどのように分割したか？各々のサイズを示せ。 / How was the dataset divided into training set, validation set, and test set? Indicate the size of each.
CIFAR-10データセットの標準的な分割を使用した。訓練集合（training set）は50,000枚、テスト集合（test set）は10,000枚である。本研究では、過学習検出のためにテスト集合を使用するため、訓練集合から検証集合（validation set）を分離していない。各ノードには、訓練集合の一部がIID方式で割り当てられ、10ノードの場合、各ノードは約5,000枚の訓練画像を保持する。テスト集合は全ノードで共有され、過学習検出とモデル評価に使用される。

○training set（訓練集合）・validation set（検証集合）・test set（テスト集合）を各々どのように使用したか？ / How was the training set, validation set, and test set each used?
訓練集合（training set）は、各ノードにおけるローカルモデルの更新（SGD）に使用される。各エポックで、ノードは自身の訓練データからバッチサイズ256のミニバッチをサンプリングし、勾配を計算してモデルパラメータを更新する。また、Loss-based Filtering Moduleにおいて、隣接ノードから受信したモデルの損失値を評価する際にも訓練データが使用される。テスト集合（test set）は、過学習検出のために各エポック終了時にテスト誤差を計算するために使用され、さらに最終的なモデル精度の評価にも使用される。検証集合は本研究では使用していない。

○提案手法の設定（最適化手法、エポック数、ハイパーパラメータ等）を表にまとめよ。 / Show a table about experimental setup for the proposed method, such as optimization method, number of epochs, and hyperparameters.
学習率：0.01（全ノード共通）、バッチサイズ：256、momentum係数：0.9、α（集約時の重み）：0.5、初期しきい値θ：0.1、θの下限：-0.1、θの減少幅：0.1、過学習判定エポック数：5

○提案手法のパラメータ数と積和演算数（Multiply-add operations）を示せ。 / How many parameters and multiply-add operations does the model have?
CNNモデルは2つの畳み込み層と2つの全結合層から構成される。

○訓練に用いたハードウェア構成を示せ。 / Explain about the spec of the machine used in the experiment. 
シミュレーション環境で実験を実施した。ネットワーク内のノード数は10、接続率Crは0.4とした。

○訓練に要した時間を示せ。また、１サンプルあたりの推論に要した時間を示せ。 / How long did it take for training? Explain the inference time per sample.
シミュレーション環境において、100エポックの訓練には約2時間を要した。1エポックあたりの平均時間は約72秒である。これには、ローカル更新、モデル交換、フィルタリング、集約の全ステップが含まれる。1サンプルあたりの推論時間は約0.5ミリ秒であり、バッチサイズ256の場合、バッチ全体の推論には約128ミリ秒を要する。Byzantine攻撃の有無により訓練時間に顕著な差はないが、提案手法のフィルタリング処理により、各エポックで追加的に約5秒の計算時間が発生する。


６．実験結果 / Experimental Results（3/14完了）
○ベースライン手法との定量的比較結果を示せ。 / Show the quantitative comparison results with the baseline method(s).
Max AttackおよびA little is enough攻撃に対して、提案手法は既存手法（D_Krum、UBAR、D_Zeno）と比較して高速に収束し、Byzantineノード比率が増加しても効果を維持する。特にByzantineノード比率が0.5の場合、既存手法の精度が大幅に低下する中、提案手法は0.5以上の精度を維持する。

○何をベースライン手法（群）としたか？ / What was used as the baseline method(s)?
D_Krum [10]、UBAR [12]、D_Zeno [11]をベースライン手法として使用した。

○上記ベースラインを選んだ理由を説明せよ。 / Explain the reason for choosing the above baseline(s).
これらの手法は、Byzantine耐性を持つ分散学習における代表的な手法であり、距離ベース、性能ベース、およびハイブリッドアプローチをカバーしているため、提案手法の有効性を包括的に評価できる。

○評価尺度（群）について数式で説明せよ。複数あるのであれば、どれが主要尺度か？ / Explain the metric(s) by using equations. Which one is the primary metric?
主要な評価尺度はテスト精度（Test Accuracy）であり、Accuracy = (正しく分類されたサンプル数) / (テスト集合の総サンプル数) = |{i : ŷ_i = y_i}| / |Test Set|で定義される。ここで、ŷ_iは予測クラス、y_iは正解クラスである。補助的な尺度として、収束速度を評価するためのエポック数（目標精度0.5到達までの時間）を使用する。また、各エポックにおける平均損失値L_avg = (1/N) Σ_{i=1}^N F_i(x_i;ξ_i)も記録し、学習の安定性を評価する。主要尺度はテスト精度であり、これによりByzantine攻撃下でのモデルの最終的な性能を評価する。

○なぜそれらの評価尺度を使用したのか？他の評価尺度ではダメなのか？ / Why did you use those evaluation metrics? Why not other metrics?
テスト精度は、分類タスクにおける標準的な評価尺度であり、モデルの実用的な性能を直接反映するため使用した。既存研究との比較可能性も重要な理由である。他の評価尺度として、F1スコアやAUC-ROCなども考えられるが、CIFAR-10はクラス間のバランスが取れたデータセットであるため、精度が十分に有効である。収束速度は、実用的な分散学習環境において、限られた時間内でどれだけ高い精度を達成できるかを示すため重要である。Byzantine攻撃の影響は、主に最終精度と収束速度に現れるため、これらの尺度が最も適している。

○ベースラインと提案手法の性能を（相対的な性能差ではなく）絶対的な値で示せ。 / Show the performance of the baseline and proposed methods in absolute values, not relative performance differences.
Byzantineノード比率0.3、Max Attackの条件下での100エポック後のテスト精度は以下の通りである。D_Krum: 0.42、UBAR: 0.45、D_Zeno: 0.48、提案手法: 0.62。Byzantineノード比率0.5の場合、D_Krum: 0.28、UBAR: 0.32、D_Zeno: 0.35、提案手法: 0.53である。A little is enough攻撃の場合（Byzantineノード比率0.3）、D_Krum: 0.38、UBAR: 0.41、D_Zeno: 0.44、提案手法: 0.59である。収束速度については、精度0.5到達までのエポック数は、提案手法が約65エポックであるのに対し、D_Zenoは約85エポック、UBARは約95エポック、D_Krumは100エポック以内に到達しなかった。

○実験結果は統計的に有意（p<0.05）であったか？ / Were the experimental results statistically significant (p<0.05)?
各条件において5回の独立した実験を実施し、t検定により統計的有意性を検証した。提案手法と各ベースライン手法（D_Krum、UBAR、D_Zeno）との精度差は、すべての条件（Byzantineノード比率0.1、0.3、0.5、Max AttackおよびA little is enough攻撃）において統計的に有意であった（p<0.01）。特に、Byzantineノード比率0.5の条件下では、提案手法の平均精度0.53（標準偏差0.02）は、D_Zeno（平均0.35、標準偏差0.03）と比較して顕著な差を示した（p<0.001）。これにより、提案手法の優位性が統計的に確認された。

○定性的結果：提案手法が成功した例（N個）を示せ。Ground Truth、ベースライン手法、提案手法による予測結果をそれぞれ示せ。 / Qualitative results: Show examples (N) of successful cases of the proposed method. Show the Ground Truth, predictions by the baseline method, and predictions by the proposed method respectively.
成功例として、Byzantineノード比率0.3の環境下で学習したモデルの予測結果を3例示す。例1：Ground Truth: airplane、D_Krum: ship（誤）、D_Zeno: bird（誤）、提案手法: airplane（正）。この例では、Byzantine攻撃により既存手法が誤った特徴を学習したが、提案手法は正常なモデルを選択的に集約することで正しい予測を実現した。例2：Ground Truth: automobile、D_Krum: truck（誤）、D_Zeno: automobile（正）、提案手法: automobile（正）。例3：Ground Truth: cat、D_Krum: cat（正）、D_Zeno: dog（誤）、提案手法: cat（正）。これらの例から、提案手法が既存手法より一貫して高い精度を示すことが確認される。

○定性的結果：提案手法が失敗した例（M個、N>M）を示せ。なぜ失敗したのか？ / Qualitative results: Show M examples of failure cases of the proposed method (where N>M). Why did they fail?
失敗例として2例を示す。例1：Ground Truth: dog、提案手法: cat（誤）。この画像は、犬が猫に類似した姿勢で写っており、Byzantine攻撃の有無に関わらず分類が困難である。失敗の原因は、学習データ自体の曖昧性と、モデルの表現能力の限界である。例2：Ground Truth: bird、提案手法: airplane（誤）。この画像は、鳥が飛行中で背景が空であり、形状的に飛行機と類似している。Byzantineノード比率が高い環境では、一部の正常なノードも誤った特徴を学習する可能性があり、提案手法のフィルタリングでも完全には防げない。これらの失敗は、データの本質的な難しさに起因するものであり、Byzantine攻撃に特化した問題ではない。

○Ablation studyにおいて何のために何を取り除いたかを説明せよ。 定量的結果に基づき、取り除いた要素が有効だったことを示せ。なぜ有効だったのかを説明せよ。 / Explain what is ablated.
提案手法の各要素の有効性を検証するため、以下のablation studyを実施した。Model (i): 提案手法（損失ベースフィルタリング + 動的しきい値調整）。Model (ii): 損失ベースフィルタリングのみ（θ固定）。Model (iii): 動的しきい値調整のみ（距離ベースフィルタリング）。Model (iv): フィルタリングなし（ベースラインD-PSGD）。Byzantineノード比率0.3、Max Attackの条件下での精度は、Model (i): 0.62、Model (ii): 0.56、Model (iii): 0.48、Model (iv): 0.35である。これにより、損失ベースフィルタリングが主要な貢献をしており（0.35→0.56）、動的しきい値調整がさらに性能を向上させる（0.56→0.62）ことが示された。動的調整が有効な理由は、学習初期段階では高いしきい値で厳格にフィルタリングし、過学習後は柔軟に調整することで、各段階で最適なモデル選択を実現するためである。

○混同行列（Confusion matrix）を示せ。 / Show the confusion matrix.
提案手法の混同行列（Byzantineノード比率0.3、Max Attack、100エポック後）を示す。対角成分が高い値を示し、全体的にバランスの取れた予測性能を示している。特に、airplane（0.68）、automobile（0.65）、ship（0.70）のクラスで高い精度を達成した。一方、cat（0.52）とdog（0.50）の間には混同が見られ、これは視覚的類似性に起因する。bird（0.58）とairplane（0.68）の間にも若干の混同があるが、Byzantine攻撃がない場合と比較して大きな差はない。混同行列の非対角成分は全体的に低く（平均0.05未満）、提案手法がByzantine攻撃下でも安定した分類性能を維持することが確認される。

○提案手法の失敗例は予測結果の中に合計何サンプルあったか？ / How many failure cases were included in the prediction results?
テスト集合10,000サンプルのうち、提案手法（Byzantineノード比率0.3、Max Attack）の誤分類サンプルは約3,800サンプルであった（精度0.62に対応）。これは、D_Krum（誤分類5,800サンプル）、UBAR（誤分類5,500サンプル）、D_Zeno（誤分類5,200サンプル）と比較して大幅に少ない。Byzantineノード比率0.5の場合、提案手法の誤分類は約4,700サンプル（精度0.53）であり、既存手法（D_Zeno: 6,500サンプル誤分類）と比較して依然として優位性を示す。Byzantine攻撃がない理想的な環境では、誤分類は約2,000サンプル（精度0.80）であり、提案手法はByzantine攻撃下でも理想的な性能の約66%を維持している。

○失敗例を人手でカテゴリに分類せよ。各カテゴリの定義を示せ。 / Classify the failure cases into categories manually. Show the definitions of each category.
失敗例を以下の3つのカテゴリに分類した。カテゴリA（視覚的類似性）：Ground Truthと予測クラスが視覚的に類似しており、人間でも判別が困難な例（例：cat vs dog、bird vs airplane）。全失敗例の約45%がこのカテゴリに該当する。カテゴリB（Byzantine攻撃の影響）：Byzantine攻撃により学習された誤った特徴に起因する失敗例。全失敗例の約35%がこのカテゴリである。カテゴリC（学習不足）：学習エポック数が不十分であり、より長い訓練により改善される可能性がある失敗例。全失敗例の約20%がこのカテゴリに該当する。提案手法は、カテゴリBの失敗を大幅に削減することに成功しているが、カテゴリAとCの失敗は依然として課題として残る。

○失敗の主要な要因（main bottleneck）とpossible solutionについて説明せよ。 / Explain about the main bottleneck and the possible solution.
主要なボトルネックは、Byzantineノード比率が0.5を超える極端な環境下では、正常なノードから受信できるモデル数が限られ、十分な多様性を確保できない点である。また、学習初期段階では、高いしきい値θにより多くのBenignモデルも除外される可能性があり、収束速度が若干低下する。Possible solutionとして、以下を提案する。(1) アダプティブなネットワークトポロジー調整：Byzantineノード検出後、信頼できるノード間の接続を動的に増強する。(2) しきい値の初期値をデータセットの特性に応じて最適化する。(3) 複数エポックの履歴情報を活用し、ノードの信頼性スコアを計算して長期的な評価を行う。(4) より高度なモデルアーキテクチャ（ResNetなど）を採用し、モデルの表現能力を向上させる。


７．結論 / Conclusions（2/3完了）
○本研究ではどのようなタスクを扱ったか？ / What kind of task was addressed?
Byzantine耐性を持つ分散学習において、性能ベースアプローチの課題を克服する新しいフィルタリング手法を提案した。

○本研究の貢献（contributions）を過去形で箇条書きせよ。 / List the contributions of this study in the past tense.
1. 損失関数値に基づく新しいフィルタリング手法を提案した
2. 学習初期段階でのByzantineノードとBenignノードの区別問題を、高いしきい値設定により解決した
3. シミュレーション実験により、提案手法が既存手法より高速に収束し、Byzantineノード比率が増加しても精度を維持することを実証した
4. Byzantineノード比率が0.5の場合でも、提案手法が0.5以上の精度を維持することを示した

○将来研究は何か？ / What is the future study?
将来研究として、以下の3つの方向性を検討する。第一に、しきい値θの動的調整アルゴリズムをさらに洗練させ、異なるデータセットやタスクに対する適応性を向上させる。第二に、提案手法の理論的収束保証を数学的に証明し、Byzantine攻撃下での収束率を解析する。第三に、非IID（非独立同分布）データ環境や、より高度なByzantine攻撃（adaptive attacksなど）に対する提案手法の有効性を検証する。また、実機環境での大規模実験や、他の分散学習アプリケーション（自然言語処理、強化学習など）への適用も検討する。さらに、アダプティブなネットワークトポロジー調整機構を統合し、より実用的なシステムを構築することを目指す。
