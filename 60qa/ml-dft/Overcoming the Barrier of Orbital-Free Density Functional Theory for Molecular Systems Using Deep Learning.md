# 60QA for "Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning"

## 1. Introduction (0/10 completed)

### Question 1. What is the social background of this research?

Density functional theory (DFT) is a powerful quantum chemistry method that has become one of the most popular computational approaches for solving electronic states and determining the energy and properties of molecular systems. Its widespread adoption stems from providing an appropriate balance between accuracy and computational efficiency, which has enabled numerous scientific discoveries across chemistry, materials science, and related fields. The prevailing Kohn-Sham DFT (KSDFT) formulation, while highly successful, requires optimizing N orbital functions for an N-electron system, resulting in computational complexity that scales as O(N³). This higher complexity is increasingly problematic for contemporary research where large-scale system simulations are in high demand for practical applications. The computational burden limits the ability to study larger molecules, proteins, and complex molecular systems that are crucial for understanding real-world phenomena in drug discovery, materials design, and biological processes. Consequently, there is growing interest in orbital-free DFT (OFDFT), which follows the original spirit of DFT by optimizing a single electron density function rather than multiple orbital functions, thereby reducing computational complexity to O(N²). However, OFDFT's accuracy has been limited by the challenge of approximating the kinetic energy density functional, particularly for non-periodic molecular systems where electron density is highly non-uniform. Recent advances in machine learning, especially deep learning, present new opportunities to overcome this accuracy barrier by learning complex functional approximations from data, potentially enabling efficient and accurate quantum chemistry calculations for large-scale molecular systems.

**Technical Terms:**
- **Density Functional Theory (DFT)**: A quantum mechanical method for calculating the electronic structure of many-body systems by using electron density rather than wave functions as the fundamental variable.
- **Kohn-Sham DFT (KSDFT)**: The prevailing formulation of DFT that represents the system using N orbital functions for N electrons, allowing explicit calculation of non-interacting kinetic energy.
- **Orbital-Free DFT (OFDFT)**: An alternative DFT formulation that optimizes only the electron density function, eliminating the need to compute individual orbitals and reducing computational complexity.
- **Electron Density (ρ(r))**: The probability distribution of electrons in space, representing the one-body reduced density.
- **Kinetic Energy Density Functional (KEDF)**: The functional that approximates the non-interacting kinetic energy of electrons as a function of electron density, denoted as T_S[ρ].
- **Computational Complexity Scaling**: The relationship between system size (N electrons) and computational cost; O(N³) for KSDFT versus O(N²) for OFDFT.
- **Non-periodic Molecular Systems**: Molecules that lack the repeating lattice structure found in crystalline materials, making them more challenging for OFDFT approximations.

### Question 2. What is the target problem of this work?

The target problem of this research is to develop an accurate and computationally efficient orbital-free density functional theory (OFDFT) method capable of solving molecular systems, particularly non-periodic molecules that have traditionally been beyond the reach of OFDFT approaches. The core challenge lies in approximating the kinetic energy density functional (KEDF), denoted as T_S[ρ], which is the central task in OFDFT. Classical approximations for KEDF, developed based on uniform electron gas theory, have achieved success for periodic material systems but remain highly inaccurate for molecular systems where electron density is far from uniform. The problem is further complicated by the need to capture non-local interactions of electron density at different spatial points, which is essential for accurate KEDF approximation but computationally prohibitive with traditional grid-based density representations. The research addresses the fundamental tension between accuracy and computational efficiency in quantum chemistry: while Kohn-Sham DFT provides good accuracy, it scales as O(N³) which becomes prohibitive for large molecular systems; OFDFT offers better O(N²) scaling but lacks sufficient accuracy for molecules. This work aims to overcome the accuracy barrier of OFDFT for molecular systems by using deep learning to approximate the KEDF, while maintaining the computational scaling advantage that makes OFDFT attractive for studying large-scale molecular systems including proteins and other complex biomolecular structures.

**Technical Terms:**
- **Kinetic Energy Density Functional (KEDF)**: A functional T_S[ρ] that approximates the non-interacting kinetic energy of electrons as a function of electron density, which is the central approximation challenge in OFDFT.
- **Uniform Electron Gas Theory**: A theoretical framework assuming electrons are distributed uniformly in space, which forms the basis for classical KEDF approximations but fails for molecular systems.
- **Non-local Interactions**: Interactions between electron density at spatially separated points, which require considering density values across the entire molecular system rather than just local neighborhoods.
- **Grid-based Density Representation**: A method of representing electron density by discretizing space into a grid and storing density values at grid points, which requires many points (~10⁴N) for molecular systems.
- **Computational Scaling**: The relationship between system size and computational cost; O(N³) means cost increases with the cube of system size, while O(N²) means quadratic increase.

### Question 3. Explain a typical use case.

A typical use case for M-OFDFT is calculating the ground-state electronic properties of large molecular systems, such as proteins, where traditional Kohn-Sham DFT becomes computationally prohibitive. For example, the research demonstrates M-OFDFT's application to chignolin, a small protein consisting of 10 residues and 168 atoms after neutralization. In this scenario, researchers need to determine the electronic energy, electron density distribution, and forces on atoms for conformational analysis or molecular dynamics simulations. The workflow begins with a molecular structure M defined by atomic coordinates and atomic numbers. Using a pre-trained deep learning KEDF model, M-OFDFT optimizes the electron density represented as expansion coefficients p under an atomic basis set to minimize the total electronic energy. Through iterative gradient descent optimization constrained to maintain normalized density, the method converges to the ground-state density and energy. The optimized density reveals the shell structure around atoms and provides accurate energies comparable to Kohn-Sham DFT but with significantly reduced computational cost. Another typical use case involves studying conformational spaces, such as analyzing ethanol structures from molecular dynamics trajectories. Here, M-OFDFT can rapidly evaluate energies and forces for thousands of molecular conformations to understand relative stability and dynamics. The method is particularly valuable when extrapolating to molecules much larger than those in the training set, such as calculating properties of molecules with 224 atoms when trained only on molecules up to 15 heavy atoms, enabling large-scale molecular simulations previously unaffordable with conventional quantum chemistry methods.

**Technical Terms:**
- **Ground-state Electronic Properties**: The lowest energy electronic configuration and associated properties like density and forces when all electrons occupy their most stable quantum states.
- **Conformational Analysis**: The study of different three-dimensional arrangements (conformations) of a molecule and their relative energies and properties.
- **Molecular Dynamics Simulations**: Computational simulations that model the time-dependent motion of atoms in molecules by calculating forces and updating positions iteratively.
- **Atomic Basis Set**: A set of mathematical functions {ω_μ(r)} centered on atoms used to represent electron density as a linear combination, where each function describes electron distribution patterns around atoms.
- **Expansion Coefficients**: The numerical weights p_μ in the linear combination ρ(r) = Σ_μ p_μ ω_μ(r) that determine how much each basis function contributes to the total electron density.
- **Shell Structure**: The organization of electron density into concentric shells around atomic nuclei, with core electrons close to the nucleus and valence electrons in outer shells.
- **Heavy Atoms**: Non-hydrogen atoms in a molecule, which typically determine molecular size complexity in quantum chemistry calculations.

### Question 4. Why is this task challenging?

This task is fundamentally challenging because approximating the kinetic energy density functional (KEDF) for molecular systems requires capturing the complex, non-uniform distribution of electron density in molecules, which differs dramatically from the uniform electron gas assumptions underlying classical KEDF approximations. The electron density in molecules exhibits sharp variations near atomic nuclei due to the nuclear cusp condition, forms shell structures around atoms, and involves covalent bonding regions where density is shared between atoms—all features that classical KEDFs based on uniform or slowly-varying density assumptions fail to capture accurately. The challenge is amplified by the essential requirement of non-locality in KEDF approximation, meaning the kinetic energy at any point depends on electron density at distant spatial locations, not just the immediate neighborhood. Incorporating non-locality is computationally expensive, especially with grid-based density representations that require approximately 10⁴N grid points for N-electron molecular systems, making non-local calculations prohibitively costly. Furthermore, the task involves unconventional machine learning challenges beyond standard supervised learning. The KEDF model serves as an optimization objective rather than a direct prediction function, requiring it to accurately capture the entire energy landscape over the space of possible density configurations for each molecular structure, not just at a single ground-state point. This necessitates generating multiple density datapoints with gradient labels for each molecular structure during training. Additionally, the model must respect geometric invariance—the output kinetic energy must remain unchanged under molecular rotation while the input density coefficients transform equivariantly. Finally, achieving meaningful extrapolation to molecules much larger than training data is critical but difficult, as the ground-state energy involves intricate many-body interactions among electrons and nuclei, creating a highly complex function that typically fails to generalize well across different molecular scales without appropriate problem formulation.

**Technical Terms:**
- **Nuclear Cusp Condition**: A physical constraint requiring electron density to exhibit a specific sharp increase (cusp) at nuclear positions, following the relationship ∂ρ/∂r|_{r→0} = -2Zρ(0) where Z is the atomic number.
- **Covalent Bonding Regions**: Spatial regions between atoms where electron density is shared and accumulated due to chemical bond formation, characterized by non-uniform density distributions.
- **Energy Landscape**: The multidimensional surface representing how total energy varies as a function of all possible density configurations, which the optimization process must navigate to find the minimum.
- **Gradient Labels**: The partial derivatives ∇_p E with respect to density coefficients p, which indicate the direction and magnitude of energy change and are essential for training the model to support gradient-based optimization.
- **Geometric Invariance**: The physical requirement that predicted energies remain unchanged (invariant) under spatial transformations like rotation, while input density representations transform accordingly (equivariantly).
- **Many-body Interactions**: Complex quantum mechanical interactions among multiple particles (electrons and nuclei) that cannot be decomposed into simple pairwise interactions, making the total energy a highly non-linear function.
- **Equivariant Transformation**: A property where the representation of an object transforms in a specific, predictable way under symmetry operations (like rotation), maintaining consistency with the physical transformation.

### Question 5. Why are conventional studies insufficient?

Conventional studies are insufficient because classical orbital-free DFT approaches, while computationally efficient, fail to achieve chemical accuracy for molecular systems, and previous machine learning attempts have been limited in scope and extrapolation capability. Classical KEDF approximations such as Thomas-Fermi (TF), von Weizsäcker (vW), and various gradient expansion corrections were developed based on uniform electron gas theory and have achieved successes for periodic material systems with relatively uniform electron density. However, these methods produce energy errors orders of magnitude larger than the chemical accuracy threshold (1 kcal/mol) for molecules because molecular electron density is highly non-uniform, featuring sharp nuclear cusps, shell structures, and covalent bonding regions that violate the slowly-varying density assumptions. Early machine learning approaches using kernel ridge regression showed promise only for one-dimensional systems, lacking the scalability needed for three-dimensional molecular applications. More recent deep learning approaches have explored learning point-wise kinetic energy density from electron density features, but these semi-local methods cannot capture the essential non-local interactions required for accurate KEDF approximation. Other works attempting to incorporate non-locality using grid-based density representations face prohibitive computational costs, limiting applications to systems with only dozens of atoms—far too small to demonstrate the scaling advantage that motivates OFDFT development. Neural network potentials (NNPs) that predict ground-state energy end-to-end from molecular structure offer fast predictions but do not describe electronic states and suffer from poor extrapolation to larger molecules than those in training data. Critically, few previous studies have demonstrated accurate extrapolation well beyond training molecule sizes, which is essential for exploiting OFDFT's computational scaling benefits. Without good extrapolation, the method cannot be applied to the large-scale molecular systems for which OFDFT's efficiency advantage would be most valuable, undermining the entire motivation for using orbital-free approaches over the more accurate Kohn-Sham DFT.

**Technical Terms:**
- **Chemical Accuracy**: A threshold of approximately 1 kcal/mol (or 1.6 milli-Hartrees) for energy prediction errors, considered sufficient for reliable prediction of chemical properties and reaction energetics.
- **Gradient Expansion**: A mathematical approximation technique that expresses the KEDF as a series of terms involving the electron density and its spatial derivatives (gradients, Laplacians, etc.).
- **Thomas-Fermi (TF) KEDF**: The simplest classical kinetic energy approximation proportional to ρ^(5/3), exact for uniform electron gas but highly inaccurate for molecular systems.
- **von Weizsäcker (vW) KEDF**: A gradient correction to TF that captures some kinetic energy contributions from density variations, proportional to |∇ρ|²/ρ.
- **Kernel Ridge Regression**: A non-parametric machine learning method that learns functions by finding optimal weights for training points in a high-dimensional feature space defined by a kernel function.
- **Point-wise Kinetic Energy Density**: The kinetic energy per unit volume at each spatial location, whose integral over space gives the total kinetic energy.
- **Neural Network Potentials (NNPs)**: Machine learning models that directly predict ground-state energy from atomic positions and types without explicitly modeling electron density or electronic structure.

### Question 6. What is proposed and solved in this study?

This study proposes M-OFDFT (Molecular Orbital-Free Density Functional Theory), a novel OFDFT approach that uses a deep learning model to approximate the kinetic energy density functional, enabling accurate quantum chemistry calculations for molecular systems while maintaining computational efficiency. The key innovation is representing electron density using expansion coefficients under an atomic basis set rather than grid-based representations, which reduces dimensionality from approximately 10⁴N to only about 10N parameters, making non-local KEDF calculations computationally affordable. The deep learning model, based on the Graphormer architecture (a Transformer variant), takes as input the density coefficients distributed over atoms along with molecular structure information, and uses attention mechanisms to capture essential non-local interactions of electron density across distant spatial regions. To address unconventional machine learning challenges, the research introduces three key technical solutions: (1) methods to generate multiple density datapoints with gradient labels for each molecular structure to train the model for use as an optimization objective; (2) local frame techniques to guarantee geometric invariance where output energy remains unchanged under molecular rotation while input coefficients transform equivariantly; (3) enhancement modules that balance sensitivity, rescale gradients dimension-wise, and provide reference offsets to enable the model to express the steep gradients required by physical mechanisms. M-OFDFT solves the problem of accurate molecular electronic structure prediction by achieving chemical accuracy (errors below 1 kcal/mol for energy and approximately 3 kcal/mol/Å for forces) on diverse molecular systems including ethanol conformations and QM9 molecules—hundreds of times more accurate than classical OFDFT. More significantly, it demonstrates remarkable extrapolation capability with per-atom errors remaining constant or decreasing on molecules up to 224 atoms (10 times larger than training), successfully handling protein systems like chignolin (168 atoms) with substantially better accuracy than classical OFDFT, and exhibiting empirical time complexity of O(N^1.46), substantially lower than KSDFT's O(N^2.49), with a 27.4-fold speedup on large molecules, thereby advancing the accuracy-efficiency frontier in quantum chemistry.

**Technical Terms:**
- **Graphormer**: A graph neural network architecture based on the Transformer model, designed to process graph-structured data by using attention mechanisms to capture interactions between nodes.
- **Attention Mechanism**: A neural network component that computes weighted combinations of features from different locations, where weights are dynamically calculated based on feature content and relationships, enabling long-range interactions.
- **Geometric Invariance**: The physical principle that predicted energies and properties must remain unchanged under rigid transformations (rotation, translation) of the molecular coordinate system.
- **Local Frames**: Coordinate systems attached to local molecular features (like atoms or bonds) that transform with the molecule, used to construct rotationally invariant or equivariant representations.
- **Enhancement Modules**: Specialized neural network components designed to improve gradient expression, including sensitivity balancing, dimension-wise rescaling, and reference offset mechanisms.
- **Per-atom Error**: The prediction error divided by the number of atoms, providing a size-normalized metric for comparing accuracy across molecules of different sizes.
- **Hellmann-Feynman Force**: The force on each atom calculated as the negative gradient of total energy with respect to atomic positions, used in molecular dynamics and geometry optimization.

### Question 7. What is the difference between the proposed and conventional methods?

The proposed M-OFDFT differs from conventional classical OFDFT methods primarily in using a data-driven deep learning model to approximate the kinetic energy density functional rather than theory-based analytical formulas derived from uniform electron gas assumptions. While classical KEDFs like Thomas-Fermi, von Weizsäcker, and gradient expansion approaches are constrained by their theoretical foundations to handle only slowly-varying densities, M-OFDFT learns complex functional relationships from labeled data generated by accurate Kohn-Sham DFT calculations, enabling it to compensate for theoretical mismatches and capture the highly non-uniform density distributions in molecules. M-OFDFT differs from previous machine learning KEDF approaches through its atomic basis representation of electron density: instead of using grid-based representations requiring approximately 10⁴N points, M-OFDFT represents density with only about 10N expansion coefficients under atomic basis functions, reducing dimensionality by three orders of magnitude and making non-local calculations computationally feasible. This contrasts with prior works that either used semi-local approaches ignoring essential non-local effects or faced prohibitive computational costs with grid-based non-local methods, limiting them to systems with dozens of atoms. Compared to neural network potentials (NNPs) that predict ground-state energy end-to-end from molecular structure, M-OFDFT formulates the learning task as approximating the objective function for density optimization rather than directly predicting the final energy. This fundamental difference means M-OFDFT must learn the mechanism of electron interactions (lower complexity) while transferring much complexity to the optimization process, whereas NNPs must learn the complete many-body result (higher complexity), leading to M-OFDFT's superior extrapolation capability. M-OFDFT also differs in incorporating specialized techniques absent from conventional approaches: generating multiple density training datapoints with gradients per structure, employing local frames for geometric invariance, and using enhancement modules for expressing steep physical gradients. Finally, while conventional methods either prioritize accuracy (Kohn-Sham DFT with O(N³) scaling) or efficiency (classical OFDFT with poor accuracy), M-OFDFT achieves both chemical accuracy comparable to Kohn-Sham DFT and favorable O(N^1.46) empirical scaling.

**Technical Terms:**
- **Theory-based Analytical Formulas**: Mathematical expressions for KEDF derived from theoretical principles (like uniform electron gas) rather than learned from data, typically involving density and its derivatives.
- **Data-driven Learning**: An approach where the functional form is learned from training examples (input-output pairs) rather than derived from theoretical principles, enabling adaptation to complex patterns.
- **Density Fitting**: A technique in quantum chemistry that approximates four-center electron repulsion integrals using auxiliary basis functions to reduce computational cost from O(N⁴) to O(N³).
- **Semi-local Approaches**: Methods where the predicted quantity at a point depends only on density values in a small neighborhood, ignoring long-range interactions.
- **End-to-end Prediction**: Machine learning paradigm where the model directly maps input (molecular structure) to final output (energy) without intermediate optimization steps.
- **Objective Function**: The function to be minimized during optimization, which in M-OFDFT is the total electronic energy as a functional of density coefficients.
- **Training Datapoints**: Individual examples used to train the machine learning model, consisting of input features (density coefficients, molecular structure) and target labels (energies, gradients).

### Question 8. Explain why the difference should be introduced.

The key differences in M-OFDFT should be introduced because they address fundamental limitations that have prevented OFDFT from achieving practical accuracy and applicability to molecular systems. The atomic basis representation is essential because grid-based representations create an intractable accuracy-efficiency trade-off: molecular electron density features sharp nuclear cusps and covalent bonding regions requiring fine grids with approximately 10⁴N points for adequate resolution, but non-local KEDF calculations with such high-dimensional inputs become computationally prohibitive, eliminating the efficiency advantage that motivates OFDFT. Atomic basis functions, designed to mimic nuclear cusp conditions and naturally forming shell structures, efficiently capture molecular density patterns with only about 10N coefficients, making non-local calculations affordable while providing a representation aligned with the physical reality of how electron density organizes around atoms. The data-driven deep learning approach succeeds where classical theory fails because molecular electron density is fundamentally far from uniform, violating the assumptions underlying analytical KEDFs derived from uniform electron gas theory. By learning from accurate Kohn-Sham DFT calculations, the model compensates for theoretical mismatches and captures complex density-energy relationships that cannot be expressed in closed analytical form. Learning the objective function rather than end-to-end energy prediction is crucial for extrapolation capability: the ground-state energy emerges from intricate many-body interactions creating a highly complex function difficult to extrapolate across molecular sizes, but the underlying interaction mechanism captured by the objective function has lower complexity and better generalization properties, with optimization tools handling the remaining complexity without extrapolation issues. This formulation enables M-OFDFT to maintain constant or decreasing per-atom errors on molecules 10 times larger than training data, whereas end-to-end methods show increasing errors. The specialized techniques for generating multiple density datapoints with gradients, ensuring geometric invariance, and enhancing gradient expression are necessary because standard supervised learning approaches cannot handle the unique requirements of learning an optimization objective function that must accurately represent energy landscapes, respect physical symmetries, and exhibit steep gradients where mechanisms vary rapidly—challenges absent in conventional machine learning applications.

**Technical Terms:**
- **Accuracy-Efficiency Trade-off**: The fundamental tension in computational methods where improving accuracy typically increases computational cost, requiring careful balance for practical applicability.
- **Nuclear Cusp Condition**: A mathematical constraint describing the sharp behavior of electron density near nuclei as ∂ρ/∂r|_{r→0} ∝ -Zρ(0), which basis functions are designed to satisfy.
- **Closed Analytical Form**: An explicit mathematical formula that can be written down and evaluated directly, as opposed to implicit definitions or iterative procedures.
- **Generalization Properties**: The ability of a learned model to perform accurately on new data different from training examples, particularly important for extrapolation to different scales.
- **Energy Landscape**: The hypersurface in density coefficient space representing how electronic energy varies with all possible density configurations, which the optimizer must navigate.
- **Physical Symmetries**: Fundamental invariances in physical laws, such as energy being unchanged by rotating or translating the molecular coordinate system, which predictions must respect.
- **Optimization Objective Function**: The function being minimized (or maximized) during an optimization process, which defines the problem being solved.

### Question 9. What is the novelty of the proposed method?

The novelty of the proposed M-OFDFT method encompasses several key innovations:

- **Novel density representation for OFDFT**: First use of atomic basis expansion coefficients as input for a machine learning KEDF model, reducing dimensionality from ~10⁴N (grid-based) to ~10N while naturally aligning with molecular electron density patterns around atoms and enabling affordable non-local calculations.

- **Deep learning architecture for KEDF**: Application of Graphormer (Transformer-based) architecture with attention mechanisms to capture essential non-local electron density interactions in molecular systems, representing the first successful deep learning KEDF model achieving chemical accuracy on diverse molecular systems.

- **Learning formulation as objective function**: Novel formulation of the machine learning task as approximating the optimization objective for density rather than end-to-end energy prediction, which significantly improves extrapolation capability by reducing complexity and transferring computational burden to optimization.

- **Specialized training data generation**: Introduction of methods to generate multiple density configurations with gradient labels for each molecular structure, addressing the unique challenge that a single ground-state datapoint per structure is insufficient for learning an optimization objective.

- **Geometric invariance techniques**: Development of local frame approaches to guarantee that the model respects physical symmetries—producing invariant energy outputs from equivariant density coefficient inputs under molecular rotation—which is non-trivial with coefficient representations.

- **Gradient enhancement modules**: Novel neural network components including sensitivity balancing, dimension-wise gradient rescaling, and reference offset mechanisms specifically designed to enable the model to express the steep gradients required by rapidly-varying physical mechanisms.

- **Demonstration of practical OFDFT for molecules**: First demonstration of an OFDFT method achieving chemical accuracy on common molecular systems including conformational spaces (ethanol) and diverse chemical spaces (QM9), recovering accurate shell structures previously deemed challenging for orbital-free approaches.

- **Remarkable extrapolation capability**: Achievement of constant or decreasing per-atom errors on molecules up to 10 times larger (224 atoms) than training data, successfully handling protein systems (chignolin, 168 atoms) with high accuracy, representing unprecedented extrapolation for quantum chemistry machine learning.

- **Computational efficiency demonstration**: Empirical validation of O(N^1.46) time complexity substantially lower than Kohn-Sham DFT's O(N^2.49), with 27.4-fold speedup on large molecules, concretely demonstrating the accuracy-efficiency frontier advancement for practical large-scale molecular applications.

**Technical Terms:**
- **Chemical Accuracy**: Energy prediction errors below ~1 kcal/mol, sufficient for reliable chemical property prediction and reaction energetics.
- **Conformational Space**: The set of different three-dimensional molecular geometries (conformations) accessible through rotation around chemical bonds without breaking bonds.
- **Chemical Space**: The space of different molecular compositions and bonding patterns, representing chemically distinct molecules rather than conformations of the same molecule.
- **Shell Structure**: The organization of electron density into concentric regions around atomic nuclei corresponding to quantum mechanical shells (K, L, M, etc.).
- **Time Complexity**: Mathematical characterization of how computational time scales with system size N, expressed in big-O notation like O(N^α).
- **Frontier Advancement**: Progress in Pareto-optimal trade-offs where both competing objectives (accuracy and efficiency) are simultaneously improved beyond previous best-known solutions.

### Question 10. Show the eye-catch figure.

The eye-catch figure for M-OFDFT is Figure 1 in the paper, which provides a comprehensive three-panel overview of the method. This figure cannot be directly reproduced here as it is a complex multi-part illustration from the published paper. However, I can describe its content and significance:

**Figure 1 Content Description:**

*Panel (a)* compares KSDFT and OFDFT formulations: Shows KSDFT optimizing N orbital functions {φᵢ(r)} with O(N³) complexity versus OFDFT optimizing one density function ρ(r) with O(N²) complexity, visually illustrating the computational scaling advantage when a good KEDF T_S[ρ] is available.

*Panel (b)* illustrates the M-OFDFT architecture: Depicts how electron density is represented using atomic basis expansion coefficients p distributed over atoms (shown with a molecular structure of ethanol with spherical basis functions), how these coefficients along with molecular structure M are processed through the Graphormer deep learning model with attention mechanisms (shown with connecting lines between atoms), and how the model outputs the kinetic energy value. The attention mechanism's non-local nature is visualized with lines connecting distant atoms.

*Panel (c)* shows the density optimization workflow: Illustrates how M-OFDFT solves a molecular system by iteratively optimizing density coefficients p^(k) → p^(k+1) using gradients ∇_p E_θ to minimize the total electronic energy E_θ(p,M), with a visual representation of the energy landscape (shown in red-blue hues) that the optimization navigates to find the ground-state density ρ* and energy E*, from which properties like forces f can be derived.

The figure effectively communicates the key innovation: representing density with atomic basis coefficients enables a deep learning model with non-local interactions to approximate KEDF, which then serves as the objective for optimization to solve molecular electronic structure with both accuracy and efficiency. This visual summary captures the entire M-OFDFT workflow from input representation through model architecture to the optimization process for solving molecular systems.

**Technical Terms:**
- **Eye-catch Figure**: The main overview figure in a scientific paper that visually summarizes the key concept, method, or workflow to quickly communicate the core contribution.
- **Multi-panel Figure**: A figure composed of multiple sub-figures (panels) labeled (a), (b), (c), etc., each showing different aspects or steps of the overall concept.
- **Visual Representation**: Graphical depiction using shapes, colors, arrows, and other visual elements to communicate complex concepts more intuitively than text alone.
- **Workflow Diagram**: A schematic illustration showing the sequence of steps or processes in a method, often with arrows indicating the flow of data or operations.
- **Energy Landscape Visualization**: Graphical representation of how energy varies across a parameter space, often using color gradients (like red-blue hues) to indicate high and low energy regions.
