\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{natbib}
\usepackage{geometry}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{url}
\geometry{margin=1in}

\title{Changepdftitle}
\author{Changepdfauthor}
\date{\today}

\begin{document}
\maketitle

Chinese Physics Letters
¬†¬†¬†¬†¬† 
REVIEW
AI-Driven Inverse Design of Materials: Past,
Present, and Future
To cite this article: Xiao-Qi Han et al 2025 Chinese Phys. Lett. 42 027403 
¬†
View the article online for updates and enhancements. You may also like 
Interplay of Kitaev Interaction and Off- 
Diagonal Exchanges: Exotic Phases and 
Quantum Phase Diagrams 
Qiang Luo, , Jize Zhao et al. -
On the Multi- q Characteristics of Magnetic 
Ground States of Honeycomb Cobalt 
Oxides
Yuchen Gu, Xianghong Jin and Yuan Li -
Observation of Topological Nodal-Ring 
Phonons in Monolayer Hexagonal Boron 
Nitride
Zhiyu Tao, , Yani Wang et al. -
This content was downloaded from IP address 131.113.231.191 on 21/11/2025 at 00:13

Chinese Physics Letters 42, 027403 (2025) Review
AI-Driven Inverse Design of Materials: Past, Present, and Future
Xiao-Qi Han( Èü©Â∞èÁê™)1, Xin-De Wang(ÁéãÈ¶®Âæ∑)1, Meng-Yuan Xu( ÂæêÂ≠üÂúÜ)2, Zhen Feng( ÂÜØÁ•Ø)1,
Bo-Wen Yao( ÂßöÂçöÊñá)1, Peng-Jie Guo( ÈÉ≠ÊúãÊù∞)1, Ze-Feng Gao( È´òÊ≥ΩÂ≥∞)1*, and Zhong-Yi Lu( Âç¢‰ª≤ÊØÖ)1*
1School of Physics, Renmin University of China, Beijing 100872, China
2School of Physics and Information, Shaanxi Normal University, Xi‚Äôan 710119, China
(Received 10 December 2024; accepted manuscript online 31 January 2025)
The discovery of advanced materials is a cornerstone of human technological development and progress. The
structures of materials and their corresponding properties are essentially the result of a complex interplay of mul-
tiple degrees of freedom such as lattice, charge, spin, symmetry, and topology. This poses significant challenges
for the inverse design methods of materials. Humans have long explored new materials through numerous exper-
iments and proposed corresponding theoretical systems to predict new material properties and structures. With
the improvement of computational power, researchers have gradually developed various electronic-structure cal-
culation methods, such as the density functional theory and high-throughput computational methods. Recently,
the rapid development of artificial intelligence (AI) technology in computer science has enabled the effective
characterization of the implicit association between material properties and structures, thus forming an efficient
paradigm for the inverse design of functional materials. Significant progress has been achieved in the inverse de-
sign of materials based on generative and discriminative models, attracting widespread interest from researchers.
Considering this rapid technological progress, in this survey, we examine the latest advancements in AI-driven
inverse design of materials by introducing the background, key findings, and mainstream technological develop-
ment routes. In addition, we summarize the remaining challenges for future directions. This survey provides the
latest overview of AI-driven inverse design of materials, which can serve as a useful resource for researchers.
DOI: 10.1088/0256-307X/42/2/027403 CSTR: 32039.14.0256-307X.42.2.027403
1. Introduction. Advanced materials form a corner-
stone of our modern information society as they function
as key catalysts for technological progress and industrial
expansion, and they have been advancing at an unprece-
dented rate.[1‚Äì6]Their utilization extends across diverse
industries such as aerospace, biomedical engineering, en-
ergy storage, and information technology, which will all
benefit significantly from the integration of innovative ma-
terials that can overcome existing constraints.[7]Undoubt-
edly, the evolution of novel materials is crucial for fostering
technological breakthroughs, invigorating economic pros-
perity, and elevating the standard of living.
Generally, materials science is a major scientific dis-
cipline dedicated to studying advanced functional mate-
rials. The search for advanced materials through inverse
design is an important research field within materials sci-
ence. The inverse design of materials essentially involves
creating an optimization space based on the desired per-
formance attributes of materials. This process strives to
establish a high-dimensional nonlinear mapping from ma-
terial properties to structural configurations while adher-
ing to physical constraints. The development of the inverse
design of materials has attracted widespread interest in
academic research and can be categorized into four major
paradigms:
‚àôExperiment-Driven Paradigm. The experimental-driven paradigm is the original method of material dis-
covery. Methods under this paradigm have significantly
advanced the field of materials science. For example,
Madame Curie used experiments to discover the new ele-
ments radium and polonium, Onnes discovered the super-
conductivity phenomenon in mercury,[8]and Nagamatsu
et al. discovered the high-temperature superconduct-
ing material MgB 2.[9]However, this experimental-driven
paradigm relies heavily on trial-and-error experimentation,
individual expertise, and phenomenological scientific the-
ories. Moreover, these methods are characterized by iter-
ative cycles of experiments and observations to determine
the properties and behaviors of materials, which is not only
time-consuming and resource-intensive but also results in
extended research cycles and increased costs. In materi-
als research, a heavy dependence on personal experience is
also common. Although experienced researchers can guide
experimental design with their intuition and prior knowl-
edge, this method is limited in terms of reproducibility and
scalability. The quantification and transfer of personal ex-
perience are often challenging, hindering the process of
knowledge accumulation and dissemination.[10]Addition-
ally, personal biases and misunderstandings may occur ow-
ing to individual backgrounds and cognitive limitations.[2]
‚àôTheory-Driven Paradigm. The theory-driven
paradigm emphasizes the key role of theoretical insights
*Corresponding author. Email: zfgao@ruc.edu.cn; zlu@ruc.edu.cn
¬©2025 Chinese Physical Society and IOP Publishing Ltd. All rights, including for text and data mining, AI training, and similar
technologies, are reserved.
027403-1

Chinese Physics Letters 42, 027403 (2025) Review
and computational models in materials science. This
paradigm is characterized by the widespread use of molecu-
lar dynamics (MD) simulations and thermodynamic mod-
els to understand and predict material behavior. These
developments have, to a certain extent, simplified mate-
rial research and enhanced the efficiency of investigations
into new materials. Some very famous materials and states
of matter were first predicted through theory and then ver-
ified experimentally, and these discoveries have extremely
high scientific significance, even winning Nobel Prizes. In
1930, British physicist Paul Dirac derived the existence of
‚Äúantimatter‚Äù from his quantum mechanical equations, sug-
gesting that for every particle a corresponding antiparticle
exists.[11]Dirac‚Äôs equations first predicted the existence of
the positron, the antiparticle of the electron. In 1932, Carl
Anderson discovered the positron in cosmic rays, confirm-
ing Dirac‚Äôs prediction.[12]Anderson was awarded the No-
bel Prize in Physics in 1936 for this discovery, and Dirac
also received the Nobel Prize in Physics in 1933 for his
contributions to quantum mechanics, including the the-
oretical prediction of antimatter. John Bardeen, Leon
Cooper, and John Schrieffer proposed the BCS theory,
which explained the cause of superconductivity‚Äîthe pair-
ing of electrons to form Cooper pairs resulting in zero elec-
trical resistance.[13‚Äì15]Although the BCS theory itself did
not directly predict new materials, it became the founda-
tion for research into low-temperature superconductivity.
Bardeen, Cooper, and Schrieffer were awarded the Nobel
Prize in Physics in 1972 for their work. In 2005, Charles
Kane and Eugene Mele predicted the existence of the quan-
tum spin Hall effect through topological quantum theory,
a phenomenon in which edge state conduction occurs with-
out an external magnetic field. This concept laid the foun-
dation for topological insulators. In 2007, scientists first
achieved the quantum spin Hall effect in HgTe quantum
wells, verifying the accuracy of the theory. These classic
predictions demonstrate the powerful predictive ability of
theoretical physics in the exploration of new materials and
phenomena and promote the development of experimental
physics. Many such theoretical breakthroughs ultimately
won the Nobel Prize for experimental verification, marking
significant advances in physics. Nevertheless, these the-
oretical frameworks often require complex mathematical
models that are demanding in terms of computational re-
sources and expertise. Their applicability may be limited,
particularly for material systems that exhibit multi-scale
phenomena and complex interactions.
‚àôComputation-Driven Paradigm. Established on the
foundation of theoretical progress, the computation-driven
paradigm has progressed alongside the surge in computa-
tional power and data accessibility. This paradigm lever-
ages computational models to simulate material behaviors
and inform the design process. The application of density
functional theory (DFT)[16‚Äì18]and computational chem-
istry tools such as Hartree‚ÄìFock theory has revolution-
ized our ability to predict and optimize material prop-
erties. The DFT has played a crucial role in the in-
vestigation of the electronic structure of graphene. TheDFT revealed the zero-bandgap structure of graphene,
a characteristic that is essential for its electronic prop-
erties and holds significant potential for its application
in electronic devices.[19]Furthermore, the Hartree‚ÄìFock
method has been extensively applied in calculating molec-
ular orbitals, such as in studies on water molecules, thus
offering vital insights into their geometric and electronic
characteristics.[20]The potency of these methods is clear
in their capacity to manage complex systems that were
once difficult to understand. However, reliance on compu-
tational models introduces challenges, as the accuracy of
predictions heavily relies on model quality and available
computational resources. Additionally, high-throughput
screening (HTP) and combinatorial screening have become
significant methodologies for exploring new materials and
systems. This approach significantly expedites the dis-
covery and development of novel materials, particularly in
drug discovery, catalyst design, and energy storage ma-
terial development, where it enables the parallel assess-
ment of vast compound libraries to identify potential new
materials.[3]Despite the achievements of HTP in materials
science, challenges remain, including substantial resource
requirements for physical or computational experiments,
constraints by existing material libraries, and insufficient
consideration of intricate relationships between material
properties.[21]
‚àôArtificial Intelligence (AI)-Driven Paradigm. With
the advent of the big data era, materials science has tran-
sitioned into an AI-driven paradigm. AI is a significant
shift within the engineering field, heralding an era defined
by enhanced intelligence and automation. Both the widely
utilized auto-regressive models based on the transformer
architecture[22]and the robust diffusion models[23,24]have
contributed significantly to the advancement of inverse
design of materials.[25‚Äì28]The capacity of AI to discern
patterns and formulate predictions from data has enabled
notable transformations in materials science. By exam-
ining vast experimental data and computational simu-
lation outcomes, AI models reveal intricate correlations
between material properties and their underlying crystal
structures.[29,30]Furthermore, a recent survey[25]has inte-
grated inverse design methodologies with machine learning
(ML) models to forecast the mechanical properties of ma-
terials, including elastic modulus and yield strength, thus
expediting the discovery and development of innovative
materials. These data-driven strategies not only bolster
the precision of predictions but also considerably shorten
material development cycles. Consequently, ‚ÄúML mate-
rials discovery‚Äù is attracting much research interest [see
Fig. 1(a)]. In parallel, the exponential growth of the total
known materials over time highlights the accelerated pace
of material discovery processes, with significant contribu-
tions from Google‚Äôs GNoME[31]and Meta‚Äôs OMat24.[32]
As discussed earlier, AI-driven methods are not a new
technical concept for inverse design of functional materi-
als, but they have evolved with the advance of AI over
the decades. The experiment-driven and theory-driven
paradigms primarily aim to discover new functional ma-
027403-2

Chinese Physics Letters 42, 027403 (2025) Review
terials based on heavily trial-and-error experiments or
theoretical models, whereas the latest AI-driven meth-
ods concentrate on constructing the hidden mappings be-
tween material functions and crystal structures. The
progress from conventional experiment methods to data-
driven methods is an important leap in the use of modern
advanced computational methods to design target func-
tional materials. In Fig. 2, we delineate the evolution of
materials science discoveries over time and with techno-
logical advancements. Initially, the confirmation of new
materials was primarily achieved through experimenta-
tion (such as Madame Curie‚Äôs discovery of new elements),
which entailed significant costs and numerous trials. Sub-
sequently, theoretical paradigms were introduced, predict-ing physical properties that were later experimentally ver-
ified (for instance, the prediction and validation of semi-
conductors). With the advancement of computer technol-
ogy and the enhancement of computational ability, high-
throughput computational methods have become a signifi-
cant avenue for the discovery of new materials. Ultimately,
as the latest generation of technology, AI methods can ef-
ficiently generate and screen new functional materials by
elucidating the hidden correlations between crystal struc-
tures and properties, thereby accelerating the discovery of
new materials. In summary, throughout this evolutionary
process, technological progress has enabled us to employ
more sophisticated methods to expedite the discovery of
new functional materials.
100025000
20000
15000
10000
5000
0800
600400200
0Publications
Citations(a) (b)
2019108
107
106
2020 2021 2022 2023 2024
Year2019 2020 2021 2022 2023 2024
YearTotal known materialsGNoME\&GoogleOMat24\&Meta
Fig. 1. Trends in publications and citations in the field of ‚Äúmachine learning materials discovery‚Äù from 2019 to
2024. The left panel (a) shows the increase in the number of publications (represented by blue bars) alongside the
total citations (depicted by the red line with markers), reflecting a significant increase in both metrics over the past
few years. The right panel (b) presents the variation in the total known materials over time on a logarithmic scale,
highlighting the acceleration of material discovery processes facilitated by GNoME[31]of Google and OMat24[32]
of Meta. This figure underscores the rapid development within the field of ML materials discovery.
Experiment -driven paradigm
Marie Curie's Nobel prize:
Discovery of radium and poloniumDFT calculations of MgB 2, Hydride
Superconductors, and grapheneTheory -driven paradigm
Dirac's equation: 
prediction of the positron
Quantum spin hall effectAI-driven paradigm
Artificial intelligence
AI-accelerated materials discoveryComputation -driven paradigm
AlphaFold2, GPT4
Kohn -Sham equation
AlphaFold2
Fig. 2. Materials science research paradigms. This figure depicts the evolution of research paradigms in materials
science, emphasizing key milestones across various approaches. It highlights the increasing role of AI in driving future
materials discovery, with AI becoming the dominant force in shaping the field. The experiment-driven paradigm is
exemplified by Marie Curie‚Äôs Nobel Prize-winning discovery of radium and polonium. The theory-driven paradigm
is represented by Dirac‚Äôs equation, which predicted the existence of the positron and the quantum spin Hall effect.
The computation-driven paradigm is demonstrated through DFT calculations applied to materials such as MgB 2,
hydride superconductors, and graphene. Finally, the AI-driven paradigm showcases recent breakthroughs in AI,
including AlphaFold2, GPT-4, and AI-accelerated materials discovery, signaling the frontier of research in the field.
With the development of technology, a research field
has emerged in materials science known as the inverse de-
sign of materials. Unlike traditional trial-and-error meth-
ods, it utilizes complex computational techniques to design
materials with specific properties systematically. The pro-
cess involves several key steps: defining the target prop-erties or functionalities; selecting an appropriate design
space; using modeling and simulation tools (such as DFT
and finite element analysis) to simulate material proper-
ties; optimizing the material structure through algorithms
to minimize the difference between simulated properties
and target goals; finally, validating the design through
027403-3

Chinese Physics Letters 42, 027403 (2025) Review
experimental verification, followed by iterative refinement
based on experimental results. This approach is widely ap-
plied in areas such as optics, electronics, energy storage,
catalysis, and composite materials, and it significantly ac-
celerates the development of new materials. However, in-
verse design also faces challenges such as computational
cost, data quality, and experimental validation. With the
advancement of computational power and optimization al-
gorithms, materials inverse design is expected to play an
increasingly important role in the future development of
materials science.
In the existing literature, the inverse design of ma-
terials has been extensively discussed and surveyed.[2‚Äì6]
However, current surveys often focus on specific ML al-
gorithms or particular types of materials, resulting in a
lack of systematic integration of diverse methodologies and
a broad range of material systems. Many existing sur-
veys predominantly focus on specific categories of materi-
als or application scenarios, such as topological insulators
or high-entropy alloys,[33,34]thereby failing to provide a
comprehensive examination of AI-driven inverse design of
materials. Specifically, comparative and analytical studies
across different researches about AI-driven inverse design
of materials are lacking, which hinders a holistic under-
standing of the advantages, disadvantages, and applicable
contexts of various methodologies. These limitations pose
challenges for readers attempting to fully grasp the over-
arching landscape of AI-driven inverse design of materials,
particularly with respect to the dynamic evolution of new
methods and their applications.
Owing to both opportunities and challenges, more at-
tention is required on the research and development of
AI-driven inverse design of materials. To provide a ba-
sic understanding of this research field, this survey aims
to address the gaps in the current body of research by
comprehensively examining previous studies from two per-
spectives: the discovery of functional materials based on
AI methods and the development of AI methods in materi-
als science. We systematically analyze the latest advance-
ments in AI technologies within the domain of inverse de-
sign of materials. We conduct an exhaustive survey of the
literature to synthesize the pivotal discoveries, AI meth-
ods, and procedural methods in the inverse design of func-
tional materials. We are also aware of several relative sur-
vey articles on inverse design of materials.[35,36]Ref. [36]
provided an overview of the importance and utilization
of graph neural networks (GNNs) within chemistry and
materials science. GNNs can directly process the graph-
ical representations of molecules and materials, thereby
capturing the essential information required to character-
ize these materials. The review further outlined the fun-
damental principles of GNNs, including commonly used
datasets and architectures, and emphasized their critical
role throughout the materials development. Another Ref.
[35] systematically explored the research advancements of
geometric GNNs in the applications of materials and drug
discovery. It emphasized the significance of geometric
graphs in scientific fields, particularly their ability to cap-
ture geometric features such as the three-dimensional (3D)coordinates of nodes. The survey further defined geometric
graphs and compared them with traditional graphs, eluci-
dating their distinct characteristics. Additionally, it sum-
marized existing models, including invariant and equivari-
ant GNNs. Our survey presents the latest advancements
in functional materials accelerated by ML techniques, with
particular emphasis on the robust representational capa-
bilities of geometric GNNs. Furthermore, we provide a
comprehensive overview of advanced generative models
and large language models (LLMs), highlighting their piv-
otal roles in driving materials discovery. Finally, we have
gathered standard datasets and benchmarks that are cru-
cial for material discovery to advance the methods of AI-
driven inverse design of materials.
‚ÄúAll significant achievements take time. ‚Äù The inverse
design of materials has undergone a long development to
achieve the latest successes. Our aim is to discuss the
historical progression of material directional design, with
a particular focus on the innovative approaches to mate-
rial discovery that have occurred in the era of AI. This
survey will elucidate the critical challenges inherent in in-
verse design of materials. Subsequently, we discuss the
specific classes of materials that are currently at the fore-
front of materials science (including superconducting ma-
terials and magnetic materials), and detail the AI tech-
nologies. We have also compiled a comprehensive overview
of the evolution of AI technologies within the materials do-
main. We expect that the contributions presented in this
paper will propel the field of AI-driven inverse design of
materials to new heights of advancement. In the following,
we introduce the recent applications of AI-driven method
in expediting the inverse design of functional materials in
Section 2. We then elaborate on the development history
of AI technology in the field of materials science in Sec-
tion 3. Finally, we briefly discuss a series of open problems
and promising directions for the future in Section 4 and
conclude in Section 5.

\section{Discovery of Functional Materials Based on AI}

Methods. The AI-accelerated discovery of functional mate-
rials has emerged as a dominant trend in materials science.
As the demand for novel materials continues to increase,
traditional material discovery methods often become too
slow and labor-intensive to match the pace of technolog-
ical innovation. Consequently, AI‚Äìparticularly ML and
deep learning (DL)‚Äìhas demonstrated significant potential
in advancing material discovery. AI facilitates the efficient
identification of patterns in data, the prediction of ma-
terial properties, and the optimization of complex mate-
rial compositions, thus offering tools for materials science
that were previously unimaginable. This chapter compre-
hensively reviews AI applications across several key cate-
gories of functional materials, including superconducting
materials, magnetic materials, thermoelectric materials,
carbon-based nanomaterials, two-dimensional (2D) ma-
terials, photovoltaic materials, catalytic materials, high-
entropy alloys, and porous materials. These materials are
crucial to the development of advanced technologies in ar-
eas such as energy storage, electronics, and environmental
sustainability.
027403-4

Chinese Physics Letters 42, 027403 (2025) Review
Superconducting materials
AI predicts critical temperature
AI generates new superconductors
AI performs EPC calculations
AI integrates experimental feedback2D materials
AI-driven construction of 2D material database
AI discovers 2D topological insulators
AI discovers van der Walls heterostructures
Photoelectric materials
AI predicts photoelectric conversion efficiency
AI predicts perovskite band gap
AI searches for stable semiconductors
Catalyst materials
Active learning discovers catalysts
AI predicts adsorption energy
LLMs discovers new catalysts
High -entropy alloys
AI predicts HEA phases
Active learning designs Low -TEC HEAs
AI analyzes elemental ratio impact on HEA hardness.
Porous materials
Adversarial networks generate crystalline porous materials
Generative models for inverse design of MOFs
AI predicts the properties of COFsMagnetic materials
AI search altermagnetic materials
LLMs establishes magnetic materials database
AI-based classification of magnetic material types
Thermoelectric materials
AI predicts thermoelectric performance ZT
AI guides doping and strain engineering
AI-experimental feedback integration
Carbon -based nanomaterials
AI simulation of carbon nanomaterial growth
AI predicts physical properties
AI-driven biocompatibility predictionMgB 2
Nd2Fe14B
TiO 2CaTiO 3C
TiGePt
MOF -74CoCrFeMnNi
CAI-accelerated
discovery of
materials
Fig. 3. AI-driven discovery of materials. This figure shows the role of AI in accelerating the discovery of vari-
ous types of materials. The examples presented highlight how the AI-driven approaches are employed to optimize
the identification, design, and property prediction of materials across diverse categories, including superconducting
materials, magnetic materials, thermoelectric materials, carbon-based nanomaterials, 2D materials, photovoltaic
materials, catalyst materials, high-entropy alloys, and porous materials. By leveraging large datasets and advanced
computational techniques, AI methods facilitate more efficient screening and prediction, thereby significantly ad-
vancing the pace of material discovery. These examples represent only a subset of the broad potential of AI in
transforming materials research. Further discussion is provided in the main text.
2.1. Superconducting Materials. Superconducting ma-
terials exhibit zero electrical resistance and complete ex-
pulsion of magnetic fields below a critical temperature
(ùëác). These materials have wide applications owing to
their outstanding physical properties, such as in magnetic
resonance imaging[37]and nuclear fusion technology.[38]
Superconductor-based devices are used in quantum in-
formation processors, advanced sensors, and communica-
tion systems.[39‚Äì41]Superconducting materials were dis-
covered in 1911 when mercury exhibited zero resistance at
4.2 K.[42]In 1933, the Meissner effect,[43]where supercon-
ductors expel magnetic fields entirely, was observed. Sig-
nificant milestones include the 1973 discovery of niobium-
germanium alloy[44]with a ùëácof 23.2 K, the 1986 break-
through in copper oxide superconductors[45]reaching 35 K,
and yttrium-barium-copper-oxide materials[46]surpassing
77 K in 1987. In 2008, iron-based compounds exceeded
55 K.[47]In recent years, high- ùëácsuperconductors have ad-
vanced, with scandium setting a record for elemental su-
perconductors at 36 K[48]and pressed nickelate bilayers
reaching liquid-nitrogen temperatures.[49]Hydride super-
conductors, such as H 3S, have also been confirmed under
high pressure.[50]
The search for new high- ùëácsuperconductors is a sig-
nificant task in condensed matter physics. With the ad-
vancement of AI technologies, extensive exploration has
been conducted in the field of AI-accelerated supercon-ducting material discovery. The study in Ref. [51] uti-
lized data extracted from the SuperCon database,[52]com-
prising approximately 16,400 compounds (without crystal
structures). They employed a random forest (RF) algo-
rithm to build ML models for predicting the ùëácof su-
perconducting materials. Separate regression models were
developed for different superconducting families, such as
cuprates, iron-based superconductors, and low- ùëácsuper-
conductors. Ablation studies demonstrated that these re-
gression models cannot be generalized across different su-
perconducting families, likely owing to their distinct su-
perconducting mechanisms. Considering the crucial role of
band theory in explaining superconducting mechanisms, a
recent study[53]employed electronic band structure data
and applied a transformer-based model with attention
mechanisms to predict the superconducting ùëácof mate-
rials. Zhang et al. released the SuperBand dataset, com-
prising electronic band structures suitable for ML training,
generated through high-throughput DFT calculations.[54]
Traditional ML algorithms struggle to effectively
model complex crystal structures, whereas GNNs[55‚Äì60]
have a natural advantage in representing such structures.
Choudhary et al.[61]leveraged the atomistic line graph
neural network (ALIGNN)[62]to accelerate the discovery
of superconductors. They employed ALIGNN to predict
key physical properties such as Debye temperature, elec-
tronic density of states (DOS) at the Fermi level, and the
027403-5

Chinese Physics Letters 42, 027403 (2025) Review
ùëácof superconducting materials. By screening materials
with high Debye temperatures and high electronic densi-
ties of states at the Fermi level, they conducted electron-
phonon coupling (EPC) calculations on 1,058 materials,
constructing a systematic BCS superconductivity perfor-
mance database. Using the McMillan-Allen-Dynes for-
mula, they identified 105 dynamically stable materials
with a ùëácexceeding 5 K. Recent reserch[63‚Äì66]has demon-
strated that ALIGNN can also be used to predict the su-
perconducting ùëácof hydride superconductors under vary-
ing pressures, resulting in the discovery of 122 dynam-
ically stable structures with a ùëáchigher than that of
MgB 2(39 K). With the advancement of algorithms, su-
perconducting datasets containing crystal structures, such
as 3DSC[67]and SuperCon3D, have been successively re-
leased.
The method of searching for high- ùëácsuperconductors
based on existing databases has explored only a small
region of chemical space. In recent years, generative
models[68‚Äì70]have attracted significant interest because
they can produce highly realistic images, and such algo-
rithms have been widely applied in areas such as molecu-
lar docking[71]and material generation.[23,24]In principle,
generative models can explore an infinite chemical space.
Han et al.[72]developed an AI workflow for discovering
high- ùëácsuperconductors. This workflow first generates
new candidate superconducting crystal structures using
a diffusion-based generative model. Thereafter, a super-
conductivity classification model[73,74]assesses the likeli-
hood of the material being a superconductor, followed by
a formation energy prediction model[75,76]that evaluates
the material‚Äôs stability. Subsequently, a DPA-2 model[77]
optimizes the structure, and finally, ALIGNN is used to
predict the ùëácof materials. The results have been val-
idated through first-principles electronic-structure calcu-
lations, which identified 74 dynamically stable supercon-
ducting candidates with ùëácvalues higher than 15 K, none
of which are found in existing datasets. A series of sim-
ilar studies[78]have also employed generative models to
explore superconducting materials.
When validating the stability of candidate supercon-
ducting materials, the DFT requires expensive phonon
spectrum calculations. Recent studies[79]introduced the
virtual node graph neural network (VGNN), which can
directly predict ùõ§-point phonon spectra and full disper-
sion relations across the entire Brillouin zone using only
atomic coordinates as input. A ùõ§-point phonon database
containing over 146,000 materials was also developed. Fur-
ther validation of superconducting materials requires the
calculation of EPC, and Zhong et al.[80]provided an ML
approach to accelerate the computation of EPC matrices.
Most of the above-mentioned AI models are primarily
combined with high-throughput DFT calculations to dis-
cover new high- ùëácsuperconductors, where the supercon-
ducting mechanisms are well-understood within the frame-
work of BCS theory. However, the superconducting mech-
anisms for most high- ùëácsuperconductors remain unclear,
and these materials are considered unconventional super-conductors. Additionally, empirical rules[81‚Äì84]that de-
scribe correlations between ùëácand structural features ex-
ist, but these rules are limited to cuprates and iron-based
superconductors and cannot be generalized to other ma-
terials. Because chemical bonding and electronic interac-
tions in the lattice are crucial factors for superconductiv-
ity, Liang et al.[85]developed a bond sensitive GNN (BS-
GNN) to predict the upper limit of ùëác(ùëácmax) in differ-
ent materials. This model integrates three modules: near-
est neighbor graph representation (NGR), communication
message passing (CMP), and graph attention (GAT). It
reveals a close relationship between ùëácmax and chemical
bonding, showing that shorter bond lengths favor higher
ùëácmax, consistent with existing domain knowledge. How-
ever, this model can only predict ùëácand cannot determine
whether a material is superconducting. Additionally, ex-
pert input is required for further screening to eliminate
particularly unreasonable materials, such as insulators.
The above-mentioned AI methods are primarily com-
bined with theoretical calculations. In contrast, the re-
search in Ref. [86] introduces a closed-loop ML approach,
which integrates ML with experimental feedback to ac-
celerate the discovery of superconducting materials. Us-
ing an active learning strategy, this method iteratively se-
lects and experimentally validates materials predicted by
an ML model; subsequently, it feeds the experimental re-
sults back into the model to continually improve its predic-
tions. Through this approach, the research team discov-
ered a previously unreported superconductor in the Zr-In-
Ni system and rediscovered five known superconductors
that were not part of the training dataset, significantly
enhancing the success rate of superconductor discovery.
This closed-loop method highlights the potential of com-
bining ML with experimental feedback to accelerate new
material discoveries and demonstrates the critical role of
experimental validation in refining ML predictions.
2.2. Magnetic Materials. Magnetic materials are sub-
stances that can generate magnetization when subjected
to a magnetic field and exhibit attraction to ferromagnetic
elements such as iron. Dating back approximately 2,500
years, humanity had discovered that certain materials pos-
sess the ability to attract iron. For centuries, the creation
of artificial magnets was confined to a singular method:
friction with a natural magnet or an existing artificial mag-
net, the latter having been initially produced through con-
tact with a natural source. A pivotal moment occurred in
1820 when Hans Christian Oersted uncovered the mag-
netic effects induced by electric currents. This discovery
laid the foundation for the invention of the electromagnet
in 1825, a breakthrough that introduced a novel means of
generating significantly stronger artificial magnetic fields.
Consequently, this period marked the commencement of
extensive scientific inquiry into the properties and appli-
cations of magnetic materials.[87]
Based on their properties, magnetic materials can
be categorized into three types: ferromagnetic,[88]
antiferromagnetic,[89]and altermagnetic.[90‚Äì98]The differ-
ence between ferromagnetic and antiferromagnetic mate-
027403-6

Chinese Physics Letters 42, 027403 (2025) Review
rials lies in the arrangement of the magnetic moments and
the resulting magnetic behavior. Ferromagnetic materials
exhibit a wide range of magnetic domains,[99]where the
magnetic moments within each domain are aligned in the
same direction. However, the magnetic moments in differ-
ent domains may have different orientations. Under the
influence of an external magnetic field, ferromagnetic ma-
terials can be strongly magnetized, and they have a high
coercivity, meaning that a strong reverse magnetic field is
required to change the direction of magnetization. After
the removal of the external magnetic field, ferromagnetic
materials maintain a certain level of remanence and ex-
hibit high permeability. The altermagnetic materials, de-
spite exhibiting antiferromagnetic compensated magnetic
order, show macroscopic time-reversal symmetry-breaking
phenomena and spin polarization similar to ferromagnets.
This seemingly contradictory behavior has caused scien-
tists to reclassify them based on spin-symmetry principles,
thereby defining altermagnetism as a new magnetic phase.
As research on altermagnetic materials deepens, more ma-
terial candidates have been discovered with these prop-
erties, including insulators, semiconductors, metals, and
high-temperature superconductors.[91]
Moreover, altermagnetic materials have attracted sig-
nificant interest owing to their novel physical effects,
such as giant magnetoresistance (GMR),[100]unconven-
tional superconductivity,[101,102]tunneling magnetore-
sistance (TMR),[100]piezomagnetic effects,[103]spin-
splitting torque,[104‚Äì106]time-reversal odd anomalous
effects,[94,107‚Äì112]quantum anomalous Hall effects,[113]
higher-order topological states,[114]altermagnetic
ferroelectricity,[115]and strong spin-orbit coupling ef-
fects in light-element altermagnetic materials.[116]Recent
studies[117]have demonstrated the theoretical feasibility of
achieving bipolarized Weyl semimetals and the quantum
crystal valley Hall effect in 2D altermagnetic materials.
With the development of science and technology, the
discovery of new magnetic materials with a greater operat-
ing temperature range and better performance is essential.
Recently, a comprehensive experiment-based database of
magnetic materials based on LLMs, named the northeast
materials database (NEMAD), has been created.[118]Itani
et al. indicated that several ML models can classify mag-
netic materials and predict their magnetic properties, but
the lack of a comprehensive database of magnetic mate-
rials results in poor generalization of the models, that is,
the accuracy of the models in predicting different classes
of new magnetic materials is low. Based on this, they
created an application, GPTArticleExtractor,[119]to au-
tomatically extract data from scientific articles to build a
comprehensive database of material properties. Similarly,
an AI search engine named MatAltMag[74]was proposed
to accelerate the discovery of altermagnetic materials. The
engine first undergoes pre-training using crystal graph con-
volutional neural networks (CGCNNs)[73]and the Materi-
als Project database[120]to learn the intrinsic features of
material crystal structures. It then fine-tunes the classifierusing a limited number of positive samples to accurately
predict intercalated magnetism. This engine has success-
fully discovered 50 new altermagnetic materials, includ-
ing metals, semiconductors, and insulators, significantly
expanding the known range of altermagnetic materials.
The altermagnetism of these materials has been validated
through DFT calculations, revealing novel physical effects
such as the anomalous Hall effect, anomalous Kerr effect,
and topological properties. Furthermore, the discovery of
fourùëñ-wave altermagnetic materials is a breakthrough in
the study of altermagnetic phases. The AI-driven method
demonstrates significant potential in accelerating the dis-
covery of altermagnetic materials.
Owing to the relatively recent emergence of altermag-
netic materials, only few researchers have employed ML
algorithms in this field, and the potential of AI has yet to
be fully tapped. We anticipate that future research will
utilize generative models to explore a broader chemical
space in the search for novel altermagnetic materials while
leveraging AI algorithms to accelerate the DFT validation
process.
2.3. Thermoelectric Materials. Thermoelectric mate-
rials represent a class of functional materials that can di-
rectly convert heat into electricity, and vice versa, through
the Seebeck effect, which generates an electric current in
response to a temperature gradient.[121]These materials
hold significant promise for applications in waste heat re-
covery and solid-state cooling technologies. Currently, ap-
proximately two-thirds of global energy consumption is
considered to be lost as waste heat, and thermoelectric ma-
terials provide a potential pathway to reclaim this wasted
energy, thereby improving overall energy efficiency.[122]
Furthermore, thermoelectric devices, which require nei-
ther mechanical components nor harmful working fluids,
present an environmentally friendly and sustainable solu-
tion for various applications, including space power sys-
tems, automotive and industrial waste heat recovery, and
thermal management in microelectronics.[123]
The performance of thermoelectric materials is gener-
ally evaluated using the dimensionless figure of merit, ZT,
defined as ZT =ùõº2ùúéùëá
ùúÖ, where ùõºis the Seebeck coefficient,
ùúéis the electrical conductivity, ùëáis the absolute tempera-
ture, and ùúÖis the thermal conductivity.[124]The term ùõºùúé,
known as the power factor, is a function of both carrier
concentration ( ùëõ) and carrier mobility ( ùúá).[125]Achieving
a high ZT value requires materials that exhibit both a high
electrical conductivity and high Seebeck coefficient while
maintaining a low thermal conductivity. However, opti-
mizing ZT is challenging owing to the interdependence of
these parameters; for example, increasing electrical con-
ductivity often results in a concomitant increase in thermal
conductivity, which can diminish the desired improvement
in ZT.[126]This trade-off remains one of the central chal-
lenges in thermoelectric material research.
Recent advancements in computational methods, par-
ticularly through the integration of ML and high-
throughput screening techniques, have created new av-
enues for addressing this challenge. By leveraging large
027403-7

Chinese Physics Letters 42, 027403 (2025) Review
datasets and advanced algorithms, researchers can now
identify promising thermoelectric materials more effi-
ciently and accurately than with traditional trial-and-error
approaches or first-principles calculations alone. Stud-
ies have demonstrated the potential of ML models, such
as the RF model combined with Bayesian optimiza-
tion, to predict new M2X3-type thermoelectric materials
with rhombohedral structures from large datasets, suc-
cessfully identifying candidates with high thermoelectric
performance.[127]Similarly, unsupervised learning tech-
niques, including K-means and Gaussian mixture models,
have been applied to cluster half-Heusler compounds, ef-
fectively identifying materials with favorable thermoelec-
tric properties.[128]These approaches underscore the util-
ity of ML in uncovering complex structure-property rela-
tionships relevant to thermoelectric performance.
For doped materials, the DopNet neural network ar-
chitecture has been introduced to capture the effects of
dopants accurately, enabling the prediction of the ther-
moelectric properties of doped materials based on exten-
sive datasets.[129]This model has successfully predicted
the impact of various dopants on crucial properties such
as the Seebeck coefficient and electrical conductivity. In
addition, artificial neural networks (ANNs) combined with
techniques such as combinatorial gradient thermal anneal-
ing have optimized the internal strain of bismuth telluride
films, resulting in significant improvements to their See-
beck coefficient.[130]Such studies illustrate the importance
of doping and strain engineering in enhancing thermoelec-
tric performance and reveal how ML can assist in identi-
fying critical relationships.
In the realm of high-throughput computing and screen-
ing, frameworks have been established to analyze com-
pounds such as diamond-like ABX2, thus identifying mate-
rials with high ZT values and highlighting key conductive
mechanisms contributing to thermoelectric efficiency.[131]
Similarly, approaches that combine high-throughput ab
initio calculations with deep neural networks have pre-
dicted the thermoelectric properties of IV-V-VI layered
semiconductors, revealing high-performance candidates,
such as n-type Pb 2Sb2S5, with ZT values surpassing
1.0.[132]These integrated approaches expedite the discov-
ery of new thermoelectric materials by leveraging ML and
high-throughput screening. Additionally, the ToBaCCo
3.0*code has been employed for large-scale screening of
metal‚Äìorganic frameworks (MOFs). MD simulations on
10,194 hypothetical MOFs were conducted to investigate
the structural characteristics affecting thermal conductiv-
ity, revealing that parameters such as density, pore size,
porosity, and surface area significantly influence thermal
transport properties.[133]Although ML models were not
utilized in this study, the computational screening pro-
vided valuable insights into the structure-performance re-
lationships governing MOF thermal conductivity.
High-throughput screening techniques have also been
instrumental in identifying materials with excellent Peltier
cooling performances among Heusler compounds, reveal-ing their potential for sustainable cooling applications.[134]
The identification of compounds with desirable electronic
structures and thermoelectric transport properties demon-
strates the utility of high-throughput approaches for ap-
plications in efficient cooling technologies.
Finally, the integration of ML with experimental feed-
back has been proposed as a promising approach for
accelerating material discovery. By iteratively refining
ML models with experimental data, methods such as er-
ror correction learning (ECL) have successfully predicted
high-performance thermoelectric materials with improved
power factors, minimizing experimental trials and enhanc-
ing predictive accuracy.[135]
Looking ahead, the convergence of ML and high-
throughput computational methods is expected to be piv-
otal in advancing the inverse design of thermoelectric ma-
terials. As computational capabilities expand and larger
and more diverse datasets become available, these tech-
nologies will continue to drive breakthroughs in addressing
the challenges associated with optimizing thermoelectric
properties. ML models‚Äìsuch as RFs, neural networks, and
clustering algorithms‚Äìhave already demonstrated their
ability to uncover intricate structure-property relation-
ships across various material classes, including M2X3 com-
pounds, half-Heuslers, and doped systems. Coupled with
high-throughput screening, which facilitates the explo-
ration of extensive material libraries, such as MOFs and
Heusler compounds, researchers can swiftly identify high-
ZT candidates and deepen their understanding of key fac-
tors affecting thermoelectric performance, such as thermal
conductivity and electronic transport. Moreover, the in-
tegration of experimental feedback with ML models, as
exemplified by the error correction learning (ECL) ap-
proach, holds significant promise for accelerating material
discovery by continuously improving predictive accuracy.
As these techniques become more refined and collabora-
tions between computational and experimental domains
intensify, they are expected to revolutionize the design and
discovery of next-generation thermoelectric materials. Ul-
timately, these advancements will contribute to the devel-
opment of highly efficient environmentally sustainable en-
ergy systems for applications such as waste heat recovery,
energy harvesting, and sustainable cooling technologies.
2.4. Carbon-Based Nanomaterials. Carbon-based
nanomaterials are structures composed of carbon atoms
arranged in a hexagonal honeycomb lattice, including car-
bon nanotubes (CNTs) and graphene. Because of their
distinct physical and chemical properties, these materials
have attracted significant interest in materials science since
their discovery.[136,137]CNTs are classified into single-
walled and multi-walled CNTs. The former consist of a
single layer of rolled graphene, and the latter comprise
multiple concentric graphene layers.[138]These two forms
exhibit notable differences in mechanical, electrical, and
thermal properties. Graphene, a 2D carbon-based nano-
material, is formed by a single layer of carbon atoms in a
hexagonal lattice, offering exceptional carrier mobility and
*https://github.com/tobacco-mofs/tobaccoÀô3.0
027403-8

Chinese Physics Letters 42, 027403 (2025) Review
mechanical strength.[19]
Owing to their outstanding electrical conductivities,
mechanical strengths, and thermal conductivities, carbon-
based nanomaterials are widely applied in various ad-
vanced technology sectors. For example, CNTs and
graphene are used in the electronics industry to manu-
facture miniaturized circuits and efficient semiconductor
components and may potentially surpass the limitations
of Moore‚Äôs law.[139]In the mechanical field, carbon-based
nanomaterials are ideal for reinforcing composites owing to
their lightweight and high-strength characteristics, mak-
ing them integral in high-performance structural materi-
als for aerospace, automotive, and other industries.[140]In
the energy sector, the superior conductivity and energy
storage capabilities of CNTs and graphene have signifi-
cant promise for improving the energy density of batteries
and supercapacitors.[141]However, the synthesis and de-
sign of carbon-based nanomaterials involve complex multi-
variable optimization challenges. Traditional experimental
approaches struggle to address these challenges effectively,
prompting the integration of AI technologies as a promis-
ing solution for the inverse design and performance opti-
mization of carbon-based nanomaterials.
Some researchers have proposed an active learning
model to elucidate the growth mechanisms of carbon-based
nanomaterials on metallic substrates.[142]This study com-
bined MD with the time-stamped force-bias Monte Carlo
method, enhanced by the Gaussian approximation poten-
tial model for sampling. By simulating graphene growth
on a copper substrate (Cu(111)), the researchers analyzed
carbon monomer and dimer diffusion, the formation of car-
bon chains and rings, and the copper-assisted edge growth
mechanism. The model dynamically generates ML po-
tentials during the simulations, thus offering key insights
into the growth processes of carbon materials on various
metal substrates. Similarly, ML-enhanced molecular simu-
lations have investigated the high-temperature growth dy-
namics of CNTs, using the DeepCNT-22 ML force field
to model interfacial behaviors, defect formation, and de-
fect healing mechanisms during CNT growth.[143]By uti-
lizing machine learning force fields (MLFFs) trained on
first-principles calculations, this study extended simula-
tion time scales while maintaining computational accu-
racy, revealing atomic-level processes from CNT nucle-
ation to growth. Additionally, combining ML with au-
tomation enhances the synthesis efficiency of carbon-based
nanomaterials, as demonstrated by the AI-driven plat-
form carbon copilot. This platform integrates transformer-
based language models (Carbon-GPT and Carbon-BERT),
a robotic chemical vapor deposition (CVD) system, and
data-driven ML models to optimize synthesis processes,
significantly improving controllability and yield in the
growth of CNTs and graphene, particularly for horizon-
tally aligned CNT arrays.[144]
Beyond synthesis optimization, ML is pivotal in pre-
dicting the physical properties of carbon-based nanomate-
rials, particularly for key attributes such as thermal and
electrical conductivity. Compared with traditional meth-ods, ML techniques provide more efficient and accurate so-
lutions. For example, ML-based multi-scale modeling pre-
dicts the thermal conductivity of CNT-reinforced polymer
composites, effectively capturing the impact of structural
uncertainties on thermal conductivity by combining MD
simulations with finite element analysis, regression tree
models (RFs and gradient boosting machines), and deep
neural networks.[145]Similarly, an interpretable ML frame-
work predicts the electrical conductivity of CNT/polymer
composites using stochastic multi-scale numerical models.
This approach employs AI techniques, RFs, and extreme
gradient boosting (XGBoost) models along with Shap-
ley Additive exPlanations (SHAP) analysis to elucidate
the influence of CNT structural parameters on conduc-
tivity, offering a robust theoretical framework for mate-
rial design optimization.[146]Another study applied ANN
models to accurately predict the electrical conductivity of
CNT-reinforced polymer composites, reducing computa-
tional costs while maintaining predictive accuracy across
various conductive network structures.[147]
Modeling the structure-property relationship is critical
for understanding the behavior of carbon-based nanoma-
terials. ML is particularly adept at capturing the non-
linear relationships between complex structures and their
properties, facilitating the design and optimization of new
materials. For instance, a DL model called CNTNeXt,
based on multi-layer synthesized images, predicts the me-
chanical properties of vertically aligned CNT (VACNT)
forests. By utilizing a ResNeXt feature extractor paired
with an RF regression model, the model improves predic-
tion accuracy by generating 2.5D morphological images
that simulate real VACNT structures, enhancing under-
standing of CNT self-assembly processes.[148]Addition-
ally, a neural network-based surrogate model (NN-EBE)
efficiently predicts higher-order phenomena such as buck-
ling and nonlinear deformation for CNTs, providing com-
putational advantages over traditional micromechanical
models, particularly for large-scale simulations in com-
posite material design.[149]For electronic property predic-
tions, ML predicts the electronic properties of graphene
nanosheets based on geometric features. Using the density
functional tight binding (DFTB) method to generate data,
this approach applies linear regression, multilayer percep-
trons (MLPs), and support vector machines (SVMs) to
efficiently identify graphene structures with desirable elec-
tronic properties, aiding high-throughput material screen-
ing in electronic applications.[150]
In terms of interface design and load transfer in com-
posites, ML models have proven to be effective in opti-
mizing chemical linkages and the mechanical behavior of
CNTs within composites. Alred et al. employed ML mod-
els to predict the electron density and mechanical proper-
ties of sulfur cross-linked CNTs.[151]By generating train-
ing data from DFT and MD simulations, the study utilized
MLP neural networks and RF models for accurate pre-
dictions, significantly reducing computational costs. This
research highlighted the importance of ML in interface de-
sign for CNT composites.
027403-9

Chinese Physics Letters 42, 027403 (2025) Review
ML techniques can also be applied to optimize the
biocompatibility of carbon-based nanomaterials, partic-
ularly in predicting their biocompatibility and toxicity.
Singh et al. explored the use of AI and ML to address
the limitations of traditional experimental methods, which
are often time-consuming and costly. By combining ex-
tensive experimental validation data with CNT physical
properties (e.g., length, diameter, surface functionaliza-
tion) and the chemical composition of polymers, they de-
veloped predictive models for biocompatibility and toxi-
city. Using ANN, RF, and XGBoost models, with ANN
excelling in capturing the complex interactions between
CNTs and biological systems, the study utilized K-fold
cross-validation and regularization techniques to improve
generalization, whereas SHAP analysis was used to further
enhance model interpretability.[152]The results demon-
strated the efficiency of the ANN in predicting toxicity
responses, significantly reducing experimental time and
cost while revealing critical relationships between the CNT
structure and biocompatibility. This research was the first
application of AI and ML in predicting nanomaterial bio-
compatibility, offering a novel tool for efficient toxicity as-
sessment in future material design.
In the future, the continued advancement of ML and
DL technologies will further automate and enhance the
inverse design of carbon-based nanomaterials. Automated
experimental platforms, combined with intelligent experi-
mental planning, will accelerate the synthesis and screen-
ing of materials, particularly in complex multi-variable
systems. Future active learning algorithms will dynam-
ically update models with real-time feedback, improv-
ing design efficiency. In multi-scale modeling, future ap-
proaches will better integrate micro- and macro-scale fea-
tures through the combination of first-principles calcula-
tions, MD simulations, and experimental data, establish-
ing comprehensive multi-scale prediction frameworks. Ad-
ditionally, the interpretability of ML models will become
increasingly important, particularly in high-risk fields such
as biomedicine and environmental safety, ensuring trans-
parency and accountability in decision-making processes.
Interdisciplinary collaboration will be pivotal in advanc-
ing carbon-based nanomaterial design, with the conver-
gence of computational science, materials science, and
biomedicine driving further innovations. In conclusion,
future ML technologies will significantly improve the ef-
ficiency of carbon-based nanomaterial design, accelerating
the transition from laboratory research to industrial ap-
plications and creating new avenues for the discovery and
development of novel materials.
2.5. Two-Dimensional Materials. 2D materials con-
sist of only one to a few atomic layers in the direction
of thickness, and they have the potential to extend in-
definitely in the plane. These materials are characterized
by their unique physical and chemical properties, which
differ significantly from their bulk counterparts. Differ-
ent layers of materials can be adhered together by van
der Waals forces. Materials that rely solely on these in-
terlayer van der Waals interactions, without any cova-lent bonds between the layers, are referred to as van der
Waals heterostructures. These heterostructures combine
the unique properties of individual 2D layers to create ma-
terials with tailored functionalities, making them promis-
ing for a wide range of applications in electronics, photon-
ics, and nanotechnology.[153]
Because of the extremely small thickness, the move-
ment of electrons in 2D materials is highly constrained,
resulting in the quantum confinement effect. This ef-
fect often results in novel physical properties, mak-
ing 2D materials of significant interest in fields such
as electronics,[154‚Äì156]spintronics,[157]valleytronics,[158]
optoelectronics,[159]twistronics,[160]and slidetronics.[161]
Common examples of 2D materials include graphene,
which consists of a single layer of carbon atoms arranged
in a honeycomb lattice.[162]Another important class of
2D materials is transition metal dichalcogenides, typically
composed of one layer of transition metal atoms (such
as Mo or W) sandwiched between two layers of chalco-
genide atoms (such as S, Se or Te).[163]For van der Waals
heterostructures, interlayer coupling can be performed by
regulating the interaction between different 2D material
layers.[164]By changing the number of layers and the stack-
ing order, the properties of the van der Waals heterostruc-
tures can be fine-tuned, and 2D materials can be con-
verted into topological insulators through specific layering
structures.[165]
Currently, experimental methods for obtaining single-
or multi-layer 2D materials include exfoliating them from
3D bulk materials or directly growing them on substrates
using CVD. Exfoliation techniques involve peeling off in-
dividual layers from bulk materials, whereas CVD en-
ables the controlled growth of 2D materials on various
substrates.[166,167]However, discovering new 2D materials
through experimental methods can be resource-intensive
and time-consuming, requiring significant investment in
both materials and research efforts. ML can learn to cap-
ture material features from a large number of crystals, thus
guiding the synthesis of new 2D materials.[168,169]
Topological insulators are a typical category of 2D ma-
terials; they behave as insulators in the body but exhibit
electrical conductivity at the surface or edge. This unique
property results from the topological properties of the ma-
terial, i.e., the electron band structure of the material has a
special topological invariant mathematically. In 2D topo-
logical insulators, the spin and momentum of electrons are
locked together to form edge states. This phenomenon is
called the quantum spin Hall effect.[170,171]Topological in-
sulators have a wide range of applications, including field-
effect transistors in electronics, efficient optoelectronic de-
vices in optics, topological qubits in quantum computing
to enhance the stability of quantum systems, and mag-
netic topological insulators in magnetism. However, ow-
ing to the lack of sufficient candidate materials, the re-
search on topological insulators is limited. In traditional
methods, materials are evaluated individually through a
trial-and-error process, making the search of the mate-
rial space resource-intensive and time-consuming. Thus,
027403-10

Chinese Physics Letters 42, 027403 (2025) Review
a pipeline for determining new 2D topological insulators
was developed.[172]With this method, 56 topological ma-
terials were identified, of which 17 are quantum spin Hall
insulators, nine have not been reported in the literature,
and three exhibit large energy gaps suitable for room-
temperature applications.
Van der Waals heterostructures are another category
of materials that have attracted interest; they consist
of 2D materials that are combined. However, compu-
tational screenings have suggested that the number of
possible 2D materials could be in the thousands, re-
sulting in potentially millions of distinct heterointer-
face combinations.[173,174]Subsequently, a computational
database, web applications, and ML models have been
developed to accelerate the design and discovery of 2D
heterostructures.[175]Based on 674 non-metallic 2D mate-
rials, they generate 226,779 heterostructures classified into
three types, of which type-II was observed to be the most
common and type-III the least common. Other researchers
can also use their network applications and ML model to
generate 2D heterostructures and predict physical proper-
ties of the new 2D heterostructures.
AI-Driven Experiments. With AI-assisted experimen-
tal procedures, 2D thin film materials can be synthesized
through automatic control.[176]Specifically, the growth
conditions are selected by the experimenter to initialize
the algorithm, which then autonomously grows 125 sam-
ples. The process is about ten times faster than the tra-
ditional one. In addition to supervised learning styles,
with the existing positive samples and a large number
of unlabeled samples, an ML model can be trained us-
ing semi-supervised or unsupervised learning.[177]A large
number of potential 2D materials with known properties
can be screened through high-throughput clustering. This
approach can aid in the design of new 2D materials.[178]
Additionally, the query strategy of AI can be optimized
based on reinforcement learning, and the classification per-
formance of the model through rewards can be improved.
Moreover, through the framework of active learning, only
a limited number of labels can be iteratively obtained and
updated more positive sample labels.[179]
The research described above used ML models to di-
rectly design crystal structures, which can aid researchers
identify 2D materials of interest. Additionally, experi-
menters can be indirectly assisted in synthesizing new 2D
and quasi-1D materials by training an ML model to con-
trol the parameters of CVD through the integration of AI
in the experimental process.[180,181]They can also predict
the probability of synthesizing new materials based on the
parameters of a given CVD and recommend the most fa-
vorable parameters.[182]
2D Materials Datasets. Currently, the number of
known 2D materials is still relatively limited, far fewer
than the number of 3D bulk materials. Therefore, the
construction of a comprehensive 2D material database is
a crucial task in condensed matter physics. The Compu-
tational 2D Materials Database (C2DB) is a database for
2D material discovery that is aided by ML.[183,184]C2DBfirst generates new crystals by replacing experimentally
known crystal structures with reasonable atoms. Subse-
quently, stable materials are selected through a series of
steps, including structural relaxation, deduplication, and
stability calculation using DFT. Finally, stable materials
are screened to build a 2D material database. 2DMatPe-
dia selects 3D materials with layered structures from the
Materials Project database through high-throughput topo-
logical analysis. It generates new materials by performing
atomic replacements after stripping the layers. Stable ma-
terials are then identified through DFT calculations and
added to its database.[185]
Moreover, AI can also be used to replace the DFT cal-
culation part in the construction of 2D material databases.
With discriminative AI models, the properties of 2D ma-
terials can be directly predicted and classified.[186,187]A
2D perovskite database can predict band gaps and atomic
charges using ML models.[188]This demonstrates that ML
can assist in the design of new 2D mixed perovskite mate-
rials through material classification.
Furthermore, new 2D materials can be generated and
their properties can be predicted directly using AI, with-
out requiring traditional computational methods such as
DFT. The fabrication of solid-state devices with tailored
optoelectronic, quantum emission, and resistive proper-
ties requires the design of 2D materials with point de-
fects. Owing to the strong correlation effect of electrons
and the exponential growth of the defect site search space,
traditional methods cannot determine these 2D materi-
als on a large scale. Through deep transfer learning, an
ML model is first pre-trained on 3D materials and then
used to predict 2D materials that are likely to produce
effective point defects. Based on these predicted 2D ma-
terials, another ML model is trained to map these mate-
rials from the initial graph structure to calculated defect
properties.[189]In addition, manual data extraction from
publications is the mainstream method for collecting 2D
materials. However, through natural language processing
and text mining technologies in the field of AI, crystals
with interesting properties can be automatically extracted
from publications.[190,191]
2.6. Photovoltaic Materials. Photovoltaic conversion
is one of the most important energy conversion meth-
ods mastered by humanity, enabling us to ‚Äústore light.‚Äù
The search for high-performance photovoltaic materials
has long been a crucial pursuit. Not only do they pro-
vide support for lighting and display but they also con-
tribute to reducing dependence on fossil fuels, thereby
having a profound impact on addressing global climate
change. The essence of ‚Äústoring light‚Äù lies in capturing
excitons generated by photons. Enhancing photovoltaic
conversion efficiency (PCE) generally involves two main
strategies: improving photon-to-exciton conversion effi-
ciency and designing effective junctions to capture exci-
tons. Photovoltaic conversion works operated in both di-
rections, and these improvements have the potential to
inspire new applications in fields such as solar cells, light-
emitting diodes (LEDs), laser diodes, photodetectors, and
027403-11

Chinese Physics Letters 42, 027403 (2025) Review
photocatalysis.
Currently, monocrystalline silicon is the most main-
stream photovoltaic material. It is widely used in ground-
based photovoltaic power generation owing to its relatively
high power generation efficiency (27.3\%[192]) and long ser-
vice life. However, it suffers from several limitations. In
classical studies, the ideal bandgap for single-junction so-
lar cells is approximately 1.34 eV, which can theoretically
achieve a maximum efficiency of 33.7\%.[193]However, the
bandgap of monocrystalline silicon is approximately 1.1 eV
and cannot be adjusted.[194]To address these limitations,
Wang et al.[195]successfully identified 22 silicon crystal
structures with direct bandgaps through high-throughput
calculations and ML methods, overcoming the limitations
of traditional diamond-like silicon materials. They uti-
lized the Carbon-24 dataset to construct initial silicon
structures and optimized them using ML potentials, such
as the GPUMD neural evolutionary potential, resulting
in 2,637 stable silicon crystals. Subsequently, the elec-
tronic structures were predicted using an ML Hamilto-
nian model (HamGNN),[196]and structures with direct
bandgaps were selected. These structures were then vali-
dated through DFT calculations for their bandgaps, tran-
sition dipole moments, and other properties. Ultimately,
the researchers confirmed 22 stable direct bandgap silicon
structures, several of which exhibit higher bandgaps and
potential for photovoltaic applications, providing a new
theoretical foundation for the design of silicon-based op-
toelectronic devices. The second is indirect bandgap. It
requires phonons as a medium for light absorption, result-
ing in lower absorption efficiency and making it difficult to
reduce the material thickness.[194]The final one is the high
sensitivity to impurities. Although the silicon industry is
mature, producing high-purity monocrystalline silicon re-
mains costly.[197]
III-V compounds represent another important class
of photovoltaic materials as they offer significant advan-
tages over silicon in certain applications. These com-
pounds have direct bandgaps that can be precisely tuned
through doping, enabling their use across a broad spec-
trum of optoelectronic devices.[198]For instance, gallium
nitride (GaN), with a bandgap of approximately 3.4 eV,
is widely utilized in blue and ultraviolet LEDs,[199,200]
whereas gallium arsenide (GaAs), with a bandgap of about
1.42 eV, is commonly applied in red LEDs.[200]III-V com-
pounds exhibit superior thermal stability, high defect tol-
erance, and exceptional efficiency, making them particu-
larly suitable for applications in extreme environments,
such as space-based photovoltaics.[201]Despite these ad-
vantages, III-V compounds also pose challenges, includ-
ing high production costs, the inclusion of toxic elements,
and moderate chemical stability, which may limit their
widespread adoption.[198,202]In the exploration of next-
generation photovoltaic materials, perovskites and organic
solar cells (OSCs) stand out as two prominent directions.
Perovskite Materials. Perovskite materials have been
some of the most important subjects of study in materi-
als science owing to their outstanding optoelectronic prop-erties and complex crystal structures.[203,204]The term
‚Äúperovskite‚Äù refers to the materials that share the crys-
tal structure of calcium titanate (CaTiO 3), an inorganic
perovskite, characterized by a general chemical formula of
ABX 3, where A and B are cations, and X is an anion that
bonds with both cations.[205]These materials typically
adopt a cubic structure, but various distortions can result
in alternative configurations.[205]Such structural flexibil-
ity enables the incorporation of a wide range of elements,
making the perovskite family remarkably diverse, with po-
tentially tens of thousands of possible compositions. More-
over, when considering element substitution and doping,
the number of potential perovskite variants could exceed
millions.[206]
The surge of interest in perovskites began with early
demonstrations of their potential in solar cells, and the
power conversion efficiency (PCE) of perovskite solar
cells (PSCs) has increased dramatically over the past
decade, reaching certified values above 25\%.[207]This ex-
ceptional performance is largely owing to the unique prop-
erties of perovskites, such as their high light absorption co-
efficients, direct and tunable bandgaps, high charge-carrier
mobilities, and long carrier diffusion lengths. However,
the prototypical organic‚Äìinorganic hybrid lead halide per-
ovskites are highly sensitive to environmental factors, in-
cluding moisture, oxygen, and temperature, and their per-
formance depends on the presence of toxic lead. Conse-
quently, current research is increasingly focused on iden-
tifying stable, non-toxic alternatives to traditional lead
halide perovskites. Addressing these challenges will be
crucial for transitioning perovskites from the laboratory
to practical optoelectronic applications.
ML has demonstrated significant potential in acceler-
ating the discovery of high-performance perovskite mate-
rials, particularly in terms of predicting photovoltaic ef-
ficiency and identifying stable synthesizable structures.
Various ML models have been successfully deployed to
predict key properties of PSCs, including the PCE, short-
circuit current density, open-circuit voltage, fill factor, and
external quantum efficiency.[208]In a recent study, several
models were compared for PCE prediction, and XGBoost
was identified as the most accurate.[209]Furthermore, XG-
Boost has also been utilized to predict recombination losses
in PSCs, revealing insights into dominant recombination
mechanisms.[210]
Beyond performance prediction, ML is essential in as-
sessing structural stability and guiding the synthesis of
promising candidates. ML interatomic potential (MLIP)
models have been developed to predict the crystal struc-
tures of hybrid organic‚Äìinorganic perovskites (HOIPs), en-
abling researchers to evaluate the stability of these com-
pounds accurately.[211]Additionally, MLIP has been ap-
plied to explore the dynamic behaviors of metal halide
perovskites, shedding light on their structural charac-
teristics under different conditions.[212]Through a com-
bination of ML and MD simulations, researchers have
also investigated the stability of HOIPs.[213]Moreover,
ML methods are actively used to identify synthesizable
027403-12

Chinese Physics Letters 42, 027403 (2025) Review
PSCs, which is crucial for material validation in practi-
cal applications.[214]Additionally, ML aids in the search
for non-toxic perovskite materials as well. Active learn-
ing has been applied to identify lead-free white-light LEDs
by training models on oxide perovskites and datasets se-
lected from six halide perovskites using active learning
methods.[215]This study successfully predicted photolu-
minescence quantum yield (PLQY), observing a signifi-
cant correlation between ionic radii and PLQY. A sim-
pler ML model has also been applied to identify non-toxic
PSCs,[216]focusing on the importance of the ùëë10orbital in
double perovskite doping. Improving interpretability and
identifying chemical patterns is another key area of devel-
opment in perovskite-related ML research. Genetic algo-
rithms (GAs) have been used as a pre-screening tool to
aid graph convolutional networks (GCNs) in bandgap pre-
diction, facilitating the identification of relevant chemical
trends.[217]Moreover, decision tree models have been en-
hanced to improve interpretability in applications to solid-
state chemistry, enabling researchers to identify significant
descriptors across diverse materials, including perovskites,
spinels, and rare-earth intermetallics.[218]
Organic Solar Cells. OSCs represent another promi-
nent class of next-generation photovoltaic materials.
While inorganic materials are known for their efficiency
and durability, their production can be costly. In con-
trast, OSCs offer distinct advantages, such as lightweight
and flexible structures that can be easily fabricated into
various shapes and sizes, along with the potential for low-
cost and scalable production. However, OSCs generally
have lower efficiency and shorter lifetimes, presenting a
significant challenge for widespread adoption.[219]The pri-
mary device architecture is bulk-heterojunction, which fea-
tures an active layer composed of interpenetrating net-
works of donor and acceptor materials, which facilitates
efficient charge separation and transport.[220]The initial
breakthrough in acceptor materials occurred with the use
of fullerene derivatives, such as C 60,[221]which exhibited
promising efficiency and laid the groundwork for further
advancements in OSCs. Soluble fullerene-based acceptors
such as PC 61BM and PC 71BM have since been developed
and attracted significant interest. However, the inherent
limitations of fullerene acceptors, such as weak absorption
in the solar spectrum, difficulty in tuning energy levels,
and the propensity for aggregation and crystallization‚Äì
have hindered their further development and highlighted
the need for alternative materials.[222]
Recently, the focus has shifted toward non-fullerene
acceptors (NFAs), which have demonstrated significant
promise owing to their tunable energy levels, improved ab-
sorption properties, straightforward synthesis, and better
morphological stability. A major milestone was reached
in 2019 with the introduction of Y6,[223]a new bench-
mark NFA that achieved a PCE of 18\%,[224]attracting
widespread interest for its high performance. Since its
introduction, Y6 and related NFAs have become a cen-
tral topic in the field, with research efforts dedicated to
further improving performance, understanding the under-lying mechanisms responsible for the high efficiency, and
exploring new applications. The next phase of develop-
ment in OSCs will likely involve optimizing Y6 derivatives
to further enhance performance and stability, as well as the
continued search for novel NFAs with unique properties.
These efforts aim to push the limits of efficiency while ad-
dressing the remaining challenges related to the lifetime of
organic solar cells, laying the foundation for more practical
and commercially viable OSC technologies. In materials
science, decision tree algorithms have been widely utilized
to accelerate the discovery of new materials, particularly
for predicting optical and electronic properties of molecules
and materials. The general workflow typically includes
collecting molecular datasets, mapping molecular struc-
tures to descriptor spaces, and then employing ML mod-
els to learn and predict key properties such as PCE. This
approach has been applied extensively in various studies.
RF has been used to predict the PCE for NFAs,[225]aid-
ing in the development of new acceptor materials for MP6
donors. In Ref. [226], RF was applied to predict the short-
circuit current density (JSC), assisting in the creation of
new donor molecules compatible with NFAs. Addition-
ally, XGBoost is leveraged for high-throughput screening
to predict PCE for DA pairs.[227]
Comparative studies have also been conducted on vari-
ous decision tree models, with RF often emerging as advan-
tageous in PCE prediction. RF is used to screen and pre-
dict performance for NFA and broader DA pairs.[228,229]
Meanwhile, other studies have observed that gradient
boosting models exhibit superiority in predicting JSC and
open-circuit voltage (VOC), as noted in Ref. [231]. To
further enhance model performance, some studies have ex-
plored algorithmic improvements. In a recent study,[232]
an RF‚Äôs PCE predictions for NFAs were observed to be
enhanced by the introduction of artificial failure data. An-
other approach integrates geometric GNNs, automatically
extracting features from molecular structures, and then
uses decision tree models (such as LightGBM) as a back-
end for analysis, as described in Ref. [233]. Additionally,
owing to the lag in available datasets, leveraging LLMs to
retrieve literature can expand material libraries and accel-
erate the discovery of novel materials, which is shown in
Ref. [230].
2.7. Catalyst Materials. Catalyst materials are sub-
stances that can alter the rate of a chemical reaction. Note
that catalysts are not themselves involved in the final prod-
uct of the reaction; however, they accelerate or decelerate
the rate of the reaction by modifying the path of the re-
action and reducing the activation energy required for the
reaction to occur. A catalyst retains its chemical nature
and quality both before and after a reaction; therefore, it
can be reused on numerous occasions.
The history of the application of catalysts can be
traced back several hundred years. Over time, catalyst
technology has developed in a direction that is increas-
ingly efficient, environmentally friendly, and sustainable.
It has contributed significantly to various fields, including
the chemical industry, energy, environmental protection,
027403-13

Chinese Physics Letters 42, 027403 (2025) Review
life science, and medicine. Recently, the field of material
synthesis has undergone accelerated development, largely
owing to the advent of advanced AI technologies. The syn-
thesis of catalyst materials has been no exception to this
trend. Owing to the extensive scope of catalyst materials
and the diverse applications of corresponding ML technol-
ogy, selecting a representative sample of work for presen-
tation is deemed prudent, considering the limitations of
author‚Äôs knowledge in this field.
Descriptors are important in improving the accuracy
of ML models. While ML techniques can improve the ac-
curacy of predictions, descriptors often determine the up-
per limit of the prediction.[234]Some researchers focus on
searching for additives in the electrochemical deposition of
copper catalysts for the reduction of CO 2(CO2RR).[235]
Selecting an appropriate combination of additives for the
preparation of the catalyst is a challenging process. To
solve this problem, scholars have devised a strategy com-
prising three rounds of learning, integrating experimental
outcomes and ML and subsequently applied it to an ad-
ditive library. The process enabled researchers to identify
crucial chemical components and to synthesize the requi-
site molecules. This research represents a significant con-
tribution to the field of experiment-based descriptors.
Furthermore, the descriptors for product selectivity in
the oxidative coupling of methane (OCM) reaction were
analyzed using ML and physical quantities derived from
the periodic table.[236]One of the principal objectives of
this study was to investigate the selectivity of C 2H4/C2H6
(C2s). The process employs the use of hierarchical cluster-
ing, RF classifier, and support vector classifier. Eventu-
ally, three previously unreported catalysts with high C 2s
were identified as potential candidates, i.e., Ti-V-Ce-BaO,
Y-Y-Eu-TiO 2, and La-Pr-Hf-BaO, and their performance
was verified through experimental analysis. The authors
additionally examined five additional related descriptors.
They additionally examined five related descriptors and
concluded that high C 2s values are associated with low
first ionization energies, electron affinities, and electroneg-
ativities, as well as high second ionization energies and
densities.
In addition to experiment-based descriptors, some
studies have utilized theory-guided descriptors. The sure
independence screening and sparsifying operator (SISSO)
descriptors are expressed as nonlinear functions of in-
trinsic properties of the clean catalyst surface.[237]The
authors demonstrated that their method was more gen-
eral and accurate in predicting the adsorption energy
of alloys on mixed metal surfaces, even when based
on training data that included only pure metals. If a
considerable number of features are available, the com-
pressive sensing method SISSO represents an appropri-
ate solution.[238]This approach has also been applied
to study other materials, including perovskite oxides
and halides[239]and doped transition metal oxides.[240]
However, this method still has some limitations, such
as the presence of nearly degenerate models, stability
challenges under data perturbations, and unclear physi-cal interpretations.[241]Extensive research has been con-
ducted on theory-guided descriptors from other perspec-
tives, such as intrinsic atomic properties,[242]electronic
and structural properties,[243‚Äì245]and others.[246‚Äì248]Sim-
ilarly, efforts have been made to identify descriptors that
integrate theoretical and experimental data.[249‚Äì252]
Additionally, research has been conducted from alter-
native perspectives on the subject of catalysts. For exam-
ple, the utilization of active learning in conjunction with
DFT calculations to develop an efficient copper-aluminum
electrocatalyst for the conversion of CO 2to ethylene is
remarkable.[253]This approach has resulted in the highest
reported Faradaic efficiency to date. In their study, the
researchers employed probabilistic models with Gaussian
processes, trained with ùëéùëè ùëñùëõùëñùë°ùëñùëú data and a set of multi-
fidelity features, to identify high-performance ABO 3-type
cubic perovskites that can catalyze the oxygen evolution
reaction (OER).[244]The method has successfully iden-
tified several known perovskites, which demonstrate su-
perior performance to the benchmark LaCoO 3. A se-
ries of perovskites with favorable properties have also
been obtained, including KRbCo 2O6, BaSrCo 2O6, and
KBaCo 2O6.
The discovery of single-atom alloy catalysts (SAACs)
represents a significant area of focus within the scientific
community.[254]In this particular study, they combined
first-principles calculations with compressed-sensing data-
analytics methodology. With this approach, they final-
ized more than 200 unreported candidate SAACs, some of
which exhibit greater stability than previously observed.
Concurrently, their investigation highlighted the signifi-
cance of data analysis in avoiding bias in catalytic design.
A recent publication presented an active learning
workflow for the generation of fuel cell catalysts.[255]
The authors focused on ternary alloys in the form of
Pt2CoM (in the practical application of proton exchange
membrane fuel cells, PtCo is the most promising alloy cat-
alyst, whereas M represents another base metal element).
Guided by theoretical calculations, the researchers ulti-
mately prepared the Pt 2CoCu and Pt 2CoNi compounds
through experimental synthesis. These materials exhib-
ited a large electrochemically active surface area of ap-
proximately 90 m2/gPtand a high specific activity of ap-
proximately 3.5 mA/cm2.
Chen et al. leveraged local ML capabilities to rapidly
and accurately identify structure descriptors by integrat-
ing fundamental physical attributes with graph convolu-
tional neural networks (CGNNs).[256]They successfully
identified 43 high-performance alloys as electrocatalysts
for the hydrogen evolution reaction, with some candidates
already validated. To further validate the method‚Äôs pre-
cision, they conducted a comprehensive study of AgPd
through ab initio calculations in a realistic electrocatalytic
environment.
An intriguing prospect emerged from the utilization of
language models in catalyst discovery.[257]The discovery
of catalyst materials was presented with the aid of an LLM,
designated CatGPT. The focus is on the two-electron oxy-
027403-14

Chinese Physics Letters 42, 027403 (2025) Review
gen reduction reaction (2e-ORR), with the model being ap-
plied to identify the catalyst for this process. Ultimately,
several materials that were not present in the database
were identified, including RhSe, CdAg, and SnAu.
The field of technology catalysts is vast, encompass-
ing a multitude of applications for ML technology and
its associated techniques. The aforementioned examples
represent a selection of the most influential or recently
developed outcomes, and a comprehensive account of all
relevant findings is beyond the scope of this discussion.
2.8. High-Entropy Alloys. High-entropy alloys (HEAs)
are a class of innovative materials fabricated from five or
more elements in nearly equal proportions. The traditional
concept of creating alloys is to add reinforcing elements
to a metal, which has been used extensively throughout
human history. In 2004, the discovery of HEAs offered
a distinctive alloying strategy.[258,259]These new materi-
als are referred to as HEAs owing to their increased con-
figurational entropy, which was considered to be the key
factor in their stabilization. Although configurational en-
tropy was later identified to not be as important as first
assumed.[260,261]HEAs have many excellent mechanical
properties and a large component space, which provides
a suitable platform for material research.
However, for the design of HEAs, conventional meth-
ods encounter significant challenges. Considering only the
usual elements of the periodic table, this encompasses
a significantly large composition space, which cannot be
managed using conventional material design approaches,
such as the calculation of phase diagrams and DFT.[262]
ML has developed rapidly over the past decades, which
suggests that it is likely to make a difference in the area
of material design for HEAs.[34]Some researchers utilized
several ML models including some simple deep neural net-
works and selected a conditional random search as the in-
verse predictor to design the new HEAs.[263]They suc-
cessfully observed two HEAs with better ultimate tensile
strength and total elongation than the input datasets. An
SVM was also utilized to solve problems of HEAs.[264]In
their approach, the authors emphasized the framework of
hyperparameter tuning and the use of weighted values.
Through experiments, they discovered that their architec-
ture performed very well and even exceeded the results
of an ANN. Some studies have compared the effectiveness
of different methods. Huang et al. tested three differ-
ent ML algorithms, namely K-nearest neighbors (KNNs),
SVM, and two ANNs, i.e. unsupervised self-organizing
maps and supervised multi-layer feed-forward neural net-
work (MLFFNN).[265]They concluded that MLFFNN per-
formed better. Krishna et al. tested logistic regression,
decision tree, SVM, RF, gradient boosting classifier, and
ANN. They claimed that the ANN exhibited the highest
accuracy.[266]
All of the above-mentioned studies attempted to em-
ploy ML techniques but did not fully incorporate the char-
acteristics of HEAs. The dataset for HEAs is not suffi-
ciently large; therefore, architectures that can be trained
from small samples to produce sufficiently adaptive struc-tures are required. Some recent studies have considered
this problem to some degree.
The first aspect to mention is active learning. A typ-
ical example demonstrated the successful implementation
of an iterative approach for the synthesis of new HEAs.[262]
Their workflow was a closed loop in which ML techniques,
DFT, thermodynamic calculations, and experiments were
used in the process. Their research focused on the design
of high-entropy Invar alloys with low thermal expansion
coefficients (TECs), and they investigated FeNiCoCr and
FeNiCoCrCu HEAs. Their data showed that the HEAs
have lower TECs and higher configurational entropy than
past materials. In addition to the ability of discovering
new HEAs, one of the greatest strengths of this workflow
is its efficiency: the entire process of their work took only a
few months, whereas in the past, the corresponding discov-
eries could have taken several years and more experiments.
Note that other efforts have proposed frameworks with a
similar structure.[267]
Some researchers employed a deep network architec-
ture with residual connections to predict the phase forma-
tion in HEAs.[268]Compared with traditional neural net-
works, the overall accuracy of this framework could reach
81.9\%. This research provided a new approach for predict-
ing the phase formation of HEAs and is also significant for
designing new HEAs.
Wang et al. devised a novel type of neural network
called the elemental convolution neural network (ECNet),
which can attain global element-wise representations.[269]
The authors investigated FeNiCoCrMn/Pd systems us-
ing ECNet and the data obtained using DFT calcula-
tions. The authors also used transfer learning to enhance
the performance of the network. With this framework,
the concentration-dependent formation energies, magnetic
moments, and local displacements in various sub-ternary
and binary systems could be obtained.
The application of ML to the analysis of materials mi-
crostructure provides a basis for the reverse engineering
of alloys, which is then integrated with the accumulated
knowledge of human experience. As a result of employ-
ing their own methodologies, Pei et al. identified a novel
alloy, provisionally named 9\% Cr steel.[270]The authors
posited that the success of the approach can be attributed
to the optimization of neural network structures and the
fine-tuning of associated parameters.
Some of the studies described above effectively miti-
gated the problem of small size of datasets. However, the
quality of the datasets and the selection of appropriate ML
techniques remain problematic.
2.9. Porous Materials. Porous materials are a class of
materials with a pore structure filled with holes or voids
of varying sizes. The size, shape, and distribution of the
pores determine the properties of the material. Porous
materials typically have a high specific surface area, low
density, and good adsorption capacity, which enables them
to have a wide range of applications in various fields, such
as the chemical, energy, environment, and biomedicine in-
dustries. Zeolites are a representative class of porous mate-
027403-15

Chinese Physics Letters 42, 027403 (2025) Review
rials. Newly emerging porous materials, including MOFs,
covalent organic framework materials (COFs), and carbon-
based porous materials, have expanded the range of appli-
cations of porous materials.[271,272]
In recent years, significant developments have been
achieved in the field of AI, with notable advances in the
area of porous material synthesis. Because zeolites were
synthesized earlier and are more widely used than other
porous materials, it is unsurprising that research has been
conducted into the AI-assisted synthesis of zeolites. In
their study, Kim et al. employed a generative adversarial
network, designated ZeoGAN, to generate 121 crystalline
porous materials.[10]The neural network receives inputs
in the form of energy and material dimensions. The re-
sults demonstrated that zeolites with a desired range of
4 kJ/mol methane heat of adsorption can be produced re-
liably. Four years later, a study employing diffusion mod-
eling in the context of porous materials was conducted,[273]
and the corresponding architecture is known as ZeoD-
iff. The authors asserted that the diffusion model out-
performs the ZeoGAN with respect to structural validity,
exhibiting an improvement in performance of over 2000-
fold. Furthermore, the authors implemented conditional
generation, namely the generation of structures with user-
desired properties, with ZeoDiff. To achieve conditional
generation, they had to perform adjustments to the net-
work, such as integrating an additional channel that was
closely relevant to the property of interest.
The synthesis of MOFs is a more complex and chal-
lenging process than that of zeolites. Over 100 known
species of atoms can form MOFs, with an average number
of atoms per unit cell that is significantly higher than that
of zeolites. The variation autoencoder (VAE) has been
successfully applied for generative modeling of MOFs.[274]
A VAE framework, designated SMVAE, was employed to
generate MOFs. The structural validity of SMVAE was
demonstrated to be 61.5\%. By focusing on the adsorp-
tion capacity of CO 2in their model, the authors demon-
strated its ability to modulate the CO 2adsorption capac-
ity and selectivity. The top-performing MOF they discov-
ered has a CO 2capacity of 7.55 mol/kg and a selectivity
over CH 4of 16. A generative AI framework called GHP-
MOFassemble was proposed in the study.[275]The GHP-
MOFassemble method was employed to synthesize MOF
linkers, which were then utilized with one of three pre-
selected metal nodes (Cu paddlewheel, Zn paddlewheel,
Zn tetramer) to form MOFs with a primitive cubic topol-
ogy. The linker molecules were generated through the uti-
lization of DiffLinker.[276]Molecular fragments with high
expression levels were extracted from an existing database.
The aforementioned molecular fragments were employed
to obtain linkers, which in turn facilitated the generation
of MOFs. Subsequently, the MOFs were evaluated using
a predictive model, resulting in the identification of six
MOFs with a CO 2capacity exceeding 2 mmol/g, indica-
tive of high performance. Researchers developed a coarse-
grained (CG) diffusion model, designated MOFDiff, whichcan generate CG MOF structures through a denoising dif-
fusion process.[277]The authors proposed that template-
based methodologies can constrain the search space and
preclude the inclusion of viable materials. Consequently,
they devised a process for generating MOFs that entails
the direct identification of coarse-grained building blocks
within 3D coordinates. As a subsequent processing stage,
an additional MOF assembly procedure is necessary to
orientate the components and ascertain the interconnec-
tivity between them. The utilization of MOFDiff has en-
abled the identification of potential candidates for high
CO2working capacities, with nine of the current top ten
being generated by this framework. A recent study used
signed distance functions (SDFs).[278]They introduced a
latent diffusion model, MOFFUSION, which utilizes SDFs
as the input representation of MOFs. The model demon-
strated a high structural validity of 81.7\%. Additionally,
the authors revealed its capacity for conditional genera-
tion across a range of data modalities, including numeric,
categorical, text data, and their combinations.
In addition to zeolites and MOFs, research has been
conducted into the use of AI in the inverse design of other
porous materials. For example, a methodology employ-
ing ML approaches for the identification of highly porous
carbon materials was devised.[279]A methodology employ-
ing quantitative structure‚Äìproperty relationships in con-
junction with ML techniques to forecast the properties
of COFs was developed. This methodology utilizes the
structural characteristics of the solvents and COF build-
ing blocks.[280]Furthermore, the integration of ML with
porous media has facilitated several advancements across
diverse research domains.[281,282]The application of ML
technology in the synthesis of porous materials is now
widely acknowledged. Further attempts are currently un-
derway.
3. Development of AI Methods in Materials Science.
In this chapter, we present a comprehensive review of the
advancements in AI technologies within the field of mate-
rials science. Drawing upon recent trends and the growing
significance of AI, we explore traditional ML methods, geo-
metric GNNs, discriminative AI, generative AI, and LLMs.
As depicted in Fig. 4, GNNs are classified into invariant
and equivariant models. Invariant GNNs are extensively
applied in discriminative AI to predict material properties,
thereby enabling high-throughput screening. In contrast,
equivariant GNNs are predominantly employed in gener-
ative AI to facilitate structural predictions of materials.
Next, we provide a detailed overview of the development
of these algorithms and their applications in materials dis-
covery.
3.1. Traditional Machine Learning Methods. We cat-
egorize techniques such as RFs, convolutional neural net-
works (CNNs), SVMs, and MLPs as traditional ML meth-
ods. These algorithms are among the most commonly ap-
plied in materials discovery, with each offering distinct ad-
vantages in addressing different design challenges. RF, as
an ensemble method, combines the predictions of multiple
027403-16

Chinese Physics Letters 42, 027403 (2025) Review
decision trees to reduce the risk of overfitting from indi-
vidual trees. Its formula is given by
\^{}ùë¶=1
ùëÅùëÅ‚àëÔ∏Å
ùëñ=1‚Ñéùëñ(ùë•), (1)
where \^{} ùë¶represents the final prediction, ùëÅdenotes the
number of trees in the ensemble, and ‚Ñéùëñ(ùë•) refers to the
prediction made by the ùëñ-th tree.[283]The decision tree,
renowned for its interpretability, performs classification by
recursively splitting the data. While decision trees are
prone to overfitting, this risk can be mitigated by con-
trolling the depth of the tree. Common splitting criteria
include the Gini coefficient and entropy, with entropy de-
fined as
Entropy( ùê∑) =‚àíùëõ‚àëÔ∏Å
ùëñ=1ùëùùëñlog(ùëùùëñ), (2)
where ùê∑is the dataset, and ùëùùëñis the probability of class
ùëñin the dataset.[284]The SVM determines an optimal hy-perplane that maximizes the margin between classes; for
nonlinear data, it uses kernel functions to map data to a
higher-dimensional space, optimizing min ùë§, ùëè1
2|ùë§|2to de-
termine the hyperplane, where ùë§is the weight vector and
ùëèis the bias term.[285]The MLP is an NN with at least
one hidden layer, which minimizes the mean squared error
(MSE) via backpropagation to learn from complex data.
Its MSE formula is
MSE =1
ùëõùëõ‚àëÔ∏Å
ùëñ=1(ùë¶ùëñ‚àí\^{}ùë¶ùëñ)2, (3)
where ùëõdenotes the number of samples, ùë¶ùëñis the true
value, and \^{} ùë¶ùëñis the predicted value.[286,287]Furthermore,
the MLP utilizes nonlinear activation functions, such as
ReLU, to capture complex data features. Together, these
algorithms exhibit strong capabilities in addressing the
high-dimensional nonlinear challenges inherent in materi-
als science and design.
‚Ä¶‚Ä¶
2024
2023
2022
2021
2019

\section{CNN}

PCAMLPSVM/SVR Random
forest
Decision
treeKNNTraditional machine learning
Discriminative AI \& Invariant GNNs
Generative AI \& Equivariant GNNs
Large language modelsFlowLLM
KDD
BatteryGPT
GPT4
ChatGPTCoscientistMatAltMag
MMPT
Matformer
ALIGNN
MEGNet
SchNetCGCNN
TFNDDPM Score -based
diffusionCrystal GANLieTransformer
SE(3) -
transformeFrame
averaging
PaiNNEGHNDPA -2InvDesFlow
OMat24
CrystalFormer
LEFTNet
MatterGenDiffCSP++
DiffCSP
eSCN
SCN
TorchMD -
NetEquiformerEquiformerV2
NequIPMACEHamGNN DeepH
Cond -CDVAE
Con -CDVAE
GNoME
SyMat
Allegro
e3nn
GMN
PaiNN ClofNet
Stable
diffusion CDVAESEGNNsEGNNsGVP -GNN GraphormerECNCrystal
twins
Fig. 4. Rapid advancement of AI technologies accelerating materials discovery in various ways. Blue indicates
traditional ML; green represents the development of invariant GNNs and their application in discriminative AI for
predicting material properties; deep blue denotes the progress of equivariant GNNs, generative AI techniques, and
their integration for structural predictions; orange signifies the role of LLMs in expediting materials discovery.
In the design of nonlinear responses for mechanical
metamaterials, neural networks, when combined with evo-
lutionary strategies within an optimization framework, en-
able the precise engineering of metamaterials with speci-fied stress‚Äìstrain behaviors.[288]PCA generates a stress‚Äì
strain dataset consisting of 7,500 elements, effectively re-
ducing data dimensionality to facilitate neural network
training. With precise stress‚Äìstrain behavior design, the
027403-17

Chinese Physics Letters 42, 027403 (2025) Review
relative error in the test set is as low as 4.8\%, supporting
personalized material design for applications such as soft
robotics and energy absorption systems. This method in-
troduces innovation by controlling the nonlinear response
of metamaterials through geometric parameter optimiza-
tion, thereby enhancing the efficiency of nonlinear mechan-
ical metamaterial design and expanding their potential in
smart device applications.
In alloy optimization, multiple regression algorithms
are employed to predict the hardening curves of boron
steels, thereby improving alloy design. Using experimen-
tal hardening curve data from 62 boron steels, with in-
put variables including chemical composition, Jominy bar
distance, and material hardness as the output, a 10-fold
cross-validation was applied to evaluate various regression
algorithms.[289]The RF model had the highest correlation
coefficient and lowest error, facilitating the design of boron
steel alloys with enhanced hardening performance. This
model exhibited considerable potential for commercial ap-
plication in software such as JMatPro‚Ä†, underscoring the
significant role of ML in optimizing material performance.
In the field of optical metasurface solar absorber de-
sign, decision tree and RF regressors are employed to op-
timize geometric parameters for spectral absorption.[290]
Using data from full-wave electromagnetic simulations,
PCA reduces dimensionality, enhancing computational ef-
ficiency. The RF model achieves high prediction precision
for spectral absorption, with an ùëÖ2value of 0.99, improv-
ing the design efficiency of solar absorbers for green energy
applications and paving new pathways in optical mate-
rial design. To accelerate the development of polymeric
biomaterials, various ML models, including DL, RF, and
Gaussian process models, process the physical properties
of polymers encoded by SMILES notation and molecular
descriptors.[291]These ML models significantly enhance
the design of novel polymer materials, optimizing physi-
cal, electrical, and rheological properties under data-scarce
conditions, thereby accelerating progress in polymer bio-
materials within the medical field.
In real-time topology optimization, support vector re-
gression (SVR) and KNN models generate optimized ma-
terial distributions.[292]Through feature extraction and
PCA for dimensionality reduction, simplified design vari-
able vectors from direct optimization serve as training in-
puts. The model adapts structures rapidly to different ex-
ternal loads, supporting applications in short-beam struc-
ture optimization and illustrating the potential of ML in
real-time structural optimization for complex industrial
structures.
CNNs[293]represent a powerful class of DL algorithms
that are particularly suited for processing images and se-
quential data owing to their capability to efficiently ex-
tract complex features. Widely applied in computer vi-
sion and related scientific fields, CNNs perform a series
of convolution operations across multiple layers, progres-sively abstracting high-dimensional input data into lower-
dimensional representations. This hierarchical feature ex-
traction enhances their effectiveness in tasks such as pat-
tern recognition and predictive modeling. Mathematically,
the convolution operation in each layer ùëôwith filter ùëòis ex-
pressed as follows:
ùëìùëò
ùëñùëó=ùëÄ‚àí1‚àëÔ∏Å
ùëö=0ùëÅ‚àí1‚àëÔ∏Å
ùëõ=0ùëäùëò
ùëöùëõ¬∑ùëã(ùëñ+ùëö)(ùëó+ùëõ)+ùëèùëò, (4)
where ùëìùëò
ùëñùëódenotes the output feature map for filter ùëòat
spatial position, ùëäùëò
ùëöùëõrepresents the weights in the convo-
lutional kernel ùëòof size, ùëã(ùëñ+ùëö)(ùëó+ùëõ)is the input feature
map from the previous layer, and ùëèùëòis the bias term as-
sociated with filter ùëò. Unlike traditional neural networks,
CNNs use a combination of convolutional, pooling, and
fully connected layers, enabling them to detect spatial and
positional relationships within structured data effectively.
In materials science, CNNs have become increasingly in-
strumental in optimizing material properties and struc-
tural design, yielding notable advancements in the topol-
ogy optimization and inverse design of complex materials.
A CNN architecture based on ResNet[294]was pro-
posed for the topology optimization of nonlinear struc-
tures, specifically targeting large-deformation hyperelastic
materials such as neo-Hookean materials.[295]The study
generated an extensive dataset, consisting of 15,000 data
pairs for linear elastic materials, 18,000 pairs for hyperelas-
tic materials, and 20,000 pairs for linear stress materials,
all aimed at optimizing material distribution to achieve
maximal structural performance. By integrating the resid-
ual learning capabilities of ResNet with the U-net architec-
ture, the model attains a Dice similarity coefficient of 0.964
in nonlinear material topology optimization, significantly
improving both predictive accuracy and optimization ef-
ficiency. This method offers a robust tool for structural
optimization of hyperelastic materials and highlights the
potential of ML in addressing complex nonlinear topology
optimization challenges in materials science.
A transfer learning framework integrating CNN with
simplified ML (SML) techniques was used to design a
novel steel alloy with superior rotating bending fatigue
resistance.[296]Utilizing a database of 411 samples, the
study extracted static mechanical performance features
and employed a transfer learning model to predict fatigue
strength, resulting in the design of Alloy R‚Äìan innova-
tive alloy with fatigue strength that significantly surpasses
that of existing alloys. This novel application of transfer
learning effectively reduces data requirements, providing a
practical solution for high-cost property predictions such
as fatigue strength. Moreover, it establishes a theoretical
foundation for exploring the relationship between fatigue
performance and alloy design, offering valuable insights for
material engineers. Additionally, a CNN-based approach
was developed to predict the toughness and strength of
composite materials under crack conditions, with finite el-
ement models generating data that treat composite mate-
rials as 8√ó8-pixel images with binary values representing
‚Ä†https://jmatpro.cn/
027403-18

Chinese Physics Letters 42, 027403 (2025) Review
different material properties (e.g., soft or hard).[297]The
CNN model achieved a prediction accuracy exceeding 98\%,
enabling high-performance composite design even under
data-scarce conditions. This research highlighted the po-
tential of ML to facilitate accurate design with minimal
data, providing a foundational method for reverse engi-
neering in composite materials, and demonstrating the ef-
fectiveness of ML in enhancing material design efficiency
and predictive accuracy.
In this section, we review the development and appli-
cation of traditional ML algorithms in the inverse design
of materials. These algorithms have provided significant
impetus for material discovery. Although they emerged
early, this does not imply that they are outdated; different
problems and scenarios require the selection of appropriate
algorithms.
3.2. Geometric Graph Neural Networks. The predic-
tion of properties and structures of crystalline materials
has long been a crucial task in materials science. Owing tothe necessity to account for complex symmetry constraints,
crystal data are challenging to model using conventional
networks such as CNNs. Geometric GNNs are models
designed to process graph data with geometric informa-
tion (e.g., spatial coordinates and angles) and are well-
suited for studying spatial structures such as molecules,
proteins, and materials. Based on scientific requirements,
geometric GNNs are categorized into two types. The first
type, invariant GNNs, maintain invariant outputs under
Euclidean transformations, making them ideal for predict-
ing properties such as band gaps, formation energies, and
ùëác, which are independent of the absolute position and
orientation of the material structure. The second type,
equivariant GNNs, update both invariant and equivariant
features such that outputs change in similarly to the in-
puts under geometric transformations, making them par-
ticularly effective for capturing directional relationships in
applications such as material structure prediction and gen-
eration.
Table 1. Basic notations. Following Han‚Äôs[35]notation conventions, we present the commonly used symbols.
Notation Description
ùí¢:= (ùê¥,ùêª) Graph with ùëÅnodes, characterized by its adjacency matrix ùê¥and node feature matrix ùêª.
‚Éóùí¢:= (ùê¥,ùêª,‚Éóùëã) Geometric graph incorporating a 3D coordinate matrix ‚Éóùëãin addition to ùê¥andùêª.
ùí©ùëñ Set of nodes neighboring node ùëñ.
‚Ñéùëñ‚ààRùê∂‚Ñé Feature of node ùëñcontaining ùê∂‚Ñéattributes.
ùë¢ Global state vector.‚®ÅÔ∏ÄAggregation of neighboring node features, such as sum, mean, or max.
‚Éóùë•ùëñ‚ààR33D spatial coordinates of node ùëñ.
‚Éóùëâùëñ‚ààR3√óùê∂Multi-channel 3D vector representing node ùëñ.
‚Éóùëâ(ùëô)
ùëñ‚ààR(2ùëô+1)√óùê∂ùëô Type- ùëôirreducible vector associated with node ùëñ.
ùëíùëñùëó‚ààRùê∂ùëí Edge feature vector from node ùëóto node ùëñ.
ùê∫, ùëî Group ùê∫and its element ùëî, relevant to transformations in the graph.
√ó,‚äó Operators for vector operations: cross product √óand Kronecker product ‚äó.
‚äócg Clebsch‚ÄìGordan tensor products.
ùëå(ùëô)(‚Éóùë•)‚ààR2ùëô+1Type- ùëôspherical harmonic vector evaluated at point ‚Éóùë•.
ùê∑(ùëô)(ùëî) ùëô-th degree Wigner-D matrix for rotation ùëî‚ààSO(3).
ùúë, ùúì, ùúô, ùúé Functions achieved through MLP.
‚Ñí Loss function.
ùëä Weight matrix.
Graph Neural Networks. GNNs differ from traditional
neural networks in that they operate on graph-structured
data rather than tensor-structured data. A graph ùí¢:=
(ùê¥,ùêª) represents a graph with ùëÅnodes, characterized
by its adjacency matrix ùê¥and node feature matrix ùêª.
The core concept of GNNs is message passing, where, as
the graph propagates forward, the features stored at node
ùëñ, denoted as ‚Ñéùëñ, are updated based on information from
its neighborhood:
‚Ñé‚Ä≤
ùëñ=ùúéùë¢ùëùùëë(Ô∏É
‚Ñéùëñ,‚®ÅÔ∏Å
ùëó‚ààùí©ùëñ‚Ñéùëó)Ô∏É
. (5)
The equation illustrates how the feature ‚Ñé‚Ä≤
ùëñof node ùëñis
updated through a message-passing mechanism. In this
framework, the function ùúéùë¢ùëùùëë, which is typically a non-
linear activation function, takes as inputs both the origi-
nal feature ‚Ñéùëñand an aggregated summary of the features
‚Ñéùëófrom neighboring nodes ùëówithin the setùí©ùëñ. The ag-
gregation operator‚®ÅÔ∏Äcan encompass operations such assummation, averaging, or obtaining the maximum. This
methodology enables node ùëñto effectively incorporate in-
formation from its local neighborhood, thereby enrich-
ing its updated feature representation. This mirrors the
behavior of physical systems, where long-range correla-
tions are governed by local interactions. Specifically, when
features include spatial information‚Äìtypically represented
as 3D vectors‚Äìthe networks are categorized as geometric
GNNs, denoted as ‚Éóùí¢:= (ùê¥,ùêª,‚Éóùëã), where a geometric
graph incorporates a 3D coordinate matrix ‚Éóùëãin addition
toùê¥andùêª.
To establish a framework for categorizing various types
of geometric GNNs, we first present the message-passing
neural network (MPNN).[298]In this framework, features
‚Ñéùëñare associated with nodes and are iteratively updated
at each hidden layer,
‚Ñé‚Ä≤
ùëñ=ùúéùë¢ùëùùëë(Ô∏É
‚Ñéùëñ,‚®ÅÔ∏Å
ùëó‚ààùí©ùëñùëöùëñùëó)Ô∏É
, (6)
027403-19

Chinese Physics Letters 42, 027403 (2025) Review
whereas messages ùëöùëñùëóare stored on the edges, serving as
update buffers for the connected nodes.
ùëö‚Ä≤
ùëñùëó=ùúéùëöùë†ùëî(Ô∏É
‚Ñéùëñ,‚Ñéùëó,‚®ÅÔ∏Å
(ùëòùëô)‚ààùí©(ùëñùëó)ùëöùëòùëô)Ô∏É
. (7)
Messages guide the feature updates and propagate along
the edges, thereby reinforcing the locality principle in
GNNs.
Invariant Geometric GNNs. Invariant geometric
GNNs can be classified according to the scalar geometric
quantities they utilize for message passing, such as pairwise
distances, triplet-wise angles, and quadruplet-wise torsion
angles. In the following, we introduce one model from each
category as an example.
SchNet[299]is one of the earliest invariant GNN mod-
els, developed as a variant of the deep tensor neural
network[300]for modeling atomic structures. In SchNet,
continuous filters are employed to capture interaction
terms based on the pairwise distances between atoms:
‚Ñé‚Ä≤
ùëñ=‚Ñéùëñ+‚àëÔ∏Å
ùëó‚ààùí©ùëñùëö‚Ä≤
ùëñùëó‚Ñéùëó, (8)
ùëö‚Ä≤
ùëñùëó=ùëä(‚Äñ‚Éóùë•ùëñ‚àí‚Éóùë•ùëó‚Äñ), (9)
where ùëädenotes the learnable filter. The filter employs
Gaussians as radial basis functions in its first layer to en-
code pairwise distances.
ùëíùëò(‚Äñ‚Éóùë•ùëñ‚àí‚Éóùë•ùëó‚Äñ) = exp(‚àíùõæ(‚Äñ‚Éóùë•ùëñ‚àí‚Éóùë•ùëó‚Äñ‚àíùúáùëò)2). (10)
Notably, later studies[301]have shown that spherical Bessel
functions serve as more effective bases. Other distance-
based models include CGCNN[302]and PhysNet.[303]
While simple and effective, these models are limited in
that they cannot distinguish between molecular structures
that have identical pairwise distances but differ in bond
angles.
DimeNet[304]utilizes triplet information by introduc-
ing directional message passing:
ùëö‚Ä≤
ùëóùëñ=ùúéùëöùë†ùëî(Ô∏É
ùëöùëóùëñ,‚®ÅÔ∏Å
ùëó‚ààùí©ùëó‚àñ\{ùëñ\}ùëöùëòùëó)Ô∏É
, (11)
where ùëöùëóùëñdenotes a directional message passed from node
ùëóto node ùëñ, which is updated by iterating over all messages
directed toward node ùëó, excluding those from node ùëñ. The
angle information \textbackslash\{\}ùëñùëóùëòcan be computed, enabling the dif-
ferentiation of structures with varying bond angles. While
DimeNet represents an advancement over SchNet by cap-
turing angular information, it still cannot resolve torsions
or distinguish chiral structures.
SphereNet[305]also applies a directional message-
passing approach but with further refinement. It intro-
duces ‚Äúspherical message passing‚Äù using a local spheri-
cal coordinate system. The messages encode not only
polar angles, such as \textbackslash\{\}ùëñùëóùëòand\textbackslash\{\}ùëñùëóùëò‚Ä≤, but also the az-
imuthal angle between ‚Éóùë•ùëò‚àí‚Éóùë•ùëóand‚Éóùë•ùëò‚Ä≤‚àí‚Éóùë•ùëó. This en-
ables SphereNet to capture complete geometric informa-
tion around node ùëó, including quadruplet torsional an-
gles. Consequently, SphereNet can distinguish chiral struc-
tures, achieving SE(3)-invariance, whereas prior modelswere limited to E(3)-invariance. Although failure cases
exist in which SphereNet cannot distinguish certain con-
figurations, such scenarios are theoretically possible but
highly improbable in natural settings. Later research[306]
proposed quaternion message passing, which encodes these
geometric features more efficiently. Other models in this
category include GemNet[307]and ComENet.[308]
Equivariant Geometric GNNs. Geometric GNNs
achieve equivariance in two main ways: one approach
achieves scalarization-based models through inner product
operators, whereas the other utilizes group representation
theory, spherical harmonics, and tensor product methods.
Finally, we introduce several studies that integrated at-
tention mechanisms into geometric GNNs models, signifi-
cantly enhancing their expressive power.
To achieve equivariance, some studies[309‚Äì311]imple-
mented a scalarization-based models approach, with equiv-
ariant GNNs[309]being the most prominent. This model
does not require costly higher-order representations; in-
stead, it first converts the 3D coordinates into invariant
scalars, specifically squared distances ‚Äñ‚Éóùë•ùëñ‚àí‚Éóùë•ùëó‚Äñ2, and then
uses this invariant information, node representations, and
edge attributes to perform edge message passing:
ùëöùëñùëó=ùúé1(‚Ñéùëñ,‚Ñéùëó,‚Äñ‚Éóùë•ùëñ‚àí‚Éóùë•ùëó‚Äñ2,ùëíùëñùëó), (12)
where ùëíùëñùëórepresents the edge attributes between the ùëñ-th
andùëó-th nodes, and ‚Ñéùëñdenotes the node representations
of the ùëñ-th node. Geometric messages can be expressed as
‚Éóùëöùëñùëó= (‚Éóùë•ùëñ‚àí‚Éóùë•ùëó)ùúé2(ùëöùëñùëó), (13)
where ‚Éóùë•ùëñand‚Éóùë•ùëórepresent the coordinates of the ùëñ-th and
ùëó-th nodes, respectively. Node features are updated by
passing invariant messages:
‚Ñé‚Ä≤
ùëñ=ùúé3(Ô∏Å
‚Ñéùëñ,‚àëÔ∏Å
ùëó‚ààùí©ùëñùëöùëñùëó)Ô∏Å
. (14)
The position of each atom is then updated using a vector
field along the radial direction; in other words, each atom‚Äôs
position is updated by a weighted sum of all relative vector
differences:
‚Éóùë•‚Ä≤
ùëñ=‚Éóùë•ùëñ+ùõæ‚àëÔ∏Å
ùëó‚ààùí©ùëñ‚Éóùëöùëñùëó, (15)
where ùúé1, ùúé2, ùúé3are MLPs, and ùõæis a predefined constant
equal to 1 /(ùëÄ‚àí1), where ùëÄis the number of atoms.
In addition to coordinates, a node‚Äôs vector informa-
tion can include attributes such as velocity and accelera-
tion. Graph Mechanics Network[312]introduces a multi-
channel vector representation ‚Éóùëâùëñ‚ààR3√óùê∂for each node to
capture these attributes. Before message passing, these
vectors undergo a scalarization process:‚Éóùëâ‚ä§
ùëñùëó‚Éóùëâùëñùëó
‚Äñ‚Éóùëâ‚ä§
ùëñùëó‚Éóùëâùëñùëó‚Äñùêπ, where
‚Éóùëâùëñùëó=‚Éóùëâùëñ‚àí‚Éóùëâùëó. This subtraction ensures that ‚Éóùëâùëñùëóremains
translation-invariant. Many models, such as ClofNet,[313]
achieve scalarization and preserve equivariance by con-
structing local frames. Other studies, such as those in
Ref. [314,315], followed similar approaches. Specifically,
the message passing is conducted as follows:
ùëöùëñùëó=ùúé1(‚Ñéùëñ,‚Ñéùëó,‚Éóùëâ‚ä§
ùëñùëó‚Éóùêπùëñùëó), (16)
027403-20

Chinese Physics Letters 42, 027403 (2025) Review
where ‚Éóùêπùëñùëóis translation-invariant.[35]Many other GNNs
achieve scalarization through inner product operators
while maintaining equivariance, such as GVP-GNN,[316]
LEFTNet,[317]Frame Averaging,[318]and EGHN.[319]
By combining the Wigner-D matrix ùê∑(ùëô)(ùëî),[320]spher-
ical harmonics ùëå(ùëô)(‚Éóùë•)‚ààR2ùëô+1, and the Clebsch‚ÄìGordan
tensor product‚äócg, e3nn[321]and TFN[320]offer a neural
network approach that can handle 3D data while preserv-
ing equivariance to rotations, translations, and inversions.
This integration enables the network to learn richer and
more robust feature representations. The Wigner-D ma-
trix represents the irreducible representations of the SO(3)
group (the 3D rotation group) and describes the rotational
behavior of angular momentum in quantum mechanics.
Wigner-D matrices ensure that network layers maintain
equivariance under rotation. Spherical harmonics, func-
tions defined on the unit sphere that are equivariant under
SO(3), can be extended to the entire R3space and are used
to construct equivariant polynomials. In e3nn, spherical
harmonics are applied to build equivariant convolutional
layers that can process point cloud data in 3D space. Their
equivariance enables the network to learn features that are
invariant to rotation. The CG tensor product combines
two irreducible representations of angular momentum into
a new irreducible representation that retains equivariance.
The e3nn framework leverages the CG tensor product to
combine outputs from different layers and construct com-
plex equivariant operations, such as convolutions and at-
tention mechanisms. The CG tensor product ensures that
these operations remain equivariant under rotation, en-
abling learned patterns to be invariant to transformations
in 3D space. By employing higher-order representations
(ùëô >1), these networks can capture complex 3D spatial
relationships, which traditional CNNs struggle to achieve.
Steerable E(3) equivariant GNNs (SEGNNs)[322]can
handle geometric and physical information contained in
node and edge attributes, such as position, force, veloc-
ity, or spin. SEGNNs integrate this information into the
message passing and node updating functions and intro-
duce a new class of equivariant activation functions, based
on manipulable node attributes and manipulable MLPs,
enabling the injection of geometric and physical informa-
tion into the node updates. Neural Equivariant Inter-
atomic Potentials (NequIP)[323]uses a similar approach
to learn interatomic potentials from ùëéùëè ùëñùëõùëñùë°ùëñùëú calculations.
NequIP provides significant improvements in the accuracy
and efficiency of MD simulations, facilitating the appli-
cation of this method across a broader range of research
fields. Wang et al.[324]enhanced the prediction accuracy
and computational efficiency of material potential energy
surfaces and physical properties by replacing traditional
MLP with Kolmogorov‚ÄìArnold networks (KANs) in vari-
ous ML frameworks.
In summary, much work remains to be accomplished
on neural networks based on the integration of Wigner-D
matrices, spherical harmonics, and CG tensor products,
such as DimeNet,[325]SCN,[326]eSCN,[327]MACE,[328]
PaiNN,[329]and Allegro.[330]Transformers have demonstrated remarkable capabil-
ities in the field of LLMs, primarily owing to their at-
tention mechanism. A natural consideration is to incor-
porate this attention mechanism into GNNs. Meta pro-
posed the equivariant graph attention transformer for 3D
atomistic graphs (Equiformer),[331]which combines the
transformer architecture with SE(3)/E(3) equivariant fea-
tures based on irreducible representations, introducing
an equivariant graph attention mechanism. By replac-
ing traditional dot product attention with MLP atten-
tion and integrating nonlinear message passing, this ap-
proach enhances the attention expressiveness of the trans-
former. The network employs equivariant operations, such
as independent linear transformations, layer normaliza-
tion, and depth-wise tensor products, to handle differ-
ent types of vectors while processing 3D graph struc-
tures through embedding layers and transformer blocks.
Meta further introduced EquiformerV2,[332]an advance-
ment over Equiformer, with key architectural improve-
ments to enhance stability, computational efficiency, and
model expressivity. EquiformerV2 incorporates an addi-
tional normalization layer preceding attention weight com-
putation to stabilize the training process, and it refines
the nonlinear activation function to more effectively handle
representations across different orders. This approach uses
specialized activation functions for each order and inde-
pendently normalizes vectors to preserve their relative im-
portance. Leveraging eSCN convolutions, EquiformerV2
simplifies the computation of SO(3) tensor products by
transforming them into SO(2) linear operations, signifi-
cantly reducing computational complexity. These innova-
tions enable EquiformerV2 to achieve improved accuracy
and efficiency on large-scale and complex 3D atomic graph
datasets, particularly through the effective utilization of
higher-order irreducible representations.
A prominent method integrating attention mechanisms
with GNNs is Graphormer,[333]a GNN built on the stan-
dard transformer architecture. Graphormer excels in a
range of graph representation learning tasks by proficiently
encoding the structural information of graphs. It intro-
duces several straightforward yet effective structural en-
codings, namely, centrality encoding, spatial encoding,
and edge encoding, which enhance its ability to model
graph-structured data. Theoretical analysis further un-
derscores Graphormer‚Äôs expressive power, proving that nu-
merous popular GNNs variants can be considered as spe-
cial cases within its overarching framework. Many simi-
lar approaches combine attention mechanisms with GNNs,
such as SE(3)-Transformer,[334]TorchMD-Net,[335]and
LieTransformer.[336]
3.3. Discriminative AI.
Introduction to Discriminative AI. A common task in
inverse design of materials involves leveraging AI to pre-
dict the physico-chemical properties of materials, enabling
high-throughput screening based on these properties. Dis-
criminative models are primarily employed to directly pre-
dict the category (e.g., superconducting material, mag-
netic material) or label (e.g., formation energy, ùëác) asso-
027403-21

Chinese Physics Letters 42, 027403 (2025) Review
ciated with a given input (e.g., crystal structure, chemical
composition). These models focus on learning how to map
input data to the corresponding output labels. The ob-
jective of discriminative models is to infer the conditional
probability distribution ùëÉ(ùë¶|ùë•) of the target variable ùë¶
given the input features ùë•.
CGCNN. The CGCNN[73]is one of the earliest tools to
use GNNs for predicting material properties. The CGCNN
achieves comparable or slightly better accuracy than the
DFT calculations in predicting properties such as forma-
tion energy, band gap, Fermi level, bulk modulus, shear
modulus, and Poisson‚Äôs ratio, with significantly faster com-
putational speed. By analyzing the energy of each site
in perovskite structures, the CGCNN aids in discovering
new stable perovskite materials, significantly reducing the
search space for high-throughput screening.
Specifically, the CGCNN uses an undirected multilat-
eral graph to represent atoms and chemical bonds as nodes
and edges, respectively. In this graph, the ùëñ-th node is
represented by the feature vector ‚Ñéùëñ, which corresponds to
the properties of the ùëñ-th atom. Each edge ( ùëñ, ùëó)ùëòis repre-
sented by the feature vector ùëö(ùëñ, ùëó)ùëò, corresponding to the
ùëò-th bond between atoms ùëñandùëó. Atoms are considered
to be connected if the distance between them does not ex-
ceed 6 ÀöA. For discrete values, such as atomic numbers, a
unique one-hot vector is used for direct embedding. For
continuous values, such as bond lengths, the value range
is divided into 10 intervals, and the value is encoded using
a one-hot vector.
In the model, two types of neural networks are em-
ployed: GCN and fully connected networks (FCNs). Con-
volutional layers are used to aggregate information from
the neighboring atoms around each atom:
‚Ñé(ùë°+1)ùëì
ùëñ = Conv(Ô∏Å
‚Ñé(ùë°)
ùëñ,‚Ñé(ùë°)
ùëó,ùëö(ùëñ, ùëó)ùëò)Ô∏Å
,(ùëñ, ùëó)ùëò‚ààùí¢,(17)
where ‚Ñé(ùëá)
ùëñrepresents the feature vector of node ùëñafter ùëá
convolutions. The pooling layer uses normalized summa-
tion as the pooling function to generate a feature vector
representing the entire graph. Finally, the target property
\^{}ùë¶is predicted through two fully connected layers. A loss
function ùêΩ(ùë¶,\^{}ùë¶) is defined, and the model parameters are
updated by minimizing this loss function:
min
ùëäùêΩ(ùë¶, ùëì(ùíû;ùëä)), (18)
where ùëärepresents weights of the CGCNN, and ùëìis a
function means that maps the crystal ùíûto the target prop-
erty \^{}ùë¶. For more specific details, please refer to the original
paper.[73]
MEGNet. The materials graph network (MEGNet)[75]
is a general material graph network model that can accu-
rately predict the properties of both molecules and crys-
tals. The model outperforms previous ML models in pre-
dicting various properties. Because earlier models did not
embed the entire crystal structure, MEGNet introduces
global state attributes to the graph representation, in-
cluding temperature, pressure, and entropy. MEGNet is
trained on the QM9[337]molecular and Materials Project(MP) crystal datasets. On the 13 properties in QM9,
MEGNet outperforms previous models in predicting 11 of
them. On the MP dataset, which includes 60,000 crystals,
MEGNet not only outperforms earlier ML models but also
achieves higher accuracy than DFT on a larger dataset.
In the model, the feature vector of the edge is up-
dated by applying a specific update rule that incorporates
information from both the node features and the edge‚Äôs
previous state. This process ensures that the edge repre-
sentation evolves through successive layers, capturing the
interactions between atoms in the crystal structure:
ùëö‚Ä≤
ùëò=ùúëùëí(‚Ñéùëñ‚äï‚Ñéùëó‚äïùëöùëñùëó‚äïùë¢), (19)
where ùúëùëíis the bond update function, ‚äïis the concate-
nation operator, ‚Ñéùëñand‚Ñéùëóare the ùëñ-th and ùëó-th atoms
corresponding feature vector, respectively, and ùë¢is the
global state vector. Next, the feature vector of each atom
is updated using
‚Ñéùëí
ùëñ=1
ùëÅùëí
ùëñùëÅùëí
ùëñ‚àëÔ∏Å
ùëò=1\{ùëö‚Ä≤
ùëñùëó\}, (20)
‚Ñé‚Ä≤
ùëñ=ùúëùë£(‚Ñéùëí
ùëñ‚äï‚Ñéùëñ‚äïùë¢), (21)
where ùëÅùëí
ùëñis the degree of atom ùëñ, and ùúëùë£is the atom
update function. Finally, the global state attribute is up-
dated as follows:
ùë¢ùëí=1
ùëÅùëíùëÅùëí‚àëÔ∏Å
ùëò=1\{ùëö‚Ä≤
ùëñùëó\}, (22)
ùë¢ùë£=1
ùëÅùë£ùëÅùë£‚àëÔ∏Å
ùëñ=1\{‚Ñé‚Ä≤
ùëñ\}, (23)
ùë¢‚Ä≤=ùúëùë¢(ùë¢ùëí‚äïùë¢ùë£‚äïùë¢), (24)
where ùúëùë¢is the global state update function. The model
combines two layers of FCN and MEGNet modules into a
large MEGNet block. Multiple MEGNet blocks are then
connected through a residual network, enabling the model
to have deep hidden layers.
ALIGNN. The atomistic line graph neural network
(ALIGNN)[338]introduces an innovative GNN architecture
that alternates message passing between atomic bond and
line graphs (capturing bond angles) to explicitly incorpo-
rate critical geometric information often ignored by tradi-
tional GNN models. Compared with models solely based
on interatomic distances, ALIGNN significantly improves
the accuracy of material property predictions. Its dual-
graph message-passing mechanism, combined with edge-
gated convolution, efficiently updates both node and edge
representations. Tests on datasets such as JARVIS-DFT,
Materials Project, and QM9 demonstrate that ALIGNN
not only outperforms existing GNN models (such as
CGCNN, MEGNet, and SchNet) in predicting properties
such as formation energy and band gaps but also main-
tains high computational efficiency and robust generaliza-
tion. By incorporating bond angle information into the
GNN architecture, this models is an effective tool for ac-
celerating materials design and discovery, with its open-
source code and datasets further promoting advancements
in materials science research.
027403-22

Chinese Physics Letters 42, 027403 (2025) Review
In ALIGNN models, the node feature embedding and
convolution design is similar to the that of the CGCNN,
but the feature vector is updated using the edge-gate graph
convolution.
\^{}ùëöùëñùëó=ùúé(ùëöùëñùëó)‚àëÔ∏Ä
ùëò‚ààùí©ùëñùúé(ùëöùëñùëò) +ùúñ, (25)
‚Ñé‚Ä≤
ùëñ=‚Ñéùëñ+SiLU(Ô∏É
Norm(Ô∏É
ùëäùë†‚Ñéùëñ+‚àëÔ∏Å
ùëó‚ààùí©ùëñ\^{}ùëöùëñ, ùëóùëäùëë‚Ñéùëó)Ô∏É)Ô∏É
,
(26)
ùëö‚Ä≤
ùëñùëó=ùëöùëñùëó+ SiLU(Norm( ùê¥‚Ñéùëñ+ùêµ‚Ñéùëó+ùê∂ùëö ùëñùëó)),(27)
where ùëäùë†,ùëäùëë,ùê¥,ùêµ, and ùê∂are learnable parameters,
ùúéis sigmoid function, SiLU is the sigmoid linear unit,
and equation (27) is equivalent to the gating term in the
CGCNN.
An ALIGNN layer consists of edge-gated graph con-
volutions on both the bond graph ( ùëî) and its line graph
(ùêø(ùëî)). To avoid confusion between the node and edge
features in the atomistic graph and its line graph, we de-
note atoms, bonds (nodes in the line graph), and triplets
(angles between bonds) as ‚Ñé,ùëö, and ùë°, respectively. The
line graph convolution generates bond messages ùëö, which
are propagated to the atomistic graph and combined with
atomic features ‚Ñéto update bond representations:
ùêª‚Ä≤,ùë°‚Ä≤= EdgeGatedGraphConv( ùêø(ùëî),ùëö,ùë°), (28)
‚Ñé‚Ä≤,ùëö‚Ä≤= EdgeGatedGraphConv( ùëî,‚Ñé, ùêª‚Ä≤). (29)
OGCNN. The orbital graph CNN (OGCNN) is a
crystal CGN that incorporates atomic orbital interaction
features.[339]Beyond accounting for orbital contributions,
the authors introduced a technique known as the orbital
field matrix (OFM),[340]which captures orbital interac-
tions by leveraging the electron configurations of both
the central atom and its neighboring atoms. The study
evaluated various properties, including formation energy,
band gap, and Fermi energy. The results indicated that
the model achieves improved predictive accuracy over the
CGCNN, underscoring the critical role of orbital‚Äìorbital
interactions. The OFM is defined as
ùëãc=ùëÇcT+ùëÄ‚àëÔ∏Å
ùëñ=1ùëÇcTùëÇùëñùúÉcùëñùúÅ(ùëücùëñ), (30)
where ùëãcrepresents the OFM for the central atom, ùëÇc
andùëÇùëñrepresent the 1D binary vectors for the central
and neighboring atoms, respectively, ùëÄdenotes the num-
ber of neighboring atoms, ùúÉcùëñdenotes the solid angle be-
tween center-neighbor pairs in the Voronoi cell, and ùúÅ(ùëücùëñ)
denotes the function related to the distance between cen-
tral and neighboring atoms, which can be selected as re-
quired. The total framework contains four modules: input,
encoder‚Äìdecoder, graph convolution, and output modules.
The input module processes the atom configuration and
OFM features and output vectors containing information
about basic atoms and OFM. The function of the second
module is to learn significant information among atomsusing an MLP. The operation in the graph convolution
module can be expressed as
ùëâ‚Ä≤
ùëñ=ùëâùëñ+‚àëÔ∏Å
ùúé(ùëß(ùëñ, ùëó)ùëòùëäùëì+ùëèùëì)
‚äôùëî(ùëß(ùëñ, ùëó)ùëòùëäùë†+ùëèùë†), (31)
where ùëß(ùëñ, ùëó)=ùëâùëñ‚äïùëâùëó‚äïùë¢(ùëñ, ùëó)ùëò,ùë¢(ùëñ, ùëó)ùëòcontains the in-
formation of kernelized distance features, ùúédenotes a sig-
moid function, and ùëîdenotes the softplus function. The
OGCNN architecture uses a total of three convolutional
operations and a summation operation is performed next.
Finally, in the output module, a pooling layer and FCN
are implemented to map to the desired result.
ECN. The equivariant crystal network (ECN)[341]in-
corporates spatial group symmetries into GNNs. The ECN
emphasizes that symmetry invariance is a necessary condi-
tion for practical applications. The authors experimented
using the Materials Project dataset, filtering it to retain
only data relevant to 3D materials. They then predicted
physical properties such as formation energy, Fermi en-
ergy, band gap, and magnetic moment per atom. The
authors framed their work as both regression and clas-
sification tasks. Experimental results revealed improved
performance compared with previous models, supporting
the authors‚Äô claim that symmetry provides a beneficial in-
ductive bias.
In practice, using models that are equivariant to the
actual symmetry of the data can be more beneficial in
terms of the model‚Äôs expressiveness. This is because the
corresponding group is significantly smaller than the sym-
metric group; thus, equivariance to a smaller group may
reduce parameter sharing, making the model more expres-
sive. Moreover, the authors emphasized the importance of
equivariance, noting that invariant functions can be con-
structed by combining equivariant layers with an output
pooling layer. Additionally, equivariant functions can be
used to predict local properties, such as charge distribution
and magnetization.
The construction of an ECN is based on two key prin-
ciples. The first challenge is the difficulty of supervised
learning when a dataset encompasses a diverse range of
crystal structures for a specific species. To address the
discrepancies inherent in the unit cell structures, the re-
searchers introduced the direct product of groups. The
second principle in constructing the ECN is the equivari-
ant message-passing framework. The authors defined the
layer based on the update equation within this message-
passing framework.
The ECN model takes as input a graph representing
the crystal structure and generates a single encoded fea-
ture vector for each atom. This is followed by the integra-
tion of hidden layers and average pooling layers, culminat-
ing in a two-layer MLP for output prediction.
Matformer. Matformer[342]is specifically designed for
periodic graph representation learning to predict the prop-
erties of crystalline materials. It computes various physical
quantities, such as formation energy, band gap, and total
energy, across multiple benchmark datasets, surpassing ex-
isting baseline methods such as ALIGNN,[338]SchNet,[310]
027403-23

Chinese Physics Letters 42, 027403 (2025) Review
and CGCNN,[73]and demonstrating notable performance
improvements. The model achieves periodic invariance
through a specialized graph construction method, ensur-
ing that the learned representations remain invariant to
translations of the unit cell boundaries. Matformer ef-
fectively encodes periodic patterns, capturing the lattice
size and orientation of the crystal. Additionally, Mat-
former employs an attention-based architecture, integrat-
ing edge attention and geometric information encoding,
thereby enhancing its capability to process multi-atom
crystal graphs. Experimental results indicate that Mat-
former outperforms baseline methods on the Materials
Project and JARVIS datasets, offering advantages in both
training and inference speed. By incorporating periodic
orbital interaction features alongside fundamental atomic
features, Matformer significantly enhances the accuracy of
material property predictions, revealing promising poten-
tial for applications, particularly in the field of materials
discovery.
Before introducing periodic invariance, we discuss unit
cell E(3) invariance. Unit cell E(3) invariance can be ob-
served as a function ùëì: (ùê¥,ùëã,ùêø)‚Üíùúí, where the atom
feature matrix ùê¥and position matrix ùëãshould describe
unit cell itself, and ùêødescribes how a unit cell repeats itself
in different directions. Thus, the definition clearly shows
that regardless of whether the call is rotated, reflected,
or translated, the structure of the cell itself remains un-
changed. After considering the periodic invariance, the
authors defined that unit cell E(3) function ùëìis periodic
invariant if ùëì(ùê¥,ùëã,ùêø) =ùëì(ùúë(\^{}ùê¥,\^{}ùëã, ùõºùêø, ùëù), ùõºùêø) holds
for all ùëù‚ààR3andùõº‚ààN3
+, where ùúëis a function such
thatùúë: (\^{}ùê¥,\^{}ùëã, ùõºùêø, ùëù)‚Üí(ùê¥,ùëã). The authors also em-
phasized the importance of disrupting period invariance,
namely, for the same crystal, this would result in different
crystal graphs. Additionally, periodic pattern encoding is
expressed by ùêøto better represent infinite structures of
crystals.
Some researchers use both multi-edge graph construc-
tion and fully-connected graph construction, which both
satisfy periodic invariance, to build their Matformer.[73]
Additionally, the radius-based method is used for bet-
ter performance in experiments. Subsequently, self-
connecting edges is incorporated to encode a periodic
pattern, namely ùêø. For a direction vector ùëôùëñofùêø=
[ùëô1, ùëô2, ùëô3]ùëá‚ààR3√ó3, it contains two parts, which are the
length‚Äñùëôùëñ‚Äñ2and orientation. Thus, the orientation should
be encoded. The authors utilize additional distances to
encode angles between two direction vectors. For exam-
ple, the angle between ùëô1andùëô2can be derived from ‚Äñùëô1‚Äñ2,
‚Äñùëô2‚Äñ2and an additional distances ‚Äñùëô1+ùëô2‚Äñ2.
In addition, the authors discussed the impact of in-
troducing angular information. The utilization of angular
information in practical tests does not appear to provide
much hints about accuracy, but it triples the time cost.
This result may be because periodic invariant graph con-
struction and periodic patterns encoding in Matformer al-
ready provide sufficient information for the tests.CT. Crystal twins (CT) is a self-supervised learn-
ing framework that can learn from large unlabeled
datasets.[343]This framework represents one of the first
applications of self-supervised learning methods to the pre-
diction of crystalline properties, whereas before this, self-
supervised learning was primarily applied to molecular sys-
tems. The authors conducted experiments on 14 datasets
to evaluate the performance of the CT model and calcu-
late various properties, such as exfoliation energy, band
gap, and formation energy. The CT model demonstrated
strong performance in most cases, although its results were
not always be the best. Additionally, the authors assessed
the effectiveness of augmentation methods and argue that
the use of all three techniques enhances the overall effec-
tiveness of the experiments.
The authors proposed a set of main processes. First, a
CGCNN is used in pre-training to be an encoder to learn
the effective representation of the crystal system; here, the
authors proposed two different schemes based on Barlow
Twins[344]and SimSiamese[345]loss functions. Thereafter,
the weights are shared to initialize the encoder, and down-
stream tasks are fine-tuned with the aid of labeled data.
In this study, the authors also introduced three augmenta-
tion methods, namely random perturbations, atom mask-
ing, and edge masking.
We focus on the description of two pre-training frame-
works. In CT Barlow , the CGCNN encoder would gener-
ate representations of augmented instances from the same
crystal systems. The objective of pre-training here is to
align the cross-correlation matrix of the two embeddings
as closely as possible with the identity matrix. The Barlow
Twins loss function can be defined as
‚Ñíùêµùëá,‚àëÔ∏Å
ùëñ(1‚àíùê∂ùëñùëñ)2+ùúÜ‚àëÔ∏Å
ùëñ‚àëÔ∏Å
ùëóÃ∏=ùëñùê∂2
ùëñùëó, (32)
where ùê∂is the cross-correlation matrix, as
ùê∂ùëñùëó,‚àëÔ∏Ä
ùëèùëçùê¥
ùëè,ùëñùëçùêµ
ùëè,ùëó‚àöÔ∏Å
(ùëçùê¥
ùëè, ùëñ)2‚àöÔ∏Å
(ùëçùêµ
ùëè, ùëó)2. (33)
In Eq. (33), ùëèrepresents the index of the data within the
batch, ùê¥andùêµboth denote the augmented instances, and
ùëñandùëórepresents the index of the vector dimensions of the
projector output, namely ùëçùê¥andùëçùêµ. Another model is
pre-trained using the SimSiamese loss function with the
goal of maximizing the cosine similarity between the em-
beddings generated by the encoder for two augmented in-
stances. Furthermore, in CT SimSiam , one branch has a
stop-gradient operation, whereas the other branch has a
prediction header after the graph encoder. The loss func-
tion in this case can be defined as
‚ÑíSimSiam ,1
2‚àëÔ∏Å
ùëè(ùíü(ùëÉùê¥
ùëè,stopgrad( ùëçùêµ
ùëè))
+ùíü(ùëçùêµ
ùëè,stopgrad( ùëçùê¥
ùëè))), (34)
where stopgrad represents disabling back propagation of
gradients. The distance of two vectors can be defined as
ùíü(ùëÉùê¥
ùëè,ùëÉùêµ
ùëè) =‚àíùëÉùê¥
ùëè
‚ÄñùëÉùê¥
ùëè‚Äñ2¬∑ùëçùêµ
ùëè
‚Äñùëçùêµ
ùëè‚Äñ2. (35)
027403-24

Chinese Physics Letters 42, 027403 (2025) Review
MMPT. Mutex masked pre-training (MMPT) is a self-
supervised pre-training framework designed to address
challenges that hinder the prediction of crystal proper-
ties, particularly the limited availability of labeled crystal
data and the constraints of quantum chemistry.[346]The
masking techniques employed in MMPT are inspired by
the BERT framework.[347]The authors conducted their
experiments using a subset of the Open Quantum Mate-
rials Database (OQMD).[348]Compared with other super-
vised and self-supervised methods, MMPT demonstrated
strong performance. The experimental results indicated
that MMPT alleviates, to some extent, the problem of
limited labeled data. Furthermore, the authors assert that
their results outperform those of the CT method, attribut-
ing this improvement to the effective utilization of E(3)
invariance and the periodic invariance of crystals.
It is helpful to introduce the main framework of
MMPT. A crystal is described using three vectors ‚Ñ≥=
(ùê¥,ùëã,ùêø). First, two encoders are used here: one is a
lattice encoder and the other is a structure encoder. Ini-
tially, the lattice encoder encodes the lattice matrix ùêøinto
a lattice representation ‚ÑéL, which contains the informa-
tion of periodicity. The structure encoder first encodes ‚Ñ≥
into a structure representation ‚Ñéswith the aid of a pe-
riodic invariance multi-graph (PIMG) module, and then
two mutex representations ùëîsand¬Øùëîsare formed from ‚ÑéS
by mutex masking. The next step is decoding. The lat-
tice decoder decodes ‚ÑéLintoùëùL, and the coordinate and
atom decoders decode ùëîs,¬ØùëîsintoùëùC,¬ØùëùC, and ùëùA,¬ØùëùA,
respectively. Finally, crystal reconstruction is conducted
using ( ‚ÑéL,ùëùC,ùëùA) and ( ‚ÑéL,¬ØùëùC,¬ØùëùA).ùëùAand¬ØùëùAare used
for atom-type contrastive learning, which emphasizes the
role of the species of the atoms, and the periodic attribute
learning (PAL), which can guarantee the introduction of
the periodicity property.
Metux masking is a special point of this research. In a
nutshell, ùëîscan be defined as
ùëîùëñ
s=\{Ô∏É
‚Ñéùëñ
s, ùëñ /‚àà‚Ñ≥,
[MASK] , ùëñ‚àà‚Ñ≥,(36)
where‚Ñ≥is a uniform distribution. ¬Øùëîùëñ
scan be derived from
the mutex mask of ‚Ñ≥, namely ¬Ø‚Ñ≥. This mask process
enables the model to learn through structural relation-
ships between two complementary sets of atoms. Based
on the mutex masks, the authors designed crystal recon-
struction and atom-type contrastive learning. They im-
plemented crystal reconstruction by optimizing the loss
function‚ÑíREC.
Because the crystal is described by three vectors, natu-
rally‚ÑíRECis also divided into three parts, namely ‚Ñíùê¥,‚Ñíùëã,
and‚Ñíùêø.‚Ñíùê¥corresponds to ùê¥, which is the cross entropy
between real and predicted atom types. ‚Ñíùëãcorresponds
toùëã, which is based on the distance from the coordinate
of each atom to the center coordinate. ‚Ñíùêøcorresponds to
ùêø.
Owing to the influence of atom types for chemical prop-
erties, the learning of atom types was also referenced in
this work. The authors utilized Barlow Twins loss to con-sider the significance of atom types. They aligned the
cross-correlation matrix of ùëùùëñ
ùê¥and¬Øùëùùëñ
ùê¥as closely as possible
with the identity matrix to perform the optimization.
The last point relates to periodicity-related arrange-
ments. The authors introduced a PIMG and PAL to en-
sure the validity of periodicity. A crystal can be considered
a multi-graphùí¢:= (ùê¥,ùêª), where ùê¥represents the set
of atom nodes, and ùêªrepresents the set of edges, which
are relevant atom pairs. The authors ensured periodic in-
variance by constructing edges using Euclidean distance.
Then, they designed a multi-graph attention mechanism
to capture structural patterns. First, a linear transforma-
tion is applied to the initial feature vectors of the nodes,
which is parameterized by the weight ùëä. Subsequently,
the new atom node can be derived using
ùëüùëñùëó=ùëìùëé(ùëäùëé ùëñ,ùëäùëé ùëó),
ùúÄùëñùëó=exp(LeakyReLU( ùëüùëñùëó))‚àëÔ∏Ä
ùëò‚ààùí©ùëñexp(LeakyReLU( ùëüùëñùëò)),
\^{}ùëéùëñ=ùúëFC(Ô∏É‚àëÔ∏Å
ùëó‚ààùí©ùëñùúÄùëñùëó¬∑ùëéùëñ)Ô∏É
, (37)
where ùëìùëédenotes a single-layer feed-forward neural net-
work, and ùúÄis a correlation coefficient. ùêøùëíùëéùëòùë¶ùëÖùëíùêøùëà is
the activation function, and ùúëFCis a fully-connected layer.
The final step is to send the multi-graph and new atom
nodes into DimeNet++,[349]which is an E(3) invariance
GNN, to learn the crystal structure representations. The
PAL module focuses on learning about the three compo-
nents associated with periodicity: discrete direction, unit
cell position, and distance between nodes. They utilized
three attribute learners to study these three sections and
optimize the prediction by computing ‚ÑíCAA, which con-
tains three losses corresponding to three parts mentioned
above.
3.4. Generative AI Accelerates Materials Discov-
ery. In recent years, diffusion generative models have
attracted significant interest for their realistic effects in
image generation, such as stable diffusion.[350]Methods
based on diffusion generative models, such as denoising
diffusion probabilistic models (DDPMs)[351]and score-
based diffusion,[352]have been widely applied in molecu-
lar docking (AlphaFold3,[353]DiffDock[354]), and molec-
ular generation (torsional diffusion[355]). In the con-
text of materials discovery, materials are in three cate-
gories: known knowns, known unknowns, and unknown
unknowns. While the largest existing explorations of
previously uncharted crystalline materials are on the or-
der of 106to 107materials, the potential space of sta-
ble inorganic compounds, even within the realm of qua-
ternary compounds and fixed stoichiometry, reaches an
astounding 1010possibilities. The third category, the
‚Äúunknown unknowns‚Äù, represents the most challenging
yet vast frontier. Generative models present some of
the most effective means of glimpsing into this largely
uncharted space. In the field of material structure
prediction, notable generative AI methods, including
CDVAE,[23]CrystalGAN,[356]FlowMM,[357]DiffCSP,[24]
027403-25

Chinese Physics Letters 42, 027403 (2025) Review
and DiffCSP++,[358]have emerged. This section will fo-
cus on these generative AI approaches.
CDVAE. The crystal diffusion variational autoencoder
(CDVAE)[23]is a prominent early algorithm developed
to generate stable periodic structures of materials. It
employs a combination of joint equivariant diffusion and
SE(3)-equivariant GNNs, explicitly encoding interactions
across periodic boundaries while preserving permutation,
translation, rotation, and periodic invariance. Further-
more, CDVAE introduces a noise conditional score network
(NCSN)[352]as the VAE decoder to generate more realistic
material structures and utilizes Langevin dynamics to re-
fine the generation process. The algorithm also establishes
three benchmark datasets specifically for material genera-
tion, along with a set of physically meaningful evaluation
tasks and metrics. Extensive experiments validated the
superior performance of CDVAE in tasks such as material
reconstruction, generation, and property optimization, un-
derscoring its significant potential in advancing the field of
materials discovery. The workflow of CDVAE consists of
several key steps. First, a periodic material encoder is em-
ployed to map the material ùëÄinto a latent representation.
Subsequently, three independent MLPs predict the compo-
sition ùëê, lattice ùêø, and number of atoms ùëÅ, respectively.
A conditional score matching decoder with equivariance is
used to denoise the atomic coordinates and the probabil-
ity distribution of atom types. A constraint is incorpo-
rated into the loss function to account for the periodicity
of atomic coordinates. Finally, during each denoising step,
atomic types and coordinates are updated using Langevin
dynamics. Con-CDVAE[359]is a modified version of CD-
VAE designed to directly generate crystal structures based
on crystal properties. Incorporating the conditional gener-
ation method of DALL-E2,[360]Con-CDVAE achieves this
objective by introducing new modules specifically designed
for crystal latent representations in CDVAE. In the first
training phase, Con-CDVAE trains the core framework of
CDVAE and applies MLPs to the crystal latent represen-
tations to predict crystal properties, aligning crystal struc-
tures with their corresponding properties. In the second
training phase, Con-CDVAE introduces a prior module in-
spired by DALL-E2, which takes crystal properties as in-
puts to generate crystal latent representations. With these
new modules, Con-CDVAE enables the direct generation
of crystal structures from crystal properties. The model
has been applied to conditional generation tasks based on
formation energy and bandgap, revealing that the results
for conditional generation of formation energy outperform
those for bandgap. While achieving conditional genera-
tion, the model retains the crystal latent variables, po-
tentially enabling manipulable structure generation such
as latent variable interpolation. However, a key chal-
lenge lies in the design and training of the prior module
to generate diverse and accurate crystal latent variables
from the given crystal properties. The conditional CDVAE
(Cond-CDVAE)[361]is a DL-based generative model, de-
signed for crystal structure prediction (CSP). This modelgenerates physically realistic crystal structures based on
user-defined material compositions and external condi-
tions, such as pressure. By leveraging Cond-CDVAE, the
research team successfully generated high-fidelity crystal
structures under various pressure conditions, achieving an
accuracy of 59.3\%, with an impressive 83.2\% accuracy for
structures containing fewer than 20 atoms‚Äìsurpassing tra-
ditional global optimization-based CSP methods. Further-
more, a comprehensive dataset (MP60-CALYPSO) com-
prising over 670,000 local minimum structures, including
both ambient and high-pressure crystal configurations, was
established. The generated structures exhibited superior
convergence rates and fewer ionic steps during DFT lo-
cal optimization, indicating that they were closer to local
energy minima. Cond-CDVAE integrates discrete chemi-
cal compositions and continuous pressure attributes, utiliz-
ing SE(3)-equivariant GNNs to encode crystal structures,
thereby ensuring invariance under permutations, transla-
tions, rotations, and periodicity. Evaluation results under-
scored the model‚Äôs high accuracy and reliability in CSP, il-
lustrating the significant potential of DL generative models
to accelerate the discovery and design of novel materials.
MatterGen. MatterGen[362]operates through a two-
step process. In the first step, a base model is pre-trained
to generate stable and diverse materials. The model was
trained on data from the Materials Project and Alexandria
databases, where stability is defined by DFT relaxation to
a local energy minimum, with the energy per atom de-
viating no more than 0.1 eV from the reference database
values. Novelty was ensured by verifying that the gener-
ated structures did not exist in the Alexandria dataset. In
benchmark comparisons using the same Materials Project
dataset, MatterGen outperformed CDVAE by achieving a
higher proportion of stable, unique, and novel (S.U.N.)
materials while also exhibiting lower root mean square
deviation (RMSD) values, which indicates better align-
ment with DFT-relaxed structures. Furthermore, when
trained on a larger dataset, MatterGen demonstrated even
stronger performance. In the second step, MatterGen fine-
tunes the base model using adapter modules, which allow
for customization based on specific chemical compositions,
symmetry requirements, and desired electronic, magnetic,
and mechanical properties. This adaptability makes Mat-
terGen a versatile and effective tool for targeted material
discovery across a wide range of application domains. A
similar generative algorithm is SyMat.[363]
DiffCSP. CSP using joint equivariant diffusion
(DiffCSP)[24]is a specialized algorithm for CSP. It outper-
forms existing baseline methods, such as CDVAE, across
multiple benchmark datasets while offering lower compu-
tational costs than DFT-based approaches. DiffCSP gen-
erates crystal structures that satisfy periodic E(3) invari-
ance, ensuring stability in translation, rotation, and peri-
odicity. Furthermore, DiffCSP demonstrates strong scala-
bility, making it applicable not only to fixed-composition
CSP but also to tasks involving atomic type generation
027403-26

Chinese Physics Letters 42, 027403 (2025) Review
and property optimization. By employing a joint equivari-
ant diffusion process, DiffCSP simultaneously operates on
lattice vectors and atomic fractional coordinates to pre-
serve periodic invariance, utilizing denoising models and
message-passing mechanisms to improve prediction accu-
racy. The model demonstrated exceptional performance
in crystal structure and property prediction experiments,
underscoring its considerable potential to enhance both
the accuracy and efficiency of CSP. In crystal structures,
atoms are periodically arranged within the unit cell, de-
noted as‚Ñ≥= (ùê¥,ùëã,ùêø), where ùê¥‚ààR‚Ñé√óùëÅindicates
atom types, ùëã‚ààR3√óùëÅrepresents the Cartesian coor-
dinates of each atom, and ùêø‚ààR3√ó3is the lattice ma-
trix defining crystal periodicity. Any atom‚Äôs Cartesian
coordinates and type within the crystal are expressed as
\{(ùëé‚Ä≤
ùëñ,ùë•‚Ä≤
ùëñ)|ùëé‚Ä≤
ùëñ=ùëéùëñ,ùë•‚Ä≤
ùëñ=ùë•ùëñ+ùêøùëò,‚àÄùëò‚ààZ3√ó1\}. A relation-
ship between Cartesian and fractional coordinates is given
byùë•=‚àëÔ∏Ä3
ùëñ=1ùëìùëñùëôùëñ. For the generation process, DiffCSP
adopts a fractional coordinate system ‚Ñ≥= (ùê¥,ùêπ,ùêø).
With ùêøas a continuous variable and the one-hot encoding
ofùê¥treated similarly, a standard DDPM[69]can be used
to generate ùêøandùê¥, with the loss function
‚Ñíùêø/ùê¥=Eùúñ‚àºùí©(0,ùêº)[‚Äñùúñ‚àí\^{}ùúñùêø/ùê¥(‚Ñ≥ùë°, ùë°)‚Äñ2
2]. (38)
The equivariant denoising model ùúëpredicts the denoising
terms \^{}ùúñùêø(‚Ñ≥ùë°, ùë°) and \^{}ùúñùê¥(‚Ñ≥ùë°, ùë°). For ùêπ, periodicity is han-
dled using a score-matching (SM) based framework.[352]
DiffCSP++. DiffCSP++[358]is an advanced crystal-
structure generation algorithm specifically optimized to
account for space group constraints. The algorithm
demonstrates exceptional performance in generating crys-
tal structures that adhere to specific space group symme-
tries. Compared with both learning-based and DFT-based
methods, DiffCSP++ not only exhibits enhanced perfor-
mance but also achieves notable success in ab initio crystal
generation tasks, producing crystals with valid composi-
tions and stable structures. Experimental results consis-
tently show that DiffCSP++ surpasses existing baseline
methods in both crystal structure generation and property
statistics, underscoring its significant potential in materi-
als design.
DiffCSP++ considers the constraints of space groups
to generate crystal structures. Space groups are collec-
tions of symmetry operations of crystals, constrained by
the o(3) invariance of the lattice matrix and the Wyckoff
positions of fractional coordinates. According to the polar
decomposition,[364]the lattice matrix ùêø‚ààR3√ó3can be
decomposed as ùêø=ùëÑexp(ùëÜ), where ùëÑis an orthogonal
matrix, and ùëÜis a symmetric matrix. Any symmetric ma-
trix can be expressed using six symmetric basis functions,
with coefficients that are o(3) invariant:
ùëÜ=6‚àëÔ∏Å
ùëñ=1ùëòùëñùêµùëñ (39)ùêµ1=‚éõ
‚éú‚éù0 1 0
1 0 0
0 0 0‚éû
‚éü‚é†,ùêµ2=‚éõ
‚éú‚éù0 0 1
0 0 0
1 0 0‚éû
‚éü‚é†,
ùêµ3=‚éõ
‚éú‚éù0 0 0
0 0 1
0 1 0‚éû
‚éü‚é†,ùêµ4=‚éõ
‚éú‚éù1 0 0
0‚àí1 0
0 0 0‚éû
‚éü‚é†,
ùêµ5=‚éõ
‚éú‚éù1 0 0
0 1 0
0 0‚àí2‚éû
‚éü‚é†,ùêµ6=‚éõ
‚éú‚éù1 0 0
0 1 0
0 0 1‚éû
‚éü‚é†.
By determining the coefficients ùëòof six symmetric basis
functions ùêµ, DiffCSP++ ascertains the lattice matrix ùêø.
During noise addition and denoising, these coefficients can
be transformed. The 230 space groups are categorized
into six crystal families ùê∫family (triclinic, monoclinic, or-
thorhombic, tetragonal, hexagonal, and cubic), each im-
posing distinct constraints on ùëòùëñ. These families define six
projection spaces, ensuring consistent projections to the
prior crystal family space throughout the crystal gener-
ation process. The Wyckoff positions ( ùëäpositions ) repre-
sent the symmetry of equivalent atoms in the unit cell,
with ùëÅfractional coordinates ùêπ‚ààR3√óùëÅderived from ùëÅ‚Ä≤
basic fractional coordinates ùêπ‚Ä≤‚ààR3√óùëÅ‚Ä≤. Noise addition
and denoising can be performed on these basic coordinates
ùêπ‚Ä≤, enabling the determination of fractional coordinates
for all atoms within the unit cell. The coefficients ùëòare
treated as continuous variables, and the one-hot encoded
atomic types of Wyckoff positions are similarly consid-
ered, both generated using standard DDPM. Because the
fractional coordinates of the Wyckoff positions are peri-
odic, DiffCSP++ utilizes an SM framework for generation.
CrystalFormer[365]also considers the constraints of space
groups to generate crystals.
CrystalFormer. CrystalFormer[365]is a transformer-
based autoregressive model specifically designed to gener-
ate crystal materials that respect space group symmetries.
The model learns the discrete and sequential nature of
Wyckoff positions to directly predict the type, position,
and lattice parameters of symmetry-inequivalent atoms
within the lattice, thereby generating crystal structures.
Compared with traditional CSP methods, CrystalFormer
has significant advantages in tasks such as symmetry struc-
ture initialization and element substitution. Additionally,
CrystalFormer facilitates property-guided material design
by integrating solid-state chemistry knowledge and heuris-
tic rules, enabling systematic exploration of crystal ma-
terials and the discovery of novel superconductors with
low Ehull values ( <0.1 eV/atom). To achieve these ca-
pabilities, CrystalFormer incorporates algorithms such as
Markov chain monte Carlo[366]sampling, Gaussian mix-
ture models,[367]and von Mises distributions, effectively
incorporating space symmetries and other physical con-
straints during the generation process. This research offers
new insights into the discovery of high-temperature super-
conductors and advances the field of materials modeling
and discovery.
027403-27

Chinese Physics Letters 42, 027403 (2025) Review
GNoME. Graph networks for materials exploration
(GNoME)[31]is a significant advancement in the genera-
tion and discovery of novel materials through an innovative
active learning algorithm. Departing from conventional
approaches that rely on sampling from existing datasets,
GNoME challenges the prevailing assumption that newly
generated materials must adhere to the same data distri-
bution as the training set. By employing an active learn-
ing framework, it efficiently generates millions of novel
crystal structures. This methodology uncovers 2.2 mil-
lion potentially stable materials, many of which transcend
traditional chemical intuition. Of these, 381,000 materi-
als are integrated into the materials database, with 736
structures experimentally validated for stability, thereby
enriching the field with valuable resources for further re-
search and practical applications in materials science.
The GNoME framework operates through two keymodules: symmetry-aware partial substitutions combined
with random structure search, and GNN-based modeling
of material properties. These components drive two in-
dependent material discovery pipelines. The structural
pipeline focuses on evaluating the stability of crystal
frameworks without considering specific atomic types, fil-
tering randomly generated structures using GNoME to re-
tain potentially stable frameworks. In contrast, the com-
positional pipeline uses chemical formulas as inputs for
GNoME, identifying stable chemical combinations to ex-
plore novel material compositions. After structures are
selected through these pipelines, DFT calculations are per-
formed to further validate their structural stability. Stable
materials are then added to the training set for subsequent
iterations, creating an iterative active learning loop. This
process facilitates the discovery of new materials that ex-
tend beyond existing data distributions.
Iterative optimization 
Experimental
validation Theoretical calculations
and simulationsFurther
screening Experimental
synthesisComputational
modelingDesign and
generation of
materialsHigh-
throughput
screeningAI-driven
Fig. 5. General process of inverse design of materials, which is divided into two main parts: the AI-driven theoretical
calculation and experimental validation parts. The theoretical calculation part is further subdivided into material
design and generation, high-throughput screening, and computational modeling.
InvDesFlow. The InvDesFlow[72]develops an AI-
driven workflow for discovering high- ùëácsuperconductors
that are not present in any existing database. In this sur-
vey, we summarize the general process of the inverse design
of materials, as shown in Fig. 5. The process is divided
into two main parts: theoretical calculations and exper-
imental validation. The theoretical calculations are fur-
ther subdivided into material design and generation, high-
throughput screening, and computational models. Unlike
traditional inverse design, the entire theoretical part is
fully AI-driven, with AI implementing the entire theoreti-
cal simulation process.
OMat24. Meta has introduced Open Materials 2024
(OMat24),[32]a comprehensive dataset featuring over 110
million DFT-based calculations, emphasizing structural
and compositional diversity. This dataset spans non-
equilibrium atomic crystal structures and varied elemental
compositions, offering a rich resource for materials discov-
ery. Utilizing a pre-trained EquiformerV2 model, Meta
achieved state-of-the-art results on the Matbench Discov-
ery‚Ä°leaderboard. Through extensive experimentation,they explored the impact of different training strategies
on model performance, providing valuable insights for fu-
ture advancements. By openly sharing both the dataset
and model, Meta empowers the research community to
build upon and refine these foundational resources, foster-
ing progress in AI-driven materials science.
FlowLLM. Meta has introduced FlowLLM,[368]an ad-
vanced crystal generation model that integrates LLMs
with Riemannian flow matching (RFM) to enable the de-
sign of novel crystalline materials. FlowLLM first fine-
tunes an LLM to capture an effective foundational dis-
tribution of metastable crystals within textual represen-
tations. After the conversion of text to graph representa-
tions, the RFM model further refines LLM-generated sam-
ples through iterative optimization of atomic coordinates
and lattice parameters. FlowLLM surpasses existing state-
of-the-art methods by over threefold in stable material
generation rates. The structures produced by FlowLLM
are notably closer to relaxed states, substantially reducing
post-processing costs while improving both the efficiency
and precision of material generation, thereby marking a
‚Ä°https://matbench-discovery.materialsproject.org/
027403-28

Chinese Physics Letters 42, 027403 (2025) Review
significant advancement in the field of materials science.
3.5. Large Language Models. In recent years, LLMs,
such as GPT-3.5 Turbo,[369]GPT-4S, and BERT,[347]
have been widely adopted across various scientific fields,
becoming essential tools for natural language processing
and knowledge generation. OpenAI‚Äôs GPT-3.5 Turbo and
GPT-4 are particularly popular owing to their ability to
generate human-like text, answer complex questions, and
facilitate knowledge synthesis. These models are pow-
ered by transformer-based architectures,[22]where self-
attention mechanisms enable the efficient processing of
large-scale textual data across diverse applications. Sim-
ilarly, Google‚Äôs BERT, distinguished by its bidirectional
training approach, captures context from both directions
in a text, making it particularly effective for tasks that re-
quire nuanced understanding, such as question-answering.
In addition to these general-purpose models, domain-
specific LLMs such as Coscientist,[370]SciBERT[371]and
MatSciBERT[372]have been developed to improve perfor-
mance in particular scientific domains. SciBERT, based
on the BERT architecture, is fine-tuned on scientific lit-
erature, enabling more precise information retrieval and
classification within scientific texts. Similarly, MatSciB-
ERT, tailored for materials science, incorporates domain-
specific language and terminology to enhance its effec-
tiveness in analyzing material-related data and generat-
ing specialized tags. Building upon these foundational
and domain-specific models, researchers are increasingly
employing LLMs for inverse material design, using these
models to effectively predict and optimize material prop-
erties, as discussed in the following sections.
In sustainable concrete design, a methodology using
LLMs to develop alkali-activated concrete formulations to
reduce the carbon footprint and environmental impact
of concrete production was developed.[373]Researchers
utilized GPT-3.5 Turbo and GPT-4 models to create a
‚Äúknowledge-driven design‚Äù (KDD) system, which inte-
grates domain-specific knowledge with experimental feed-
back to enhance the accuracy and efficiency of material
design. Through the automated generation of low-calcium
concrete formulations, property optimization, and perfor-
mance prediction, this system demonstrated a marked
improvement in predictive accuracy for complex com-
posite mixtures. This innovative approach introduces a
sustainable paradigm in concrete design, supporting the
development of an environmentally friendly concrete in-
dustry. In the field of battery technology, particularly
for rapid charging applications, the BatteryGPT system
leverages LLMs to accelerate information extraction and
innovation.[374]Utilizing retrieval-augmented generation
technology, BatteryGPT aggregates data from over 2,200
publications and incorporates advanced technical method-
ologies to facilitate knowledge generation and optimiza-
tion in fast-charging battery technology. BatteryGPT pro-
vides domain-specific literature reviews and recommends
the latest solutions for fast-charging materials, such asLi3P-enhanced solid electrolyte interfaces and laser pat-
terning. This system significantly enhances the efficiency
of information integration and processing in material in-
novation, supporting advancements in battery technology
aimed at extending electric vehicle range and improv-
ing energy storage. In a study on microstructure evo-
lution within materials, LLMs generated code and sim-
ulated complex multiphysics-coupled models.[375]The re-
searchers employed ChatGPT to produce code based on
phase-field models to simulate the evolution of material
microstructures over time. Although the model-generated
code required further validation and adjustments for com-
plex equations, this research systematically explored the
potential of LLMs in microstructure modeling. This novel
approach highlights the utility of LLMs in materials educa-
tion and research, offering new perspectives for integrated
computational materials engineering (ICME)¬∂. From a
broader perspective, Lei et al. investigated automation
and knowledge integration benefits of LLMs within mate-
rials science.[376]The study showed that LLMs not only
retrieve knowledge and generate code through natural lan-
guage instructions but also conduct multi-level literature
analysis and generate tags, such as for 3D microstruc-
ture analysis and micrograph labeling. By leveraging fine-
tuned, domain-specific models such as SciBERT[371]and
MatSciBERT,[377]this study demonstrated that LLMs ef-
fectively process complex materials science data and pro-
duce high-quality structured information. This advance-
ment supports the automation of materials science work-
flows with significant applications in rapid charging and
renewable energy integration.
In summary, LLMs have shown remarkable potential in
inverse materials design, transforming traditional materi-
als innovation processes. Leveraging advanced language
processing and knowledge synthesis capabilities, LLMs
have significantly enhanced the accuracy of property pre-
diction and optimization while also providing sustainable
solutions to pressing challenges in materials science. For
instance, in sustainable concrete design, LLMs enable re-
searchers to develop eco-friendly materials that lower car-
bon emissions. In battery technology, LLMs facilitate the
integration of vast information, accelerating innovation in
fast-charging batteries that support extended electric ve-
hicle ranges and improved energy storage. Additionally,
LLMs contribute to the simulation of material microstruc-
tures and multiphysics modeling, offering new possibili-
ties for ICME and materials education. As applications of
LLMs in inverse materials design continue to expand, these
models are anticipated to become essential in property
prediction, novel material discovery, and the automation
of knowledge integration. Coupled with domain-specific
models, LLMs promise breakthroughs in processing com-
plex materials data and generating high-quality informa-
tion, supporting the development of automated scientific
workflows. Future research may further explore robust al-
gorithm designs and the integration of real-time data anal-
Shttps://openai.com/gpt-4
¬∂https://link.springer.com/book/10.1007/978-3-030-40562-5
027403-29

Chinese Physics Letters 42, 027403 (2025) Review
ysis with experimental feedback, thereby enhancing the
breadth and depth of LLMs applications in materials sci-
ence and providing technical support for sustainable and
intelligent materials innovation.
3.6. Datasets. As the previous section shows, various
datasets are typically used when testing the performance
of a model. In Table 2, we briefly introduce a few common
material datasets.
Table 2. Some typical databases. Listed in the table are
their name, amount of data, description, and reference.
Datasets Size Description Reference
QM7 >7,000 DFT calculations [378]
QM9 >134,000 DFT calculations [337]
MD17 >100,000 MD simulation data [379,380]
MP >150,000 Materials Project [381]
OQMD >1,226,000 Quantum Materials [348]
OC20 >133,940,000 Open Catalyst 2020 [382]
JARVIS-DFT >80,000 DFT calculations [383]
PubChemQC >85,000,000 DFT calculations [384,385]
Different researchers have created different datasets for
different types of materials. In the specific research, dif-
ferent datasets are selected according to the requirements,and the appropriate data from the dataset are selected to
conduct experiments. Moreover, different researchers se-
lect different previous studies with some impact as bench-
marks, such as CGCNN[73]and ALIGNN.[338]Some re-
searchers use different frameworks as benchmarks for dif-
ferent parts in their studies.
4. Future Directions. The previous chapters have pro-
vided a comprehensive overview of the way that AI has ac-
celerated advancements in the inverse design of functional
materials, alongside a rapid evolution of AI technologies
within the materials science domain. In this chapter, we
will delve into potential future directions for AI across each
critical stage of the reverse design workflow for functional
materials. Key stages in this workflow encompass the de-
sign and generation of novel materials, high-throughput
screening for target functional properties, theoretical vali-
dation of candidate materials through computational mod-
eling, and the experimental synthesis and testing necessary
to confirm material performance. By advancing and de-
signing AI algorithms that deeply integrate with each of
these stages, we aim to accelerate every step of the process,
enabling AI to fully achieve its transformative potential in
the inverse design of materials.
ÔÅ∞
ÔÅ∞
ÔÅ∞
ÔÅ∞ÔÅ∞ ÔÅ∞
ÔÅ∞
ÔÅ∞ÔÅ∞
ÔÅ∞
ÔÅ∞ÔÅ∞
ÔÅ∞
ÔÅ∞
ÔÅ∞ÔÅ∞
ÔÅ∞
ÔÅ∞
ÔÅ∞ÔÅ∞ÔÅ∞
ÔÅ∞ÔÅ∞
ÔÅ∞
ÔÅ∞Design and generation
High -throughput
screening
Computational
modeling
Experimental
synthesisConditional generation models
AI predict material properties
AI-accelerated DFT calculations
Integrating ML models with
robotic automation systemsDynamic adjustment of predictive
models with real -time experimental
dataDensity functional perturbation
theoryDeep -learning DFT HamiltonianLLMs rankingLLMs generationChemical composition generationBenchmarks, dataset
Active learning screeningAI structural relaxationFunctional materials
Space group numbers
Heterostructure
Amorphous
Formation energy
ML techniques for Hamiltonian -based
Ab Initio calculations
Machine learning interatomic potentials
AI predict phonon spectra
AI predict EPCBand gap, DosT
c, superconductivity
Thermal conductivity,
seebeck coefficient, ZT value
Fig. 6. Future of AI-driven inverse design of materials. This figure outlines the potential development directions
of AI in the key stages of the functional material reverse design workflow, including the design and generation
of new materials, high-throughput screening, computational modeling for candidate validation, and experimental
synthesis and testing. By optimizing the integration of AI algorithms, these AI techniques can accelerate efficiency
and innovation in materials discovery.
4.1. Design and Generation of New Materials. For
the inverse design and generation of new functional ma-
terials, current generative models remain constrained in
their capabilities and fail to satisfy the complex require-
ments of material design. The following challenges repre-
sent areas in which we anticipate AI advancements may
provide impactful solutions in the future. The first one is
that the AI-generated material structures are frequently
not in a stable ground state, necessitating additional as-sessment and structural relaxation. Enhancing generative
models to address this limitation remains a key objective
for future development. The second one is the genera-
tive models based on chemical composition are currently
scarce, despite being frequently required in experimental
science. LLMs may provide such capabilities in the fu-
ture. The third one is that we require conditional gen-
eration methods in which a partially known structure or
chemical formula serves as input, producing a complete
027403-30

Chinese Physics Letters 42, 027403 (2025) Review
structure or formula. For example, given part of a het-
erostructure, we aim to generate the remaining portion.
The fourth one is that the space group family-based gener-
ation algorithms, such as DiffCSP++, have been achieved,
but algorithms enabling direct control over space group
numbers for new structure generation have yet to be de-
veloped. Moreover, the generative AI algorithms specifi-
cally designed for diverse functional materials have yet to
be developed. A significant number of materials exist in
amorphous rather than crystalline forms, highlighting the
necessity for the future development of generative algo-
rithms specifically for amorphous materials. Furthermore,
the generative algorithms discussed above necessitate the
development of more equitable benchmarks for assessing
model performance. Consequently, the release of suitable
datasets and corresponding benchmarks is a crucial task.
Creation and Updating of Datasets. With the assis-
tance of AI, the development of materials science has pro-
gressed significantly, but some urgent problems remain to
be solved. First, large databases already exist for some of
the materials such as MP,[381]OQMD,[348]and OC20.[382]
However, data for some complex materials such as HEAs
are still lacking. Some methods are designed to deal with
these materials.[262]However, the creation of a database of
complex materials is also required. Second, with the assis-
tance of AI, many new materials have been discovered that
exist in theory, but these new materials may not actually
be synthesized in actual experiments. Experimental val-
idation is required to determine whether these materials
should be added to the database. However, the progress
of experiments is often insufficient. Thus, we could create
a candidate database that records AI-generated materials.
The third point is that many AI-generated materials do
not have a standardized nomenclature. Many researchers
use simple numbers to represent generated materials right
in their own papers, which is not conducive to the docu-
mentation of new materials and the retrieval of new ma-
terials. All of the above are problems that must be solved
or optimized with respect to the database. Additionally,
some databases related to AI have been established, which
can be considered as a future direction.
LLMs. The future prospects of LLMs in inverse ma-
terial design are promising. As the technology matures,
LLMs are expected to enable profound changes in au-
tonomous material discovery and efficient data integra-
tion. First, a significant potential of LLMs in inverse ma-
terial design lies in achieving autonomous material dis-
covery and design systems. These systems can rapidly
adjust design strategies while interpreting human instruc-
tions and dynamically adapt to different tasks and ma-
terial properties, ultimately enabling an automated ma-
terial research and development (R\&D) process. For in-
stance, the LLMatDesign[386]project demonstrated the
potential of LLMs to achieve autonomous material de-
sign through instruction fine-tuning in low-sample envi-
ronments. Its framework enables a model to perform ma-
terial screening and optimization based on design instruc-
tions and chemical knowledge. With future enhancementsin model optimization on datasets and improved multi-
modal integration capabilities, LLMs are expected to be
more flexible in complex material tasks, even forming ‚Äúau-
tonomous laboratories‚Äù to accelerate the material R\&D
process. The HoneyComb system[387]builds upon this by
using its high-quality knowledge base, MatSciKB,[387]and
computational tool center, ToolHub, to enable real-time
data updates and cleaning support, providing a stronger
data foundation and scientific computing capabilities for
autonomous material design. This indicates that future
LLMs will not only generate and evaluate material design
schemes but also continuously learn and improve through
knowledge bases, laying the foundation for fully automated
material discovery. Second, future LLMs will make signif-
icant strides in the efficient integration and extraction of
material data. The key to achieving this objective lies in
building high-quality multi-modal datasets and enhancing
a model‚Äôs ability for complex reasoning. Several studies
have emphasized the necessity of dataset expansion and
multi-modal information integration. For example, Miret
et al.[388]proposed a six-step interactive roadmap that
progressively improves a model‚Äôs reasoning performance
in complex material tasks by integrating text, images, and
experimental data. Similarly, Lei et al.[376]highlighted the
importance of high-quality multi-modal data for enhanc-
ing the model‚Äôs understanding of the complexity of the
materials science field. The study indicated that by dy-
namically integrating experimental data, LLMs can signif-
icantly enhance their ability to parse information related
to material properties and structures, thereby advancing
the automation of the material discovery process. These
studies indicate that through the construction and integra-
tion of multi-modal information, future LLMs will exhibit
stronger reasoning capabilities in complex materials sci-
ence tasks, particularly under conditions of limited data,
providing reliable support for the design and validation of
new materials.
In conclusion, the future development prospects of
LLMs in inverse material design are extensive. As the
capabilities of models in data processing, knowledge in-
tegration, and complex reasoning continue to improve,
LLMs are anticipated to significantly accelerate the mate-
rial R\&D process, promoting autonomous and intelligent
material design. By dynamically acquiring and parsing
multi-modal data and continuously learning from the lat-
est research developments in materials science, LLMs can
effectively support all stages of material discovery, from
screening to structural optimization and experimental plan
generation, gradually achieving a more comprehensive and
efficient material innovation process. This technological
advancement will not only aid scientists in addressing cur-
rent research challenges more rapidly but also create new
research avenues in the field of materials science and laying
a solid foundation for future technological innovation.
4.2. High-Throughput Screening of Functional Mate-
rials. In recent years, the high-throughput screening of
target functional materials has predominantly utilized in-
variant GNNs to classify and predict material properties,
027403-31

Chinese Physics Letters 42, 027403 (2025) Review
subsequently establishing specific thresholds for material
selection. This approach has resulted in numerous signifi-
cant contributions, enabling the accurate prediction of sev-
eral physical properties, including formation energy, band
gap, Debye temperature, and density of states. However,
certain physical properties remain challenging to predict
with high precision due to their inherent complexity. The
following are potential challenges that require further in-
vestigation.
The rapid development of AI technology in recent years
has provided new momentum for the inverse design of su-
perconducting materials, resulting in the establishment
of a comprehensive workflow for discovering new high-
ùëácsuperconductors. However, considerable potential for
enhancement across various dimensions remains. For in-
stance, the application of AI to accurately assess whether a
material exhibits superconductivity, predict the ùëácof any
superconductor‚Äìwhether characterized by conventional or
unconventional properties and defined by its chemical for-
mula or crystal structure‚Äìexpedite the DFT verification
process for EPC through AI integration, and provide more
precise guidance for experimental directions using AI. Ulti-
mately, we anticipate that advancements in AI will illumi-
nate new physics related to superconducting mechanisms
in the future.
For complex materials, such as high-entropy alloys,
the primary challenge associated with AI-assisted compu-
tation is the limited size of available datasets. As pre-
viously stated, several workflows have been proposed in
recent years to address this class of materials.[262,267,389]
However, the corresponding methods require further pro-
motion and application to assess their practicality and rea-
sonableness. Concurrently, the necessity for high-quality
datasets for complex materials persists. Moreover, some
studies have used activating learning to discover new and
efficient catalysts. This concept is very similar to the ‚Äúex-
ploration‚Äù and ‚Äúexploitation‚Äù concepts in reinforcement
learning. In the context of expanding the existing dataset,
exploitation enables AI to generate more data of the same
distribution, whereas exploration enables the step of acti-
vating learning. However, current activating learning still
requires DFT or other methods for validation, and the ver-
ified samples must be manually added to the dataset for
the next iteration. Therefore, if the steps of activating
learning can be automated, future exploration of crystals
through AI could significantly improve efficiency.
Note that in AI-driven high-throughput screening of
functional materials, significant gaps remain in mate-
rial classification and property prediction, particularly in
terms of accuracy and handling complex properties. Fu-
ture LLMs hold promise for advancing material recommen-
dation, ranking, and structural design through frameworks
such as natural language embeddings, which generate com-
positional and structural feature vectors of materials.[390]
Such models aim to better represent materials, identify
under-explored spaces, and streamline material optimiza-
tion. Despite these advancements, current ML methods
often struggle with reliably predicting key properties‚Äìsuchas thermal conductivity, Seebeck coefficient, and ZT value‚Äì
owing to the challenges in modeling nonlinear relationships
within complex material systems, including thermoelec-
tric materials.[126]Additionally, the accurate prediction of
dopant and structural effects on material performance re-
mains limited, with models such as DopNet capturing only
partial insights into these intricate dependencies.[129]Ad-
dressing these challenges requires AI models that can inte-
grate multi-scale data and adapt to experimental feedback,
ultimately improving robustness and reliability in predic-
tions. Furthermore, systems such as the HoneyComb il-
lustrate the need for interpretable AI models, which are
essential for achieving precise material recommendation
and structural optimization, particularly for high-stakes
applications requiring practical and reliable adoption.
4.3. Computational Modeling for the Validation
of Candidate Materials. Most conventional materials-
calculation methods are based on the DFT. Neverthe-
less, DFT-based approaches are constrained in their abil-
ity to accommodate a comprehensive range of materials,
largely owing to the influence of intricate terms such as the
exchange-correlation functional. Therefore, it is unsurpris-
ing that most new calculation methods are developed to
improve the quality of the calculations. Furthermore, the
combination of ùëéùëè ùëñùëõùëñùë°ùëñùëú calculation with AI is a popular
and promising avenue of research.
Some related studies have focused on predicting com-
plex terms with the assistance of AI. For example,
some researchers have employed ML techniques to pre-
dict EPC[391‚Äì393]and others have employed AI to predict
phonon spectra.[394,395]Furthermore, promising avenues
for researchers to utilize AI in optimizing alternative ver-
sions of DFT beyond the prevalent Kohn‚ÄìSham DFT[396]
exist. Attention should be given to recent research on
DeepH,[397‚Äì406]which is a framework using ML techniques
to study the Hamiltonian of materials to conduct ab initio
calculation. This method is highly efficient and achieves
high accuracy on many materials. Additionally, this ap-
proach is now being generalized to a wider range of sys-
tems, and many similar studies have been conducted, such
as HamGNN.[196,407,408]More research and applications in
these aspects are inevitable in the future.
To summarize, we can actually see the following points
worth trying for the combination of AI and material cal-
culation methods. The most important one is that the
lack of a generalized network structure or a generalized
approach to network selection, and the answer to how ML
technology can be integrated into material computation
methods is not conclusive, and many perspectives exist
that are worth testing. Moreover, there is still a certain
threshold for the various methods, which implies the ne-
cessity of writing relevant software packages or developing
relevant software.
4.4. Experimental Synthesis and Testing for Validating
Material Performance. As evidenced by recent research, a
workflow that integrates computational prediction with ex-
perimental synthesis can be an invaluable tool for studying
complex materials with limited datasets.[262,267,389]The
027403-32

Chinese Physics Letters 42, 027403 (2025) Review
proposed workflow enables researchers to obtain actual
materials directly, which is not always possible in other
fields in which materials prediction involves a disconnect
between computational prediction and experimental syn-
thesis. Note that the time cost of this workflow is not
insignificant and requires continuous improvement.
AI-guided experimentation holds significant promise
for advancing functional material development, particu-
larly in thermoelectric materials, where experimental syn-
thesis and optimization remain complex and resource-
intensive. In the field of thermoelectric materials, AI-
driven approaches, such as error correction learning mod-
els, refine predictive accuracy through iterative experi-
mental feedback, enabling faster identification of high-
performance materials.[135]Future research in AI-guided
experiments focuses on enhancing adaptability and scal-
ability for large-scale synthesis processes, incorporating
real-time data from experimental setups to dynamically
adjust predictive models. Furthermore, AI-guided exper-
imental planning proves invaluable for efficiently testing
the effects of doping, strain, and nano-engineered struc-
tures, which are critical for improving ZT values in ther-
moelectric materials.[130]By integrating ML models with
automation platforms, such as robotic experimental sys-
tems, researchers explore complex parameter spaces more
efficiently, facilitating the development of sustainable and
high-performance materials for applications such as waste
heat recovery and thermal management in microelectron-
ics.
5. Conclusion. In this paper, we discuss the history
of the inverse design of materials to pinpoint the essence
of AI-driven material design and to underscore the pivotal
role of AI technology in the process of inverse design of
materials. Furthermore, we comprehensively review of the
latest endeavors aiming at enhancing AI-driven inverse de-
sign processes, encompassing recent AI-based discoveries
on typical materials and the research progress and tech-
nological trajectories of AI in the field of materials sci-
ence. These collective efforts have significantly contributed
to the recent wave of advancements in AI-driven inverse
design of materials. While existing AI-driven inverse de-
sign of materials has yielded promising results, particularly
in the inverse design of functional materials for few-shot
learning scenarios, the future development of AI technol-
ogy in materials science and its application in key areas
remain open questions. Particularly with the burgeoning
growth of LLM technology, it is crucial to explore which
aspects of materials science can benefit from improvements
and optimizations offered by LLMs. We hope that our in-
sights will inspire further efforts in this field and propel
the development of AI-driven inverse design of materials
forward.
Notes and Contributions.
Author Contributions. The contributions of all au-
thors are listed as follows: Ze-Feng Gao and Zhong-Yi Lu
led this survey program; Ze-Feng Gao and Xiao-Qi Han
designed the structure of this paper; Ze-Feng Gao drafted
the abstract and Section 1; Xiao-Qi Han, Xin-De Wang,Meng-Yuan Xu, Zhen Feng, and Bo-Wen Yao drafted Sec-
tions 2 and 3. All faculty authors drafted various top-
ics in Section 4. Peng-Jie Guo provided comments to the
manuscript, and Xiao-Qi Han and Ze-Feng Gao proofread
the entire paper. The authors would like to thank Li-Jun
Chen and Xi-Wen Liu for useful discussions.
Survey Writing. This survey was planned during a
discussion meeting held by our research team, with the
objective of summarizing the latest advancements in AI-
driven inverse design of materials into a highly readable
report. Subsequently, we extensively revised the writing
and contents in several passes. Owing to space limitation,
we could include only a fraction of existing AI methods
in Fig. 4 by setting the selection criterion. We released
the initial version on November 14, 2024, and this latest
version on November 26, 2024.
Seeking for Advise. Despite our best efforts, this
survey may still have many limitations, such as the poten-
tial omission of important references, models, methods, or
topics, as well as the possibility of imprecise expressions
and discussions. We will continue to update this survey
and strive to enhance its quality as much as possible. For
our research team, the process of writing this survey is also
a journey of learning about research on AI-driven inverse
design of materials. Readers who have constructive sug-
gestions to improve this survey are welcome to send emails
to our authors. We will revise future versions based on the
comments and suggestions received and acknowledge those
readers who have contributed constructive suggestions in
our survey.
Update log. In this part, we regularly maintain an
update log for the submissions of this survey to arXiv:
‚àôFirst release on November 14, 2024: the initial ver-
sion.
‚àôUpdate on November 26, 2024: add several related
studies in Sections 2 and 3, revise Fig. 4 and Table 2, add
Fig. 5, improve the writing, and correct some minor errors.
Acknowledgements. The authors would like thank Lei
Wang, Yong Xu, Xingao Gong, Wanjian Yin, Miao Liu,
Hongjun Xiang, Hongming Weng, Jian Lv, Quansheng
Wu for valuable discussions. The author would like to
thank CPL editors for a huge amount of work in text
editing of the manuscript. This work was financially sup-
ported by the National Natural Science Foundation of
China (Grant Nos. 62476278, 12434009, and 12204533).
Z.Y.L. was also supported by the National Key R\&D Pro-
gram of China (Grant No. 2024YFA1408601), and the In-
novation Program for Quantum Science and Technology
(Grant No. 2021ZD0302402).
References
[1] Zunger A 2018 Nat. Rev. Chem. 20121
[2] Lee J, Park D, Lee M, Lee H, Park K, Lee I, and Ryu S
2023 Mater. Horiz. 105436
[3] Wang J, Li X, Zhang T, Chen Y, Wang T, and Zhao Y
2022 J. Phys. Chem. Lett. 13622
[4] Long T, Zhang Y X, and Zhang H B 2024
arXiv:2409.19124 [cond-mat.mtrlsci]
027403-33

Chinese Physics Letters 42, 027403 (2025) Review
[5] Wu Y 2024 Physics-Informed Machine Learning Methods
for Inverse Design of Multi-Phase Materials with Tar-
geted Mechanical Properties (PhD Dissertation)
[6] Chen L, Zhang W, Nie Z, Li S, and Pan F 2021 J. Mater.
Inform 14
[7] Abu-Mualla M and Huang J 2023 Mater. Des. 232
112103
[8] Onnes H K 1991 Through Measurement to Knowledge:
The Selected Papers of Heike Kamerlingh Onnes 1853‚Äì
1926 (Dordrecht: Springer Netherlands) p. 264
[9] Nagamatsu J, Nakagawa N, Muranaka T, Zenitani Y, and
Akimitsu J 2001 Nature 41063
[10] Kim B, Lee S, and Kim J 2020 Sci. Adv. 6eaax9324
[11] Vidmar D 2011 PDF document provided on the internet
by the Universidade Federal Rio Grande do Sul
[12] Anderson C D 1932 Science 76238
[13] Bardeen J, Cooper L N, and Schrieffer J R 1957 Phys.
Rev.1081175
[14] Bardeen J 1955 Phys. Rev. 971724
[15] Cooper L N 1956 Phys. Rev. 1041189
[16] Kresse G and Furthm¬® uller J 1996 Phys. Rev. B 5411169
[17] Perdew J P, Burke K, and Ernzerhof M 1996 Phys. Rev.
Lett.773865
[18] Bl¬® ochl P E 1994 Phys. Rev. B 5017953
[19] Novoselov K S, Geim A K, Morozov S V, Jiang D, Zhang
Y, Dubonos S V, Grigorieva I V, and Firsov A A 2004
Science 306666
[20] Pople J A, Binkley J S, and Seeger R 1976 Int. J. Quan-
tum Chem. 101
[21] Park H, Li Z, and Walsh A 2024 Matter 72355
[22] Vaswani A, Shazeer N, Parmar N et al. 2017 Proceedings
of the 31st International Conference on Neural Informa-
tion Processing Systems p. 6000
[23] Xie T, Fu X, Ganea O E, Barzilay R, and Jaakkola T
2022 Proceedings of the 10th International Conference
on Learning Representations
[24] Jiao R, Huang W, Lin P, Han J, Chen P, Lu Y, and Liu
Y 2023 Advances in Neural Information Processing Sys-
tems, December 10‚Äì16, New Orleans, USA, vol. 36, p.
17464
[25] Chen Y, Wang X, Deng X, Liu Y, Chen X, Zhang
Y, Wang L, and Xiao H 2024 arXiv:2408.07608 [cond-
mat.mtrl-sci]
[26] Choudhary K 2024 J. Phys. Chem. Lett. 156909
[27] Fernandez-Zelaia P, Thapliyal S, Kannan R, Nandwana
P, Yamamoto Y, Nycz A, Paquit V and Kirka M M 2024
Additive Manufacturing 94104478
[28] Lyu X and Ren X 2024 Sci. Rep. 145041
[29] Gao Z F, Qu S, Zeng B C, Liu Y, Wen J R, Sun H, Guo P
J, and Lu Z Y 2023 arXiv:2311.04418 [cond-mat.mtrl-sci]
[30] Ansari M, Watchorn J, Brown C E, and Brown J S 2024
dZiner: Rational Inverse Design of Materials with AI
Agents
[31] Merchant A, Batzner S, Schoenholz S S, Aykol M, Cheon
G, and Cubuk E D 2023 Nature 62480
[32] Barroso-Luque L, Shuaibi M, Fu X, Wood B M, Dzamba
M, Gao M, Rizvi A, Zitnick C L, and Ulissi Z W 2024
arXiv:2410.12771 [condmat.mtrl-sci]
[33] Chen Y, Lan Z, Su Z, and Zhu J 2022 Nanophotonics 11
4347
[34] Liu S and Yang C 2024 Metals 14235
[35] Han J, Cen J, Wu L, Li Z, Kong X, Jiao R, Yu Z, Xu T,
Wu F, Wang Z, Xu H, Wei Z, Liu Y, Rong Y, and Huang
W 2024 arXiv:2403.00485v1 [cs.LG]
[36] Reiser P, Neubert M, Eberhard A, Torresi L, Zhou C,
Shao C, Metni H, van Hoesel C, Schopmans H, Sommer
T, and Friederich P 2022 Commun. Mater. 393[37] Lvovsky Y, Stautner E W, and Zhang T 2013 Supercond.
Sci. Technol. 26093001
[38] Bruzzone P, Fietz W H, Minervini J V, Novikov M,
Yanagi N, Zhai Y, and Zheng J 2018 Nucl. Fusion 58
103001
[39] Mirhosseini M, Sipahigil A, Kalaee M, and Painter O
2020 Nature 588599
[40] Gambetta J M, Chow J M, and Steffen M 2017 NPJ
Quantum Inf. 32
[41] Degen C L, Reinhard F, and Cappellaro P 2017 Rev.
Mod. Phys. 89035002
[42] Onnes H K 1911 Commun. Theor. Phys. 120
[43] Meissner W and Ochsenfeld R 1933 Sci. Nat. 21787
[44] Gavaler J R 1973 Appl. Phys. Lett. 23480
[45] Bednorz J G and M¬® uller K A 1986 Z. Phys. B 64189
[46] Wu M K, Ashburn J R, Torng C J, Hor P H, Meng R L,
Gao L, Huang Z J, Wang Y Q, and Chu C W 1987 Phys.
Rev. Lett. 58908
[47] Ren Z A, Lu W, Yang J, Yi W, Shen X L, Che G C,
Dong X L, Sun L L, Zhou F, and Zhao Z X 2008 Chin.
Phys. Lett. 252215
[48] Ying J, Liu S, Lu Q, Wen X, Gui Z, Zhang Y, Wang X,
Sun J, and Chen X 2023 Phys. Rev. Lett. 130256002
[49] Sun H, Huo M, Hu X, Li J, Liu Z, Han Y, Tang L, Mao
Z, Yang P, Wang B, Cheng J, Yao D X, Zhang G M, and
Wang M 2023 Nature 621493
[50] Drozdov A P, Eremets M I, Troyan I A, Ksenofontov V,
and Shylin S I 2015 Nature 52573
[51] Stanev V, Oses C, Kusne A G, Rodriguez E, Paglione J,
Curtarolo S, and Takeuchi I 2018 NPJ Comput. Mater.
429
[52] Ward L, Agrawal A, Choudhary A, and Wolverton C 2016
NPJ Comput. Mater. 216028
[53] Li J, Fang W, Jin S, Zhang T, Wu Y, Xu X, Liu Y, and
Yao D X 2024 arXiv:2409.07721 [cond-mat.supr-con]
[54] Zhang T D, Suo C Y, Wu Y L, Xu X D, Liu Y, Yao D
X, and Li J 2024 arXiv:2409.09419 [cond-mat.supr-con]
[55] Scarselli F, Gori M, Tsoi A C, Hagenbuchner M, and
Monfardini G 2008 IEEE Trans. Neural Networks 2061
[56] Wu Z, Pan S, Chen F, Long G, Zhang C, and Philip S
Yu 2020 IEEE Trans. Neural Networks Learn. Syst. 32
4
[57] Kipf T N and Welling M 2016 5th International Con-
ference on Learning Representations , April 24‚Äì26, 2017,
Toulon, France
[58] Hamilton W, Ying Z, and Leskovec J 2017 Advances in
Neural Information Processing Systems , December 4‚Äì9,
Long Beach, USA
[59] VeliÀá ckovi¬¥ c P, Cucurull G, Casanova A, Romero A, Lio
P, and Bengio Y 2017 6th International Conference on
Learning Representations , May 6‚Äì9, 2018, Vancouver,
Canada
[60] Defferrard M, Bresson X, and Vandergheynst P 2016 Ad-
vances in Neural Information Processing Systems , De-
cember 5‚Äì10, Barcelona, Spain
[61] Choudhary K and Garrity K 2022 NPJ Comput. Mater.
8244
[62] Choudhary K and DeCost B 2021 NPJ Comput. Mater.
7185
[63] Wines D and Choudhary K 2024 Materials futures 3
025602
[64] Zhao J, Wang J, He D, Li J, Sun Y, Chen X Q, and Liu
P 2024 Acta Metall. Sin. 601418
[65] Li J, Wei L, Shi X, Shi L, Si J, Liu P F, and Wang B T
2024 Phys. Rev. B 109174516
[66] Cerqueira T F T, Fang Y W, Errea I, Sanna A, and Mar-
ques M A L 2024 Adv. Funct. Mater. 342404043
027403-34

Chinese Physics Letters 42, 027403 (2025) Review
[67] Sommer T, Willa R, Schmalian J, and Friederich P 2023
Sci. Data 10816
[68] Rombach R, Blattmann A, Lorenz D, Esser P, and Om-
mer B 2022 Proceedings of the IEEECVF Conference on
Computer Vision and Pattern Recognition p. 10674
[69] Ho J, Jain A, and Abbeel P 2020 Advances in Neural
Information Processing Systems p. 6840
[70] Song Y and Ermon S 2019 Advances in Neural Informa-
tion Processing Systems p. 11918
[71] Abramson J, Adler J, Dunger J, Evans R, Green T,
Pritzel A, Ronneberger O, Willmore L, Ballard A J, Bam-
brick J et al. 2024 Nature 630493
[72] Han X Q, Ouyang Z, Guo P J, Sun H, Gao Z F, and Lu
Z Y 2024 arXiv:2409.08065 [cond-mat.supr-con]
[73] Xie T and Grossman J C 2018 Phys. Rev. Lett. 120
145301
[74] Gao Z F, Qu S, Zeng B C, Liu Y, Wen J R, Sun H, Guo P
J, and Lu Z Y 2024 arXiv:2311.04418 [cond-mat.mtrl-sci]
[75] Chen C, Ye W, Zuo Y, Zheng C, and Ong S P 2019 Chem.
Mater. 313564
[76] Zhang C, Tang H, Pan C, Jiang H, Sun H J, Ho K M,
and Wang C Z 2023 Phys. Rev. B 108024512
[77] Zhang D, Liu X, Zhang X, Zhang C, Cai C, Bi H, Du
Y, Qin X, Peng A, Huang J et al. 2024 NPJ Comput.
Mater. 10293
[78] Wines D, Xie T, and Choudhary K 2023 J. Phys. Chem.
Lett.146630
[79] Okabe R, Chotrattanapituk A, Boonkird A, Andrejevic
N, Fu X, Jaakkola T S, Song Q, Nguyen T, Drucker N,
Mu S, Wang Y, Liao B, Cheng Y, and Li M 2024 Nat.
Comput. Sci. 4522
[80] Zhong Y, Liu S, Zhang B, Tao Z, Sun Y, Chu W, Gong
X G, Yang J H, and Xiang H 2024 Nat. Comput. Sci. 4
615
[81] Chmaissem O, Jorgensen J D, Short S, Knizhnik A, Eck-
stein Y, and Shaked H 1999 Nature 39745
[82] Lee C H, Kihou K, Iyo A, Kito H, Shirage P M, and
Eisaki H 2012 Solid State Commun. 152644
[83] Mizuguchi Y, Hara Y, Deguchi K, Tsuda S, Yamaguchi
T, Takeda K, Kotegawa H, Tou H, and Takano Y 2010
Supercond. Sci. Tech. 23054013
[84] Peng Y Y, Dellea G, Minola M, Conni M, Amorese A, Di
Castro D, De Luca G M, Kummer K, Salluzzo M, Sun X
et al. 2017 Nature Phys. 131201
[85] Gu L, Liu Y, Chen P, Huang H, Chen N, Li Y, Lookman
T, Lu Y, and Su Y 2024 Mater. Genome Eng. Adv. e48
[86] Pogue E A, New A, McElroy K, Le N Q, Pekala M J, Mc-
Cue I, Gienger E, Domenico J, Hedrick E, McQueen T
M, Wilfong B, Piatko C D, Ratto C R, Lennon A, Chung
C, Montalbano T, Bassen G, and Stiles C D 2023 NPJ
Comput. Mater. 9181
[87] Cullity B D and Graham C D 2011 Introduction to Mag-
netic Materials (Hoboken, NJ: John Wiley \& Sons)
[88] Goldman A 2012 Handbook of Modern Ferromagnetic
Materials (New York, NY: Springer Science \& Business
Media)
[89] Jungwirth T, Marti X, Wadley P and Wunderlich J 2016
Nat. Nanotech. 11231
[90] ÀáSmejkal L, Sinova J and Jungwirth T 2022 Phys. Rev. X
12040501
[91] ÀáSmejkal L, Sinova J and Jungwirth T 2022 Phys. Rev. X
12031042
[92] Mazin I 2022 Phys. Rev. X 12040002
[93] Hayami S, Yanagi Y, and Kusunose H 2019 J. Phys. Soc.
Japan 88123702
[94] ÀáSmejkal L, Gonz¬¥ alez-Hern¬¥ andez R, Jungwirth T, and
Sinova J 2020 Sci. Adv. 6eaaz8809[95] Yuan L D, Wang Z, Luo J W, Rashba E I, and Zunger
A 2020 Phys. Rev. B 102014422
[96] Mazin I I, Koepernik K, Johannes M D, Gonz¬¥ alez-
Hern¬¥ andez R, and ÀáSmejkal L 2021 Proc. Natl. Acad. Sci.
U.S.A. 118e2108924118
[97] Jungwirth T, Fernandes R M, Sinova J, and Smejkal L
2024 arXiv:2409.10034 [cond-mat.mtrl-sci]
[98] Bouhon A, Lange G F, and Slager R J 2021 Phys. Rev.
B103245127
[99] Hubert A and Schafer R 1998 Magnetic Domains: The
Analysis of Magnetic Microstructures (Berlin, Heidel-
berg: Springer) p. XXIII, 696
[100] ÀáSmejkal L, Hellenes A B, Gonz¬¥ alez-Hern¬¥ andez R, Sinova
J, and Jungwirth T 2022 Phys. Rev. X 12011028
[101] Zhu D, Zhuang Z Y, Wu Z, and Yan Z 2023 Phys. Rev.
B108184505
[102] Li Y X and Liu C C 2023 Phys. Rev. B 108205410
[103] Ma H Y, Hu M, Li N, Liu J, Yao W, Jia J F, and Liu J
2021 Nat. Commun. 122846
[104] Gonz¬¥ alez-Hern¬¥ andez R, ÀáSmejkal L, V¬¥ yborn¬¥ y K, Yahagi
Y, Sinova J, Jungwirth T, and ÀáZelezn¬¥ y J 2021 Phys. Rev.
Lett.126127701
[105] Bai H, Han L, Feng X Y, Zhou Y J, Su R X, Wang Q,
Liao L Y, Zhu W X, Chen X Z, Pan F, Fan X L, and
Song C 2022 Phys. Rev. Lett. 128197202
[106] Karube S, Tanaka T, Sugawara D, Kadoguchi N, Kohda
M, and Nitta J 2022 Phys. Rev. Lett. 129137201
[107] ÀáSmejkal L, MacDonald A H, Sinova J, Nakatsuji S, and
Jungwirth T 2022 Nat. Rev. Mater. 7482
[108] Feng Z, Zhou X, ÀáSmejkal L, Wu L, Zhu Z, Guo H,
Gonz¬¥ alez-Hern¬¥ andez R, Wang X, Yan H, Qin P, Zhang
X, Wu H, Chen H, Meng Z, Liu L, Xia Z, Sinova J, Jung-
wirth T, and Liu Z 2022 Nat. Electron. 5735
[109] Gonzalez Betancourt R D, Zub¬¥ aÀá c J, Gonzalez-Hern¬¥ andez
R, Geishendorf K, ÀáSob¬¥ aÀá n Z, Springholz G, Olejn¬¥ ƒ±k K,
ÀáSmejkal L, Sinova J, Jungwirth T, Goennenwein S T B,
Thomas A, Reichlov¬¥ a H, ÀáZelezn¬¥ y J and Kriegner D 2023
Phys. Rev. Lett. 130036702
[110] Hou X Y, Yang H C, Liu Z X, Guo P J, and Lu Z Y 2023
Phys. Rev. B 107L161109
[111] Zhou X, Feng W, Yang X, Guo G Y, and Yao Y 2021
Phys. Rev. B 104024401
[112] Zhou X, Feng W, Zhang R W, ÀáSmejkal L, Sinova J,
Mokrousov Y, and Yao Y 2024 Phys. Rev. Lett. 132
056701
[113] Guo P J, Liu Z X, and Lu Z Y 2023 NPJ Comput. Mater.
970
[114] Li Y X, Liu Y, and Liu C C 2024 Phys. Rev. B 109
L201109
[115] Guo P J, Gu Y H, Gao Z F, and Lu Z Y 2023
arXiv:2312.13911 [condmat.mtrl-sci]
[116] Qu S, Gao Z F, Sun H, Liu K, Guo P J, and Lu Z Y 2024
arXiv:2401.11065 [cond-mat.mtrl-sci]
[117] Tan C Y, Gao Z F, Yang H C, Liu K, Guo P J, and Lu
Z Y 2024 arXiv:2406.16603 [cond-mat.mtrl-sci]
[118] Itani S, Zhang Y, and Zang J 2024 arXiv:2409.15675
[cond-mat.mtrl-sci]
[119] Zhang Y, Itani S, Khanal K, Okyere E, Smith G, Taka-
hashi K, and Zang J 2024 J. Magn. Magn. Mater. 597
172001
[120] Jain A, Montoya J, Dwaraknath S, Zimmermann N E R,
Dagdelen J, Horton M, Huck P, Winston D, Cholia S,
Ong S P et al. 2020 Handbook of Materials : Methods:
Theory and Modeling (Berlin: Springer) p. 1751
[121] Rowe D M 2018 Thermoelectrics Handbook: Macro to
Nano (Boca Raton: CRC Press)
[122] Tan G, Zhao L D, and Kanatzidis M G 2016 Chem. Rev.
11612123
[123] Mamur H, Dilma¬∏ c ¬®O F, Begum J, and Bhuiyan M R A
2021 Cleaner Mater. 2100030
027403-35

Chinese Physics Letters 42, 027403 (2025) Review
[124] Vedernikov M V and Iordanishvili E K 1998 Seventeenth
International Conference on Thermoelectrics. Proceed-
ings ICT98 (IEEE) p. 37
[125] Zevalkink A, Smiadak D M, Blackburn J L, Ferguson A
J, Chabinyc M L, Delaire O, Wang J, Kovnir K, Martin
J, Schelhas L T et al. 2018 Appl. Phys. Rev. 5021303
[126] Gorai P, Stevanovi¬¥ c V, and Toberer E S 2017 Nature Rev.
Mater. 217053
[127] Chen D, Jiang F, Fang L, Zhu Y B, Ye C C, and Liu W
S 2022 Rare Metals 411543
[128] Jia X, Deng Y, Bao X, Yao H, Li S, Li Z, Chen C, Wang
X, Mao J, Cao F et al. 2022 NPJ Comput. Mater. 834
[129] Na G S, Jang S, and Chang H 2021 NPJ Comput. Mater.
7106
[130] Sasaki M, Ju S, Xu Y, Shiomi J, and Goto M 2020 ACS
Comb. Sci. 22782
[131] Li R, Li X, Xi L, Yang J, Singh D J, and Zhang W 2019
ACS Appl. Mater. Interfaces 1124859
[132] Gan Y, Wang G, Zhou J, and Sun Z 2021 NPJ Comput.
Mater. 7176
[133] Islamov M, Babaei H, Anderson R, Sezginel K B, Long
J R, McGaughey A J H, Gomez-Gualdron D A, and
Wilmer C E 2023 NPJ Comput. Mater. 911
[134] Luo H, Li X, Wang Y, Jin Y, Yao M, and Yang J 2022
NPJ Comput. Mater. 8199
[135] Choubisa H, Haque M A, Zhu T, Zeng L, Vafaie M, Baran
D, and Sargent E H 2023 Adv. Mater. 352302575
[136] Iijima S 1991 Nature 35456
[137] Geim A K and Novoselov K S 2007 Nat. Mater. 6183
[138] Mendoza-Cach¬¥ u D, L¬¥ opez-Miranda J L, Mercado-Z¬¥ uÀú niga
C, and Rosas G 2018 Diam Relat Mater 8426
[139] Javey A, Guo J, Wang Q, Lundstrom M, and Dai H 2003
Nature 424654
[140] Yu M F, Lourie O, Dyer M J, Moloni K, Kelly T F, and
Ruoff R S 2000 Science 287637
[141] An K H, Kim W S, Park Y S, Choi Y C, Lee S M, Chung
D C, Bae D J, Lim S C, and Lee Y H 2001 Adv. Mater.
13497
[142] Zhang D, Yi P, Lai X, Peng L, and Li H 2024 Nat. Com-
mun. 15344
[143] Hedman D, McLean B, Bichara C, Maruyama S, Larsson
J A, and Ding F 2024 Nat. Commun. 154076
[144] Li Y, Wang S, Lv Z, Wang Z, Zhao Y, Xie Y, Xu Y,
Qian L, Yang Y, Zhao Z et al. 2024 arXiv:2404.01006v1
[physics.app-ph]
[145] Liu B, Vu-Bac N, Zhuang X, Fu X and Rabczuk T 2022
Compos. Struct. 289115393
[146] Elaskalany M and Behdinan K 2024 Adv. Eng. Mater.
432401233
[147] Matos M A S, Pinho S T, and Tagarielli V L 2019 Scr.
Mater. 166117
[148] Safavigerdini K, Nouduri K, Surya R, Reinhard A, Quin-
lan Z, Bunyak F, Maschmann MR and Palaniappan K
2023 Predicting mechanical properties of carbon nan-
otube (cnt) images using multi-layer synthetic finite ele-
ment model simulations IEEE International Conference
on Image Processing (ICIP) p. 3264
[149] Papadopoulos V, Soimiris G, Giovanis D G, and Pa-
padrakakis M 2018 Comput. Methods. Appl. Mech. Eng.
328411
[150] Fernandez M, Shi H, and Barnard A S 2016 Carbon 103
142
[151] Alred J M, Bets K V, Xie Y, and Yakobson B I 2018
Compos. Sci. Technol. 1663
[152] Singh A V, Rosenkranz D, Ansari M H D, Singh R,
Kanase A, Singh S P, Johnston B, Tentschert J, Laux
P, and Luch A 2020 Adv. Intell. Syst. 22000084[153] Novoselov K S, Mishchenko A, Carvalho A, and Castro
Neto A H 2016 Science 353aac9439
[154] Slager R J, Mesaros A, JuriÀá ci¬¥ c V, and Zaanen J 2013 Nat.
Phys. 998
[155] Kruthoff J, de Boer J, van Wezel J, Kane C L, and Slager
R J 2017 Phys. Rev. X 7041069
[156] Po H C, Vishwanath A, and Watanabe H 2017 Nat. Com-
mun. 850
[157] Bradlyn B, Elcoro L, Cano J, Vergniory M G, Wang Z,
Felser C, Aroyo M I, and Bernevig B A 2017 Nature 547
298
[158] Vergniory M G, Elcoro L, Felser C, Regnault N, Bernevig
B A, and Wang Z 2019 Nature 566480
[159] Zhang T, Jiang Y, Song Z, Huang H, He Y, Fang Z, Weng
H, and Fang C 2019 Nature 566475
[160] Chen W, George J, Varley J B, Rignanese G M, and
Hautier G 2019 NPJ Comput. Mater. 572
[161] Horton M K, Montoya J H, Liu M, and Persson K A 2019
NPJ Comput. Mater. 564
[162] Geim A K 2009 Science 3241530
[163] Manzeli S, Ovchinnikov D, Pasquier D, Yazyev O V, and
Kis A 2017 Nat. Rev. Mater. 217033
[164] Pei S, Wang Z, and Xia J 2022 ACS Nano 1611498
[165] Das S K, Yan B, van den Brink J, and Fulga I C 2019
Phys. Rev. B 99165418
[166] Yi M and Shen Z 2015 Mater. Chem. A 311700
[167] Zhang Y, Zhang L, and Zhou C 2013 Acc. Chem. Res.
462329
[168] Lu M, Ji H, Zhao Y, Chen Y, Tao J, Ou Y, Wang Y,
Huang Y, Wang J, and Hao G 2022 ACS Appl. Mater.
Interfaces 151871
[169] Ryu B, Wang L, Pu H, Chan M, and Chen J 2022 Chem.
Soc. Rev. 511899
[170] Hasan M Z and Kane C L 2010 Rev. Mod. Phys 823045
[171] Ando Y 2013 J. Phys. Soc. Jpn. 82102001
[172] Schleder G R, Focassio B, and Fazzio A 2021 Appl. Phys.
Rev.8031409
[173] Choudhary K, Kalish I, Beams R, and Tavazza F 2017
Sci. Rep. 75179
[174] Mounet N, Gibertini M, Schwaller P, Campi D, Merkys
A, Marrazzo A, Sohier T, Castelli I E, Cepellotti A, Pizzi
Get al. 2018 Nat. Nanotechnol. 13246
[175] Choudhary K, Garrity K F, Hartman S T, Pilania G, and
Tavazza F 2004 Phys. Rev. Mater. 1014009
[176] Harris S B, Biswas A, Yun S J, Roccapriore K M, Rouleau
C M, Puretzky A A, Vasudevan R K, Geohegan D B, and
Xiao K 2024 Small Methods 82301763
[177] Wang Z, Cai J, Wang Q, Wu S, and Li J 2021 NPJ Com-
put. Mater. 7128
[178] Frey N C, Wang J, Vega Bellido G I, Anasori B, Gogotsi
Y, and Shenoy V B 2019 ACS nano 133031
[179] Li Z, Yao F, and Sun H 2024 IISE Trans. 56811
[180] Rajak P, Krishnamoorthy A, Kalia R, Nakano A, and
Vashishta P 2020 Quantum material synthesis by rein-
forcement learning p. 170
[181] Xu M, Tang B, Lu Y, Zhu C, Lu Q, Zhu C, Zheng L,
Zhang J, Han N, Fang W et al. 2021 J. Am. Chem. Soc.
14318103
[182] Tang B, Lu Y, Zhou J, Chouhan T, Wang H, Golani P,
Xu M, Xu Q, Guan C, and Liu Z 2020 Mater. Today 41
72
[183] Haastrup S, Strange M, Pandey M, Deilmann T, Schmidt
P, Hinsche N, Gjerding M, Torelli D, Larsen P, Riis-
Jensen A et al. 2018 2D Mater. 5042002
[184] Gjerding M N, Taghizadeh A, Rasmussen A, Ali S,
Bertoldo F, Deilmann T, Kn√∏sgaard N R, Kruse M,
Larsen A H, Manti S et al. 2021 2D Mater. 8044002
027403-36

Chinese Physics Letters 42, 027403 (2025) Review
[185] Zhou J, Shen L, Costa M, Persson K, Ong S, Huck P, Lu
Y, Ma X, Chen Y, Tang H et al. 2019 Sci. data 686
[186] Talirz L, Kumbhar S, Passaro E, Yakutovich A, Granata
V, Gargiulo F, Borelli M, Uhrin M, Huber S, Zoupanos
Set al. 2020 Sci. Data 7299
[187] Campi D, Mounet N, Gibertini M, Pizzi G, and Marzari
N 2023 ACS nano 1711268
[188] Marchenko E I, Fateev S A, Petrov A A, Korolev V V,
Mitrofanov A, Petrov A V, Goodilin E A, and Tarasov
A B 2020 Chem. Mater. 327383
[189] Frey N C, Akinwande D, Jariwala D, and Shenoy V B
2020 ACS nano 1413406
[190] Xu P, Ji X, Li M, and Lu W 2023 NPJ Comput. Mater.
942
[191] Brito A C M, Oliveira M C F, Oliveira O N, Silva F N,
and Amancio D R 2023 ACS Appl. Mater. Interfaces 15
27437
[192] Green M A, Dunlop E D, Yoshita M, Kopidakis N, Bothe
K, Siefer G, Hinken D, Rauer M, Hohl-Ebinger J, and
Hao X 2024 Prog. Photovolt. 32425
[193] Polman A, Knight M, Garnett E C, Ehrler B, and Sinke
W C 2016 Science 352aad4424
[194] Nelson J 2003 The physics of solar cells (London: Impe-
rial College Press)
[195] Wang R, Yu H, Zhong Y, and Xiang H 2024 J. Phys.
Chem. C 12812677
[196] Zhong Y, Yu H, Su M, Gong X, and Xiang H 2023 NPJ
Comput. Mater. 9182
[197] Philipps S and Warmuth W 2019 ISE with Support of
PSE GmbH November 14th; Fraunhofer ISE: Freiburg,
Germany
[198] Streetman B, Banerjee S et al. 2000 Solid State Electronic
Devices (New Jersey: Prentice hall)
[199] Nakamura S and Fasol G 2013 The blue laser diode: GaN
based light emitters and lasers (New York: Springer Sci-
ence \& Business Media)
[200] Levinshtein M E, Rumyantsev S L and Shur M S 2001
Properties of Advanced Semiconductor Materials: GaN,
AIN, InN, BN, SiC, SiGe (New Jersey: John Wiley \&
Sons)
[201] Li J, Aierken A, Liu Y, Zhuang Y, Yang X, Mo J H, Fan
R K, Chen Q Y, Zhang S Y, Huang Y M, and Zhang Q
2021 Front. Phys. 8631925
[202] Dimroth F and Kurtz S 2007 MRS Bull. 32230
[203] Kojima A, Teshima K, Shirai Y, and Miyasaka T 2009 J.
Am. Chem. Soc. 1316050
[204] Snaith H J 2013 J. Phys. Chem. Lett. 43623
[205] Tilley R J D 2016 Perovskites: structure-property rela-
tionships (New Jersey: John Wiley \& Sons)
[206] Tao Q, Xu P, Li M, and Lu W 2021 NPJ Comput. Mater.
723
[207] Roy P, Ghosh A, Barclay F, Khare A, and Cuce E 2022
Coatings 121089
[208] Liu Y, Tan X, Xiang P, Tu Y, Shao T, Zang Y, Li X, and
Yan W 2024 Mater. Today Phys. 42101359
[209] Mohanty D and Palai A K 2023 Adv. Theory Simul. 6
2300309
[210] Akbar B, Tayara H, and Chong K T 2024 iScience 27
109200
[211] Karimitari N, Baldwin W J, Muller E W, Bare Z J L,
Kennedy W J, Cs¬¥ anyi G, and Sutton C 2024 J. Am.
Chem. Soc. 14627392
[212] Ran J, Wang B, Wu Y, Liu D, Mora Perez C, Vasenko A
S, and Prezhdo O V 2023 J. Phys. Chem. Lett. 146028
[213] Bi H, Wang M, Liu L, Yan J, Zeng R, Xu Z, and Wang
J 2024 J. Mater. Chem. A 1212744
[214] Wu Y, Wang C F, Ju M G, Jia Q, Zhou Q, Lu S, Gao X,
Zhang Y, and Wang J 2024 Nat. Commun. 15138[215] Mai H, Wen X, Li X, Dissanayake N S L, Sun X, Lu Y, Le
T C, Russo S P, Chen D, and Winkler D A 2024 Mater.
Today 7412
[216] Li X, Mai H, Lu J, Wen X, Le T C, Russo S P, Winkler
D A, Chen D, and Caruso R A 2023 Angew. Chem. Int.
Ed.62e202315002
[217] Choubisa H, Todorovi¬¥ c P, Pina J M, Parmar D H, Li
Z L, Voznyy O, Tamblyn I, and Sargent E H 2023 NPJ
Comput. Mater. 9117
[218] Selvaratnam B, Oliynyk A O, and Mar A 2023 Inorg.
Chem. 6210865
[219] Solak E K and Irmak E 2023 RSC Adv. 1312244
[220] Brabec C J, Gowrisanker S, Halls J J M, Laird D, Jia S,
and Williams S P 2010 Adv. Mater. 223839
[221] Sariciftci N S, Smilowitz L, Heeger A J, and Wudl F 1992
Science 2581474
[222] Li G, Zhu R, and Yang Y 2012 Nat. Photonics. 6153
[223] Yuan J, Zhang Y Q, Zhou L Y et al. 2019 Joule 31140
[224] Solak E K and Irmak E 2023 RSC Adv. 1312244
[225] Zhang Q, Zheng Y J, Sun W, Ou Z, Odunmbaku O, Li
M, Chen S, Zhou Y, Li J, Qin B, and Sun K 2022 Adv.
Sci.92104742
[226] Morishita Y, Yarimizu M, Kaneko M, and Muraoka A
2024 Chem. Phys. Lett. 857141719
[227] Liu X, Shao Y, Lu T, Chang D, Li M, and Lu W 2022
Mater. Des. 216110561
[228] Suthar R, Abhijith T, Sharma P, and Karak S 2023 Sol
Energy 250119
[229] Li M, Zhang C R, Zhang M L, Gong J J, Liu X M, Chen
Y H, Liu Z J, Wu Y Z, and Chen H S 2024 Phys. Status.
Solidi. A 2212400008
[230] Shetty P, Adeboye A, Gupta S, Zhang C, and Ramprasad
R 2024 Chem. Mater. 367676
[231] Suthar R, T A, Karak S 2023 J. Mater. Chem. A 11
22248
[232] Miyake Y, Kranthiraja K, Ishiwari F, and Saeki A 2022
Chem. Mater. 346912
[233] Wang H, Feng J, Dong Z, Jin L, Li M, Yuan J, and Li Y
2023 NPJ Comput. Mater. 9200
[234] Mou L H, Han T T, Smith P E S, Sharman E, and Jiang
J 2023 Adv. Sci. 102301020
[235] Guo Y, He X, Su Y, Dai Y, Xie M, Yang S, Chen J, Wang
K, Zhou D, and Wang C 2021 J. Am. Chem. Soc. 143
5755
[236] Ishioka S, Fujiwara A, Nakanowatari S, Takahashi L,
Taniike T, and Takahashi K 2022 ACS Catal 1211541
[237] Andersen M, Levchenko S V, Scheffler M, and Reuter K
2019 ACS Catal. 92752
[238] Ouyang R, Curtarolo S, Ahmetcik E, Scheffler M, and
Ghiringhelli L M 2018 Phys. Rev. Mater. 2083802
[239] Bartel C J, Sutton C, Goldsmith B R, Ouyang R, Mus-
grave C B, Ghiringhelli L M, and Scheffler M 2019 Sci.
Adv.5eaav0693
[240] Xu W, Andersen M, and Reuter K 2020 ACS Catal. 11
734
[241] Mou T, Pillai H S, Wang S, Wan M, Han X, Schweitzer
N M, Che F, and Xin H 2023 Nat. Catal. 6122
[242] Ren C, Lu S, Wu Y, Ouyang Y, Zhang Y, Li Q, Ling C,
and Wang J 2022 J. Am. Chem. Soc. 14412874
[243] Li Z, Wang S, Chin W S, Achenie L E, and Xin H 2017
J. Mater. Chem. A. 524131
[244] Li Z, Achenie L E K, and Xin H 2020 ACS Catal. 10
4377
[245] Lu Z, Chen Z W, and Singh C V 2020 Matter 31318
[246] Wang X, Ye S, Hu W, Sharman E, Liu R, Liu Y, Luo Y,
and Jiang J 2020 J. Am. Chem. Soc. 1427737
[247] Zhong W, Qiu Y, Shen H, Wang X, Yuan J, Jia C, Bi S,
and Jiang J 2021 J. Am. Chem. Soc. 1434405
[248] Gu Y, Zhu Q, Liu Z, Fu C, Wu J, Zhu Q, Jia Q, and Ma
J 2022 J. Mater. Chem. A 1014976
027403-37

Chinese Physics Letters 42, 027403 (2025) Review
[249] Williams T, McCullough K, and Lauterbach J A 2019
Chem. Mater. 32157
[250] Karim M R, Ferrandon M, Medina S, Sture E, Kariuki
N, Myers D J, Holby E F, Zelenay P, and Ahmed T 2020
ACS Appl. Energy Mater. 39083
[251] Artrith N, Lin Z, and Chen J G 2020 ACS Catal. 109438
[252] Zhu Q, Zhang F, Huang Y, Xiao H, Zhao L Y, Zhang X
C, Song T, Tang X S, Li X, He G et al. 2022 Natl. Sci.
Rev.9nwac190
[253] Zhong M, Tran K, Min Y, Wang C, Wang Z, Dinh C T,
De Luna P, Yu Z, Rasouli A S, Brodersen P et al. 2020
Nature 581178
[254] Han Z K, Sarker D, Ouyang R, Mazheika A, Gao Y, and
Levchenko S V 2021 Nat. Commun. 121833
[255] Yin P, Niu X, Li S B, Chen K, Zhang X, Zuo M, Zhang
L, and Liang H W 2024 Nat. Commun. 15415
[256] Chen L, Tian Y, Hu X, Yao S, Lu Z, Chen S, Zhang X,
and Zhou Z 2022 Adv. Funct. Mater. 322208418
[257] Mok D H and Back S 2024 J. Am. Chem. Soc. 14633712
[258] Yeh J W, Chen S K, Lin S J, Gan J Y, Chin T S, Shun
T T, Tsau C H, and Chang S Y 2004 Adv. Eng. Mater.
6299
[259] Cantor B, Chang I T H, Knight P, and Vincent A J B
2004 Mater. Sci. Eng. A 375213
[260] George E P, Raabe D, and Ritchie R O 2019 Nat. Rev.
Mater. 4515
[261] Otto F, Yang Y, Bei H, and George E P 2013 Acta Mater.
612628
[262] Rao Z, Tung P Y, Xie R, Wei Y, Zhang H, Ferrari A,
Klaver TPC, K¬® ormann F, Sukumar P T, Kwiatkowski
da Silva A et al. 2022 Science 378
[263] Wang J, Kwon H, Kim H S, and Lee B J 2023 NPJ Com-
put. Mater 960
[264] Chau N H, Kubo M, Hai L V, and Yamamoto T 2023
Vietnam J. Comput. Sci. 10101
[265] Huang W, Martin P, and Zhuang H L 2019 Acta Mater.
169225
[266] Krishna Y V, Jaiswal U K, and Rahul M 2021 Scr. Mater.
197113804
[267] Li H C, Yuan R H, Liang H, Wang W Y, Li J S, and
Wang J 2022 Mater. Des. 223111186
[268] Zhu W, Huo W, Wang S, Wang X, Ren K, Tan S, Fang
F, Xie Z, and Jiang J 2022 J. Mater. Res. Technol. 18
800
[269] Wang X M, Tran N D, Zeng S M, Hou C, Chen Y, and
Ni J 2022 NPJ Comput. Mater. 8253
[270] Pei Z R, Rozman K A, DoÀò gan ¬®O N, Wen Y H, Gao N,
Holm E A, Hawk J A, Alman D E, and Gao M C 2021
Adv. Sci. 82101207
[271] Slater A G and Cooper A I 2015 Science 348aaa8075
[272] Thomas A 2020 Nat. Commun. 114985
[273] Park J, Gill A P S, Moosavi S M, and Kim J 2024 J.
Mater. Chem. A 126507
[274] Yao Z, S¬¥ anchez-Lengeling B, Bobbitt N S, Bucior B J,
Kumar S G H, Collins S P, Burns T, Woo T K, Farha O
K, Snurr R Q et al. 2021 Nature Mach. Intell. 376
[275] Park H, Yan X, Zhu R, Huerta E A, Chaudhuri S, Cooper
D, Foster I, and Tajkhorshid E 2024 Commun. Chem. 7
21
[276] Igashov I, St¬® ark H, Vignac C, Schneuing A, Satorras V
G, Frossard P, Welling M, Bronstein M, and Correia B
2024 Nat. Mach. Intell. 6417
[277] Fu X, Xie T, Rosen A S, Jaakkola T S, and Smith J A
2024 12th International Conference on Learning Repre-
sentations , May 7‚Äì11, 2024, Vienna, Austria
[278] Park J, Lee Y and Kim J 2024 ChemRxiv
[279] Wang T, Pan R, Martins M L, Cui J, Huang Z, Thapaliya
B, Do-Thanh C, Zhou M, Fan J, Yang Z et al. 2023 Nat.
Commun. 144607[280] Kumar S, Ignacz G, and Szekely G 2021 Green Chem.
238932
[281] Delpisheh M, Ebrahimpour B, Fattahi A, Siavashi M, Mir
H, Mashhadimoslem H, Abdol M A, Ghorbani M, Shokri
J, Niblett D, Khosravi K, Rahimi S, Alirahmi S M, Yu
H, Elkamel A, Niasar V, and Mamlouk M 2024 J. Mater.
Chem. A 1220717
[282] D‚ÄôElia M, Deng H, Fraces C, Garikipati K, Graham-
Brady L, Howard A, Karniadakis G, Keshavarzzadeh
V, Kirby R M, Kutz N, Li C, Liu X, Lu H, Newell P,
O‚ÄôMalley D, Prodanovic M, Srinivasan G, Tartakovsky
A, Tartakovsky D M, Tchelepi H, Vazic B, Viswanathan
H, Yoon H, and Zarzycki P 2022 arXiv:2202.04137
[cs.LG]
[283] Breiman L 2001 Mach. Learn. 45
[284] Quinlan J R 1986 Mach. Learn. 181
[285] Cortes C and Vapnik V 1995 Mach. Learn. 20273
[286] Rumelhart D E, Hinton G E, and Williams R J 1986
Nature 323533
[287] Goodfellow I, Bengio Y, and Courville A 2016 Deep
Learning Cambridge, Massachusetts : The MIT Press
[288] Deng B, Zareei A, Ding X, Weaver J C, Rycroft C H, and
Bertoldi K 2022 Adv. Mater. 342206238
[289] Geng X, Cheng Z, Wang S, Peng C, Ullah A, Wang H,
and Wu G 2022 J. Mater. Sci. 5710755
[290] Ijaz S, Noureen S, Rehman B, Aldaghri O, Cabrera H, Ib-
naouf K H, Madkhali N, and Mehmood M Q 2023 Mater.
Today Commun. 37106951
[291] McDonald S M, Augustine E K, Lanners Q, Rudin C,
Brinson C L, and Becker M L 2023 Nat. Commun. 14
4838
[292] Lei X, Liu C, Du Z, Zhang W, and Guo X 2019 J. Appl.
Mech. 86011004
[293] LeCun Y, Bengio Y, and Hinton G 2015 Nature 521436
[294] He K, Zhang X, Ren S, and Sun J 2016 Proceedings of the
IEEE conference on computer vision and pattern recog-
nition p. 770
[295] Abueidda D W, Koric S, and Sobh N A 2020 Comput.
Struct. 237106283
[296] Wei X, van der Zwaag S, Jia Z, Wang C, and Xu W 2022
Acta Mater. 235118103
[297] Gu G X, Chen C T, and Buehler M J 2018 Extreme Mech.
Lett.1819
[298] Gilmer J, Schoenholz S S, Riley P F, Vinyals O, and Dahl
G E 2017 Proceedings of the 34th International Confer-
ence on Machine Learning p. 1263
[299] Sch¬® utt K T, Sauceda H E, Kindermans P J, Tkatchenko
A, and M¬® uller K R 2018 J. Chem. Phys. 148241722
[300] Sch¬® utt K T, Arbabzadah F, Chmiela S, M¬® uller K R, and
Tkatchenko A 2017 Nat. Commun. 813890
[301] Hu W, Shuaibi M, Das A, Goyal S, Sriram A, Leskovec J,
Parikh D, and Zitnick C L 2021 arXiv:2103.01436 [cs.LG]
[302] Xie T and Grossman J C 2018 Phys. Rev. Lett. 120
145301
[303] Unke O T and Meuwly M 2019 J. Chem. Theory Com-
put.153678
[304] Gasteiger J, Gro√ü J, and G¬® unnemann S 2020
arXiv:2003.03123 [cs.LG]
[305] Liu Y, Wang L, Liu M, Lin Y, Zhang X, Oztekin B, and
Ji S 2022 Spherical Message Passing for 3D Molecular
Graphs International Conference on Learning Represen-
tations
[306] Yue A, Luo D, and Xu H 2024 Proc. AAAI Conf. Artif.
Intell. 3816633
[307] Gasteiger J, Becker F, and G¬® unnemann S 2024
arXiv:2106.08903v1 [physics.comp-ph]
027403-38

Chinese Physics Letters 42, 027403 (2025) Review
[308] Wang L, Liu Y, Lin Y, Liu H, and Ji S 2022 ComENet:
Towards Complete and Efficient Message Passing for 3D
Molecular Graphs Advances in Neural Information Pro-
cessing Systems , 2022, New Orleans, Louisiana, USA, p.
650
[309] Garcia Satorras V, Hoogeboom E, and Welling M E 2021
Proceedings of the 38th International Conference on Ma-
chine Learning 1399323
[310] Sch¬® utt K, Kindermans P, Sauceda FEH, Chmiela S,
Tkatchenko A, and M¬® uller K R 2017 SchNet: A
continuous-filter convolutional neural network for mod-
eling quantum interactions p. 992
[311] K¬® ohler J, Klein L, and No¬¥ e F 2019 arXiv:1910.00753v1
[stat.ML]
[312] Huang W, Han J, Rong Y, Xu T, Sun F, and Huang J
2022 International Conference on Learning Representa-
tions
[313] Du W, Zhang H, Du Y, Meng Q, Chen W, Zheng N,
Shao B, and Liu T Y 2022 Proceedings of the 39th Inter-
national Conference on Machine Learning 1625583
[314] Kofinas M, Nagaraja N S, and Gavves E 2022 Advances
in Neural Information Processing Systems 346417
[315] Kofinas M, Bekkers E J, Nagaraja N S, and Gavves E
2023 Advances in Neural Information Processing Sys-
tems3631780
[316] Jing B, Eismann S, Suriana P, Townshend R J L, and
Dror R 2021 ICLR
[317] Du Y, Wang L, Feng D, Wang G, Ji S, Gomes C P, and
Ma Z M 2024 Advances in Neural Information Processing
Systems 36
[318] Puny O, Atzmon M, Smith E J, Misra I, Grover A, Ben-
Hamu H, and Lipman Y 2021 International Conference
on Learning Representations
[319] Han J, Huang W, Xu T, and Rong Y 2022 NeurIPS
[320] Thomas N, Smidt T, Kearnes S, Yang L, Li L, Kohlhoff
K, and Riley P 2018 arXiv:1802.08219 [cs.LG]
[321] Geiger M and Smidt T 2022 arXiv:2207.09453 [cs.LG]
[322] Brandstetter J, Hesselink R, van der Pol E, Bekkers E J,
and Welling M 2022 arXiv:2110.02905 [cs.LG]
[323] Batzner S, Musaelian A, Sun L, Geiger M, Mailoa J P,
Kornbluth M, Molinari N, Smidt T E, and Kozinsky B
2022 Nat. Commun. 132453
[324] Wang R, Yu H, Zhong Y, and Xiang H 2024 JMI432
[325] Gasteiger J, Gro√üJ, and G¬® unnemann S 2022
arXiv:2003.03123 [cs.LG]
[326] Zitnick C L, Das A, Kolluru A, Lan J, Shuaibi M, Sri-
ram A, Ulissi Z, and Wood B 2022 arXiv:2206.14331
[physics.chem-ph]
[327] Passaro S and Zitnick C L 2023 arXiv:2302.03655 [cs.LG]
[328] Batatia I, Kov¬¥ acs D P, Simm G N C, Ortner C, and
Cs¬¥ anyi G 2023 arXiv:2206.07697 [stat.ML]
[329] Sch¬® utt K T, Unke O T, and Gastegger M 2021
arXiv:2102.03150 [cs.LG]
[330] Musaelian A, Batzner S, Johansson A, Sun L, Owen C J,
Kornbluth M, and Kozinsky B 2023 Nat. Commun. 14
579
[331] Liao Y and Smidt T 2023 arXiv:2206.11990 [cs.LG]
[332] Liao Y L, Wood B, Das A, and Smidt T 2024
arXiv:2306.12059 [cs.LG]
[333] Ying C, Cai T, Luo S, Zheng S, Ke G, He D, Shen Y,
and Liu T 2021 arXiv:2106.05234 [cs.LG]
[334] Fuchs F, Worrall D, Fischer V, and Welling M 2020 Adv.
Neural Inf. Process. Syst. 331970
[335] Th¬® olke P and De Fabritiis G 2022 arXiv:2202.02541
[cs.LG]
[336] Hutchinson M, Lan C, Zaidi S, Dupont E, Teh Y, and
Kim H 2021 Proc. 38th Int. Conf. Mach. Learn. 139
4533[337] Ramakrishnan R, Dral P O, Rupp M and Von Lilienfeld
O A 2014 Sci. Data 11
[338] Choudhary K and DeCost B 2021 NPJ Comput. Mater.
7185
[339] Karamad M, Magar R, Shi Y, Siahrostami S, Gates I D,
and Barati Farimani A 2020 Phys. Rev. Mater. 4093801
[340] Lam P T, Kino H, Terakura K, Miyake T, Tsuda K, Taki-
gawa I, and Chi D H 2017 Sci. Technol. Adv. Mater. 18
756
[341] Kaba O and Ravanbakhsh S 2022 Advances in Neural
Information Processing Systems 354150
[342] Yan K, Liu Y, Lin Y and Ji S 2022 Advances in Neural
Information Processing Systems 3515066
[343] Magar R, Wang Y, and Barati Farimani A 2022 NPJ
Comput. Mater 8231
[344] Zbontar J, Jing L, Misra I, LeCun Y, and Deny S 2021
Proceedings of the 38th International Conference on Ma-
chine Learning 13912310
[345] Chen T, Kornblith S, Norouzi M, and Hinton G A 2020
Proceedings of the 37th International Conference on Ma-
chine Learning 1191597
[346] Yu H, Song Y, Hu J, Guo C, and Yang B 2023
arXiv:2306.05344v2 [cs.LG]
[347] Devlin J, Chang MW, Lee K, and Toutanova K 2018
arXiv:1810.04805v2 [cs.CL]
[348] Kirklin S, Saal J E, Meredig B, Thompson A, Doak J W,
Aykol M, R¬® uhl S, and Wolverton C 2015 NPJ Comput.
Mater. 115010
[349] Gasteiger J, Giri S, Margraf J T, and G¬® unnemann S 2020
arXiv:2011.14115v3 [cs.LG]
[350] Rombach R, Blattmann A, Lorenz D, Esser P, and Om-
mer B 2022 IEEE/CVF Conference on Computer Vision
and Pattern Recognition (CVPR) p. 10684
[351] Ho J, Jain A, and Abbeel P 2020 Denoising diffusion
probabilistic models, Advances in Neural Information
Processing System 336840
[352] Song Y, Sohl-Dickstein J, Kingma D P, Kumar A, Er-
mon S, and Poole B 2021 International Conference on
Learning Representations
[353] Abramson J, Adler J, Dunger J, and Evans R 2024 Na-
ture630493
[354] Corso G, St¬® ark H, Jing B, Barzilay R, and Jaakkola T S

\section{The Eleventh International Conference on Learning
Representations}

[355] Jing B, Corso G, Chang J, Barzilay R, and Jaakkola T
S 2022 Advances in Neural Information Processing Sys-
tems 35: Annual Conference on Neural Information Pro-
cessing Systems p. 24240
[356] Nouira A, Sokolovska N, and Crivello J C 2019
arXiv:1810.11203v3 [cs.LG]
[357] Miller B K, Chen R T Q, Sriram A, and Wood B M 2024
arXiv:2406.04713 [cs.LG]
[358] Jiao R, Huang W, Liu Y, Zhao D, and Liu Y 2024
arXiv:2402.03992v2 [cs.LG]
[359] Ye C Y, Weng H M, and Wu Q S 2024 Comput. Mater.
Today 1100003
[360] Ramesh A, Dhariwal P, Nichol A, Chu C, and Chen M
2022 arXiv:2204.06125 [cs.CV]
[361] Luo X, Wang Z, Gao P, Lv J, Wang Y, Chen C, and Ma
Y 2024 NPJ Comput. Mater. 10254
[362] Zeni C, Pinsler R, Z¬® ugner D, Fowler A, Horton M, Fu
X, Wang Z, Shysheya A, Crabb¬¥ e J, Ueda S, Sordillo R,
Sun L, Smith J, Nguyen B, Schulz H, Lewis S, Huang C
W, Lu Z, Zhou Y, Yang H, Hao H, Li J, Yang C, Li W,
Tomioka R, and Xie T 2025 Nature
[363] Joshi C, Bodnar C, Mathis S, Cohen T, and Lio P 2023
Proceedings of the 40th International Conference on Ma-
chine Learning 20215330
[364] Hall B C 2013 Quantum Theory for Mathematicians
(Springer)
027403-39

Chinese Physics Letters 42, 027403 (2025) Review
[365] Cao Z, Luo X, Lv J, and Wang L 2024 arXiv:2403.15734
[condmat.mtrl-sci]
[366] Brooks S 1998 J. R. Stat. Soc. Ser. D 4769
[367] Reynolds D 2009 Encycl. Biometrics 741659
[368] Sriram A, Miller B K, Chen R T Q, and Wood B M 2024
arXiv:2410.23405 [cs.LG]
[369] Brown T B, Mann B, Ryder N et al. 2020 Advances in
Neural Information Processing Systems 331877
[370] Boiko D A, MacKnight R, Kline B, and Gomes G 2023
Nature 624570
[371] Beltagy I, Lo K and Cohan A 2019 Proceedings of
the 2019 Conference on Empirical Methods in Natu-
ral Language Processing and the 9th International Joint
Conference on Natural Language Processing (EMNLP-
IJCNLP) p. 3615
[372] Gupta T, Zaki M, Krishnan N M et al. 2021 NPJ Com-
put. Mater. 8102
[373] V¬® olker C, Rug T, Jablonka K and Kruschwitz S 2024
LLMs can Design Sustainable Concrete -a Systematic
Benchmark (re-submitted version)
[374] Zhao S, Chen S, Zhou J, Li C, Tang T, Harris S J, Liu
Y, Wan J, and Li X 2024 Cell Rep. Phys. Sci. 5101844
[375] Satpute P, Tiwari S, Gupta M, and Ghosh S 2024 Mater.
Today Commun. 40109583
[376] Lei G, Docherty R, and Cooper S J 2024 Digital Discov-
ery31257
[377] Gupta T, Zaki M, Krishnan N M A, and Mausam 2022
NPJ Comput. Mater. 8102
[378] Blum L C and Reymond J L 2009 J. Am. Chem. Soc.
1318732
[379] Chmiela S, Tkatchenko A, Sauceda H E, Poltavsky I,
Sch¬® utt K T, and M¬® uller K R 2017 Science Adv. 3
e1603015
[380] Chmiela S, Sauceda H E, M¬® uller K R, and Tkatchenko
A 2018 Nat. Commun. 93887
[381] Jain A, Ong S P, Hautier G, Chen W, Richards WD,
Dacek S, Cholia S, Gunter D, Skinner D, Ceder G et al.
2013 APL. Mater. 1011002
[382] Chanussot L, Das A, Goyal S, Lavril T, Shuaibi M, Riv-
iere M, Tran K, Heras-Domingo J, Ho C, Hu W et al.
2021 ACS Catal. 116059
[383] Choudhary K, Garrity K F, Reid A C E, DeCost B, Bi-
acchi A J, Hight Walker A R, Trautt Z, Hattrick-Simpers
J, Kusne A G, and Centrone A et al. 2020 NPJ Comput.
Mater. 6173
[384] Nakata M and Maeda T 2023 J Chem. Inf. Model. 63
5734
[385] Ullah A, Chen Y, and Dral P O 2024 Mach. Learn.: Sci.
Technol. 5041001
[386] Jia S, Zhang C, and Fung V 2024 arXiv:2406.13163 [cond-
mat.mtrl-sci][387] Zhang H, Song Y, Hou Z, Miret S, and Liu B 2024
arXiv:2409.00135 [cs.CL]
[388] Miret S and Krishnan N M A 2024 arXiv:2402.05200
[cond-mat.mtrl-sci]
[389] Nie S, Xiang Y, Wu L, Lin G, Liu Q, Chu S, and Wang
X 2024 J. Am. Chem. Soc. 14629325
[390] Qu J, Xie Y, Ciesielski K, Porter C, Toberer E, and
Ertekin E 2023 arXiv:2305.01101 [cond-mat.mtrl-sci]
[391] Zhong Y, Tao Z G, Chu W B, Gong X G, and Xiang H
J 2023 arXiv:2302.00439 [physics.comp-ph]
[392] Gibson J B, Hire A C, Dee P M, Barrera O, Geisler
B, Hirschfeld P J, and Hennig R G 2025 NPJ Comput.
Mater. 117
[393] Haldar A, Clark Q, Zacharias M, Giustino F, and Shar-
ifzadeh S 2024 Phys. Rev. Mater. 8L101001
[394] Okabe R, Chotrattanapituk A, Boonkird A, Andrejevic
N, Fu X, Jaakkola T S, Song Q, Nguyen T, Drucker N,
Mu S et al. 2024 Nat. Comput. Sci. 4522
[395] Fang S, Geiger M, Checkelsky J G, and Smidt T 2024
arXiv:2403.11347 [cond-mat.dis-nn]
[396] Zhang H, Liu S, You J, Liu C, Zheng S, Lu Z, Wang T,
Zheng N, and Shao B 2024 Nat. Comput. Sci. 4210
[397] Li H, Wang Z, Zou N, Ye M, Xu R, Gong X, Duan W,
and Xu Y 2022 Nat. Comput. Sci. 2367
[398] Gong X, Li H, Zou N, Xu R, Duan W, and Xu Y 2023
Nat. Commun. 142848
[399] Li H, Tang Z, Fu J, Dong W H, Zou N, Gong X, Duan
W, and Xu Y 2024 Phys. Rev. Lett. 132096401
[400] Li H, Tang Z, Gong X, Zou N, Duan W, and Xu Y 2023
Nat. Comput. Sci. 3321
[401] Tang Z, Li H, Lin P, Gong X, Jin G, He L, Jiang H, Ren
X, Duan W, and Xu Y 2024 Nat. Commun. 158815
[402] Gong X, Louie S G, Duan W, and Xu Y 2024 Nat. Com-
put. Sci. 4752
[403] Tang Z, Zou N, Li H, Wang Y, Yuan Z, Tao H, Li Y,
Chen Z, Zhao B, Sun M et al. 2024 arXiv:2406.17561
[physics.comp-ph]
[404] Wang Y, Li H, Tang Z, Tao H, Wang Y, Yuan Z,
Chen Z, Duan W, and Xu Y 2024 arXiv:2401.17015
[physics.comp-ph]
[405] Li Y, Tang Z, Chen Z, Sun M, Zhao B, Li H, Tao H,
Yuan Z, Duan W, and Xu Y 2024 Phys. Rev. Lett. 133
076401
[406] Wang Y, Li Y, Tang Z, Li H, Yuan Z, Tao H, Zou N, Bao
T, Liang X, Chen Z et al. 2024 Science Bulletin 692514
[407] Zhong Y, Yu H, Yang J, Guo X, Xiang H, and Gong X
2024 Chin. Phys. Lett. 41077103
[408] Su M, Yang J H, Xiang H J, and Gong X G 2023 Mach.
Learn.: Sci. Technol. 4035010
027403-40

\end{document}
